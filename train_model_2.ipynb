{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zuIm2Q3EOBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "\n",
        "if torch.cuda.is_available()==True:\n",
        "    use_cuda = True\n",
        "    print(f'GPU available: {torch.cuda.get_device_name(0)} ({torch.cuda.device_count()} count)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45E6tB-cFq0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def default_device():\n",
        "    if torch.cuda.is_available()==True:\n",
        "        dflt_device = torch.device('cuda')\n",
        "    else:\n",
        "        dflt_device = torch.device('cpu')\n",
        "\n",
        "    return dflt_device\n",
        "\n",
        "\n",
        "def load_data(dir_in_str):\n",
        "    E, S_pre, durations_list, min_pitch, max_pitch = torch.load(dir_in_str)\n",
        "    E = E.to(device=dflt_device)\n",
        "    S = []\n",
        "    for tensor in S_pre:\n",
        "        S.append(tensor.to(device=dflt_device))\n",
        "\n",
        "    return E, S, durations_list, min_pitch, max_pitch\n",
        "\n",
        "\n",
        "def dimensions(E,S): \n",
        "    num_event_examples, num_events , event_emb_size  = E.shape    \n",
        "    num_seq_examples = len(S)\n",
        "    signal_emb_size = S[0].size(1)\n",
        "    \n",
        "    dims = [num_event_examples, num_events , event_emb_size, num_seq_examples, signal_emb_size ]\n",
        "    \n",
        "    return dims\n",
        "  \n",
        "\n",
        "def prepare_data(S):\n",
        "  S_pre_input = []\n",
        "  first_row = torch.zeros(1,signal_emb_size).to(device=dflt_device)\n",
        "  for tensor in S:\n",
        "      expanded_tensor = torch.cat((first_row, tensor), dim=0)\n",
        "      new_tensor = expanded_tensor[:-1, :]\n",
        "      S_pre_input.append(new_tensor)\n",
        "      \n",
        "  conditioning_idxs_vectors = [] \n",
        "  for tensor in S:\n",
        "      conditioning_indices = torch.zeros(tensor.shape[0], 1).to(device=dflt_device)\n",
        "      cumulative_duration = 0\n",
        "      for row in range(0, tensor.shape[0]-1):\n",
        "          vector = tensor[row, :]        \n",
        "          pitch_idx, rhythm_idx = list((vector != 0).nonzero())\n",
        "          pitch_idx, rhythm_idx = int(pitch_idx), int(rhythm_idx)\n",
        "          duration_type_idx = rhythm_idx - rhythm_idx_ini\n",
        "          duration_type = durations_list[duration_type_idx]\n",
        "          cumulative_duration += duration_type\n",
        "          conditioning_indices[row+1] = int(cumulative_duration)\n",
        "      conditioning_idxs_vectors.append(conditioning_indices)\n",
        "\n",
        "  lengths_list = []\n",
        "  for tensor in S:\n",
        "      lengths_list.append(tensor.shape[0])\n",
        "\n",
        "  S_padded = torch.nn.utils.rnn.pad_sequence(S, batch_first=True)\n",
        "  S_packed = torch.nn.utils.rnn.pack_padded_sequence(S_padded, batch_first=True, lengths=lengths_list, enforce_sorted=False)\n",
        "\n",
        "  return S_packed, S_padded, S_pre_input, lengths_list, conditioning_idxs_vectors\n",
        "\n",
        "\n",
        "def create_placing_matrices(conditioning_idxs_vectors, num_events):\n",
        "    placing_conditioning_matrices = []\n",
        "    for vector in conditioning_idxs_vectors:\n",
        "        placing_matrix = torch.zeros(vector.shape[0], num_events).to(device=dflt_device)\n",
        "        for i in range(vector.shape[0]):\n",
        "            placing_matrix[i, int(vector[i])] = 1\n",
        "        placing_conditioning_matrices.append(placing_matrix)\n",
        "        \n",
        "    return placing_conditioning_matrices\n",
        "\n",
        "\n",
        "def concatenate_conditioning(S_pre_input, \\\n",
        "                             encoded_conditioning, \\\n",
        "                             placing_conditioning_matrices, lengths_list):    \n",
        "  S_conditioned = []\n",
        "  for idx, tensor in enumerate(S_pre_input):\n",
        "    placing_matrix = placing_conditioning_matrices[idx]\n",
        "    dynamic_conditioning = torch.mm(placing_matrix, encoded_conditioning[idx,:,:])\n",
        "    concatenated_input = torch.cat((tensor, dynamic_conditioning), dim=1)\n",
        "    S_conditioned.append(concatenated_input)\n",
        "  S_input = torch.nn.utils.rnn.pad_sequence(S_conditioned, batch_first=True)\n",
        "  S_input = torch.nn.utils.rnn.pack_padded_sequence(S_input, batch_first=True, lengths=lengths_list, enforce_sorted=False)\n",
        "\n",
        "  return S_input\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_avKGXDBKxce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class event_net(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, event_emb_size, event_hidden_size, event_output_size, \\\n",
        "                 num_event_layers, num_event_examples, num_directions):\n",
        "        super(event_net, self).__init__()\n",
        "\n",
        "        self.event_emb_size     = event_emb_size\n",
        "        self.event_hidden_size  = event_hidden_size\n",
        "        self.event_output_size  = event_output_size\n",
        "        self.num_event_layers   = num_event_layers\n",
        "        self.num_event_examples = num_event_examples\n",
        "        self.num_directions     = num_directions\n",
        "        \n",
        "        self.event_lstm   = torch.nn.LSTM(self.event_emb_size, self.event_hidden_size, \\\n",
        "                                    self.num_event_layers, batch_first=True, bidirectional=True)\n",
        "        self.event_linear = torch.nn.Linear(self.event_hidden_size*num_directions, self.event_output_size)\n",
        "        \n",
        "        self.initHidden  = self.init_hidden()\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        h_ini = (torch.zeros(self.num_event_layers*num_directions, self.num_event_examples, self.event_hidden_size),\\\n",
        "              torch.zeros(self.num_event_layers*num_directions, self.num_event_examples, self.event_hidden_size) )\n",
        "          \n",
        "    def forward(self, Events):\n",
        "        event_lstm_out, event_hidden = self.event_lstm(Events, self.initHidden)\n",
        "        linear_output = self.event_linear(event_lstm_out*num_event_layers)\n",
        "        event_output = torch.sigmoid(linear_output)\n",
        "        \n",
        "        return event_output #event_lstm_out\n",
        "\n",
        "\n",
        "class signal_net(torch.nn.Module):\n",
        "    def __init__(self, signal_emb_size, conditioning_size, signal_hidden_size, \\\n",
        "                 signal_output_size, num_signal_layers, num_signal_examples):\n",
        "        super(signal_net, self).__init__()\n",
        "        \n",
        "        self.signal_emb_size     = signal_emb_size\n",
        "        self.conditioning_size   = conditioning_size\n",
        "        self.signal_hidden_size  = signal_hidden_size\n",
        "        self.signal_output_size  = signal_output_size\n",
        "        self.num_signal_layers   = num_signal_layers\n",
        "        self.num_signal_examples = num_signal_examples\n",
        "        \n",
        "        self.signal_lstm   = torch.nn.LSTM(self.signal_emb_size+self.conditioning_size, self.signal_hidden_size, \\\n",
        "                                    self.num_signal_layers, batch_first=True)\n",
        "        self.signal_linear = torch.nn.Linear(self.signal_hidden_size, self.signal_output_size)\n",
        "        \n",
        "    def forward(self, S_input, prev_hidden):\n",
        "        signal_lstm_out, signal_hidden = self.signal_lstm(S_input, prev_hidden)\n",
        "        signal_linear_output = self.signal_linear(signal_lstm_out.data)\n",
        "        #signal_output = torch.sigmoid(signal_linear_output)\n",
        "        \n",
        "        return signal_linear_output, signal_hidden\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Mw05tKHE7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dflt_device = default_device()\n",
        "\n",
        "E, S, durations_list, min_pitch, max_pitch = load_data('Parker_Dataset_unshuffled.pt')\n",
        "#E, S = E[0:6,:,:], S[0:6]\n",
        "\n",
        "num_event_examples, num_events , event_emb_size, num_signal_examples, signal_emb_size = dimensions(E,S)\n",
        "rhythm_idx_ini = max_pitch - min_pitch + 1 + True\n",
        "\n",
        "S_packed, S_padded, S_pre_input, lengths_list, conditioning_idxs_vectors = prepare_data(S)\n",
        "placing_conditioning_matrices = create_placing_matrices(conditioning_idxs_vectors, num_events)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F4G6u8YVYEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(12)\n",
        "\n",
        "#Choose dimensions for event LSTM\n",
        "num_event_layers = 1\n",
        "event_hidden_size = 32\n",
        "num_directions = 2\n",
        "event_output_size = 48\n",
        "\n",
        "#Choose dimensions for signal LSTM\n",
        "num_signal_layers  = 1\n",
        "signal_hidden_size = 128\n",
        "signal_output_size = 89\n",
        "conditioning_size  = event_output_size\n",
        "\n",
        "#Create 1st LSTM\n",
        "event_forward_pass = event_net(event_emb_size, event_hidden_size, event_output_size, \\\n",
        "                 num_event_layers, num_event_examples, num_directions)\n",
        "event_forward_pass = event_forward_pass.to(device=dflt_device)\n",
        "\n",
        "#Create 2nd LSTM\n",
        "signal_forward_pass = signal_net(signal_emb_size, conditioning_size, signal_hidden_size, \\\n",
        "                 signal_output_size, num_signal_layers, num_signal_examples)\n",
        "signal_forward_pass = signal_forward_pass.to(device=dflt_device)\n",
        "signal_h_ini = (torch.zeros(num_signal_layers, num_signal_examples, signal_hidden_size).to(device=dflt_device),\\\n",
        "              torch.zeros(num_signal_layers, num_signal_examples, signal_hidden_size).to(device=dflt_device) )\n",
        "\n",
        "weights = list(event_forward_pass.parameters()) + list(signal_forward_pass.parameters())\n",
        "\n",
        "#Number of parameters\n",
        "num_event_parameters = sum([p.numel() for p in event_forward_pass.parameters()])\n",
        "print(f'Number of parameters in LSTM of events: {num_event_parameters}')\n",
        "\n",
        "num_signal_parameters = sum([p.numel() for p in signal_forward_pass.parameters()])\n",
        "print(f'Number of parameters in LSTM of signals: {num_signal_parameters}')\n",
        "\n",
        "print(f'Total number of parameters: {num_event_parameters+num_signal_parameters}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6PqpNP33dok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR          = 0.05\n",
        "epochs      = 3000\n",
        "WeightDecay = 1e-8\n",
        "Momentum    = 0.9\n",
        "\n",
        "loss_func    = torch.nn.BCEWithLogitsLoss()\n",
        "#loss_func    = torch.nn.MSELoss()\n",
        "optimizer    = torch.optim.Adam(weights, lr=LR, betas=(0.9, 0.999), eps=1e-8, weight_decay = WeightDecay )\n",
        "#optimizer    = torch.optim.RMSprop(weights,lr=LR, alpha=0.99, eps=1e-8, weight_decay = WeightDecay, momentum = Momentum, centered=True)\n",
        "#scheduler    = torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.5, last_epoch=-1)\n",
        "scheduler    = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.000001, last_epoch=-1)\n",
        "\n",
        "loss_hist  = []\n",
        "for epoch in range(1, epochs+1):\n",
        "  t = time.time()\n",
        "  optimizer.zero_grad()\n",
        "  encoded_conditioning = event_forward_pass(E)\n",
        "  S_input = concatenate_conditioning(S_pre_input, encoded_conditioning, placing_conditioning_matrices, lengths_list)\n",
        "  S_hat, _ = signal_forward_pass(S_input, signal_h_ini)\n",
        "  Loss = loss_func(S_hat, S_packed.data)\n",
        "  Loss.backward()\n",
        "  optimizer.step()\n",
        "  loss_hist.append(Loss.item())\n",
        "  scheduler.step()\n",
        "  #if epoch%200==0:\n",
        "  print(f'Epoch: {epoch}, Loss: {Loss}  (Learning rate: {scheduler.get_lr()}, Time: {round(time.time()-t,4)}s')\n",
        "\n",
        "plt.plot(loss_hist[:])\n",
        "plt.xlabel('Gradient Steps')\n",
        "vert_label=plt.ylabel('Loss')\n",
        "vert_label.set_rotation(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qQ4im_HOU9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = {'num_event_layers':num_event_layers, 'event_hidden_size':event_hidden_size,\\\n",
        "                       'num_directions':num_directions, 'event_output_size':event_output_size,\\\n",
        "                       'num_signal_layers':num_signal_layers, 'signal_hidden_size':signal_hidden_size,\n",
        "                       'signal_output_size':signal_output_size, 'conditioning_size':event_output_size,\\\n",
        "                        'LR': LR, 'epochs':epochs, 'WeightDecay':WeightDecay, 'Momentum':Momentum }\n",
        "model_parameters = [hyperparameters, event_forward_pass.state_dict(), signal_forward_pass.state_dict()]\n",
        "\n",
        "torch.save(model_parameters, 'model_parameters.pt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
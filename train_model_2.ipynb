{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zuIm2Q3EOBJ",
        "colab_type": "code",
        "outputId": "9a346273-e02f-4968-c2c6-acb6d85626a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "\n",
        "if torch.cuda.is_available()==True:\n",
        "    use_cuda = True\n",
        "    print(f'GPU available: {torch.cuda.get_device_name(0)} ({torch.cuda.device_count()} count)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.3.1+cu100\n",
            "GPU available: Tesla K80 (1 count)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45E6tB-cFq0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def default_device():\n",
        "    if torch.cuda.is_available()==True:\n",
        "        dflt_device = torch.device('cuda')\n",
        "    else:\n",
        "        dflt_device = torch.device('cpu')\n",
        "\n",
        "    return dflt_device\n",
        "\n",
        "\n",
        "def load_data(dir_in_str):\n",
        "    E, S_pre, durations_list, min_pitch, max_pitch = torch.load(dir_in_str)\n",
        "    E = E.to(device=dflt_device)\n",
        "    S = []\n",
        "    for tensor in S_pre:\n",
        "        S.append(tensor.to(device=dflt_device))\n",
        "\n",
        "    return E, S, durations_list, min_pitch, max_pitch\n",
        "\n",
        "\n",
        "def dimensions(E,S): \n",
        "    \n",
        "    num_event_examples, num_events , event_emb_size  = E.shape    \n",
        "    num_seq_examples = len(S)\n",
        "    signal_emb_size = S[0].size(1)\n",
        "    \n",
        "    dims = [num_event_examples, num_events , event_emb_size, num_seq_examples, signal_emb_size ]\n",
        "    \n",
        "    return dims\n",
        "  \n",
        "\n",
        "def prepare_data(S):\n",
        "  S_pre_input = []\n",
        "  first_row = torch.zeros(1,signal_emb_size).to(device=dflt_device)\n",
        "  for tensor in S:\n",
        "      expanded_tensor = torch.cat((first_row, tensor), dim=0)\n",
        "      new_tensor = expanded_tensor[:-1,:]\n",
        "      S_pre_input.append(new_tensor)\n",
        "      \n",
        "  conditioning_idxs_vectors = [] \n",
        "  for tensor in S:\n",
        "      conditioning_indices = torch.zeros(tensor.shape[0],1).to(device=dflt_device)\n",
        "      cumulative_duration = 0\n",
        "      for row in range(0,tensor.shape[0]-1):\n",
        "          vector = tensor[row,:]        \n",
        "          pitch_idx, rhythm_idx = list((vector != 0).nonzero())\n",
        "          pitch_idx, rhythm_idx = int(pitch_idx), int(rhythm_idx)\n",
        "          duration_type_idx = rhythm_idx - rhythm_idx_ini\n",
        "          duration_type = durations_list[duration_type_idx]\n",
        "          cumulative_duration += duration_type\n",
        "          conditioning_indices[row+1] = int(cumulative_duration)\n",
        "      conditioning_idxs_vectors.append(conditioning_indices)\n",
        "\n",
        "  lengths_list = []\n",
        "  for tensor in S:\n",
        "      lengths_list.append(tensor.shape[0])\n",
        "\n",
        "  S_padded = torch.nn.utils.rnn.pad_sequence(S, batch_first=True)\n",
        "  S_packed = torch.nn.utils.rnn.pack_padded_sequence(S_padded, batch_first=True, lengths=lengths_list, enforce_sorted=False)\n",
        "\n",
        "  return S_packed, S_padded, S_pre_input, lengths_list, conditioning_idxs_vectors\n",
        "\n",
        "\n",
        "def create_placing_matrices(conditioning_idxs_vectors, num_events):\n",
        "    placing_conditioning_matrices = []\n",
        "    for vector in conditioning_idxs_vectors:\n",
        "        placing_matrix = torch.zeros(vector.shape[0], num_events).to(device=dflt_device)\n",
        "        for i in range(vector.shape[0]):\n",
        "            placing_matrix[i, int(vector[i])] = 1\n",
        "        placing_conditioning_matrices.append(placing_matrix)\n",
        "        \n",
        "    return placing_conditioning_matrices\n",
        "\n",
        "\n",
        "def concatenate_conditioning(S_pre_input, \\\n",
        "                             encoded_conditioning, \\\n",
        "                             placing_conditioning_matrices, lengths_list):    \n",
        "  S_conditioned = []\n",
        "  for idx, tensor in enumerate(S_pre_input):\n",
        "    placing_matrix = placing_conditioning_matrices[idx]\n",
        "    dynamic_conditioning = torch.mm(placing_matrix, encoded_conditioning[idx,:,:])\n",
        "    concatenated_input = torch.cat((tensor, dynamic_conditioning), dim=1)\n",
        "    S_conditioned.append(concatenated_input)\n",
        "  S_input = torch.nn.utils.rnn.pad_sequence(S_conditioned, batch_first=True)\n",
        "  S_input = torch.nn.utils.rnn.pack_padded_sequence(S_input, batch_first=True, lengths=lengths_list, enforce_sorted=False)\n",
        "\n",
        "  return S_input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_avKGXDBKxce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class event_net(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, event_emb_size, event_hidden_size, event_output_size, \\\n",
        "                 num_event_layers, num_event_examples, num_directions):\n",
        "        super(event_net, self).__init__()\n",
        "\n",
        "        self.event_emb_size     = event_emb_size\n",
        "        self.event_hidden_size  = event_hidden_size\n",
        "        self.event_output_size  = event_output_size\n",
        "        self.num_event_layers   = num_event_layers\n",
        "        self.num_event_examples = num_event_examples\n",
        "        self.num_directions     = num_directions\n",
        "        \n",
        "        self.event_lstm   = torch.nn.LSTM(self.event_emb_size, self.event_hidden_size, \\\n",
        "                                    self.num_event_layers, batch_first=True, bidirectional=True)\n",
        "        self.event_linear = torch.nn.Linear(self.event_hidden_size*num_directions, self.event_output_size)\n",
        "        \n",
        "        self.initHidden  = self.init_hidden()\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        h_ini = (torch.zeros(self.num_event_layers*num_directions, self.num_event_examples, self.event_hidden_size),\\\n",
        "              torch.zeros(self.num_event_layers*num_directions, self.num_event_examples, self.event_hidden_size) )\n",
        "          \n",
        "    def forward(self, Events):\n",
        "        event_lstm_out, event_hidden = self.event_lstm(Events, self.initHidden)\n",
        "        linear_output = self.event_linear(event_lstm_out*num_event_layers)\n",
        "        event_output = torch.sigmoid(linear_output)\n",
        "        \n",
        "        return event_output\n",
        "\n",
        "\n",
        "class signal_net(torch.nn.Module):\n",
        "    def __init__(self, signal_emb_size, conditioning_size, signal_hidden_size, \\\n",
        "                 signal_output_size, num_signal_layers, num_signal_examples):\n",
        "        super(signal_net, self).__init__()\n",
        "        \n",
        "        self.signal_emb_size     = signal_emb_size\n",
        "        self.conditioning_size   = conditioning_size\n",
        "        self.signal_hidden_size  = signal_hidden_size\n",
        "        self.signal_output_size  = signal_output_size\n",
        "        self.num_signal_layers   = num_signal_layers\n",
        "        self.num_signal_examples = num_signal_examples\n",
        "        \n",
        "        self.signal_lstm   = torch.nn.LSTM(self.signal_emb_size+self.conditioning_size, self.signal_hidden_size, \\\n",
        "                                    self.num_signal_layers, batch_first=True)\n",
        "        self.signal_linear = torch.nn.Linear(self.signal_hidden_size, self.signal_output_size)\n",
        "        \n",
        "    def forward(self, S_input, prev_hidden):\n",
        "        signal_lstm_out, signal_hidden = self.signal_lstm(S_input, prev_hidden)\n",
        "        signal_linear_output = self.signal_linear(signal_lstm_out.data)\n",
        "        #signal_output = torch.sigmoid(signal_linear_output)\n",
        "        \n",
        "        return signal_linear_output, signal_hidden\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Mw05tKHE7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dflt_device = default_device()\n",
        "\n",
        "E, S, durations_list, min_pitch, max_pitch = load_data('Parker_Dataset_unshuffled.pt')\n",
        "#E, S = E[0:6,:,:], S[0:6]\n",
        "\n",
        "num_event_examples, num_events , event_emb_size, num_signal_examples, signal_emb_size = dimensions(E,S)\n",
        "rhythm_idx_ini = max_pitch - min_pitch + 1 + True\n",
        "\n",
        "S_packed, S_padded, S_pre_input, lengths_list, conditioning_idxs_vectors = prepare_data(S)\n",
        "placing_conditioning_matrices = create_placing_matrices(conditioning_idxs_vectors, num_events)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F4G6u8YVYEf",
        "colab_type": "code",
        "outputId": "442fbcaa-738d-4bc4-aa05-18b0790d4a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "#Choose dimensions for event LSTM\n",
        "num_event_layers = 1\n",
        "event_hidden_size = 32\n",
        "num_directions = 2\n",
        "event_output_size = 48\n",
        "\n",
        "#Choose dimensions for signal LSTM\n",
        "num_signal_layers  = 1\n",
        "signal_hidden_size = 128\n",
        "signal_output_size = 89\n",
        "conditioning_size  = event_output_size\n",
        "\n",
        "#Create 1st LSTM\n",
        "event_forward_pass = event_net(event_emb_size, event_hidden_size, event_output_size, \\\n",
        "                 num_event_layers, num_event_examples, num_directions)\n",
        "event_forward_pass = event_forward_pass.to(device=dflt_device)\n",
        "\n",
        "#Create 2nd LSTM\n",
        "signal_forward_pass = signal_net(signal_emb_size, conditioning_size, signal_hidden_size, \\\n",
        "                 signal_output_size, num_signal_layers, num_signal_examples)\n",
        "signal_forward_pass = signal_forward_pass.to(device=dflt_device)\n",
        "signal_h_ini = (torch.zeros(num_signal_layers, num_signal_examples, signal_hidden_size).to(device=dflt_device),\\\n",
        "              torch.zeros(num_signal_layers, num_signal_examples, signal_hidden_size).to(device=dflt_device) )\n",
        "\n",
        "weights = list(event_forward_pass.parameters()) + list(signal_forward_pass.parameters())\n",
        "\n",
        "#Number of parameters\n",
        "num_event_parameters = sum([p.numel() for p in event_forward_pass.parameters()])\n",
        "print(f'Number of parameters in LSTM of events: {num_event_parameters}')\n",
        "\n",
        "num_signal_parameters = sum([p.numel() for p in signal_forward_pass.parameters()])\n",
        "print(f'Number of parameters in LSTM of signals: {num_signal_parameters}')\n",
        "\n",
        "print(f'Total number of parameters: {num_event_parameters+num_signal_parameters}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in LSTM of events: 17968\n",
            "Number of parameters in LSTM of signals: 148185\n",
            "Total number of parameters: 166153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6PqpNP33dok",
        "colab_type": "code",
        "outputId": "572851b9-e2d5-4e83-ae28-34a233665f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "LR          = 0.05\n",
        "epochs      = 3000\n",
        "WeightDecay = 1e-8\n",
        "Momentum    = 0.9\n",
        "\n",
        "loss_func    = torch.nn.BCEWithLogitsLoss()\n",
        "#loss_func    = torch.nn.MSELoss()\n",
        "optimizer    = torch.optim.Adam(weights, lr=LR, betas=(0.9, 0.999), eps=1e-8, weight_decay = WeightDecay )\n",
        "#optimizer    = torch.optim.RMSprop(weights,lr=LR, alpha=0.99, eps=1e-8, weight_decay = WeightDecay, momentum = Momentum, centered=True)\n",
        "scheduler    = torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.5, last_epoch=-1)\n",
        "#scheduler    = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.000001, last_epoch=-1)\n",
        "\n",
        "loss_hist  = []\n",
        "for epoch in range(1, epochs+1):\n",
        "  t = time.time()\n",
        "  optimizer.zero_grad()\n",
        "  encoded_conditioning = event_forward_pass(E)\n",
        "  S_input = concatenate_conditioning(S_pre_input, encoded_conditioning, placing_conditioning_matrices, lengths_list)\n",
        "  S_hat, _ = signal_forward_pass(S_input, signal_h_ini)\n",
        "  Loss = loss_func(S_hat, S_packed.data)\n",
        "  Loss.backward()\n",
        "  optimizer.step()\n",
        "  loss_hist.append(Loss.item())\n",
        "  scheduler.step()\n",
        "  #if epoch%200==0:\n",
        "  print(f'Epoch: {epoch}, Loss: {Loss}  (Learning rate: {scheduler.get_lr()}, Time: {round(time.time()-t,4)}s')\n",
        "\n",
        "plt.plot(loss_hist[:])\n",
        "plt.xlabel('Gradient Steps')\n",
        "vert_label=plt.ylabel('Loss')\n",
        "vert_label.set_rotation(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 0.6899568438529968  (Learning rate: [0.05], Time: 3.2956s\n",
            "Epoch: 2, Loss: 0.10421120375394821  (Learning rate: [0.05], Time: 3.1915s\n",
            "Epoch: 3, Loss: 0.08072568476200104  (Learning rate: [0.05], Time: 3.1769s\n",
            "Epoch: 4, Loss: 0.09297320991754532  (Learning rate: [0.05], Time: 3.2042s\n",
            "Epoch: 5, Loss: 0.08463162928819656  (Learning rate: [0.05], Time: 3.1902s\n",
            "Epoch: 6, Loss: 0.08150676637887955  (Learning rate: [0.05], Time: 3.1886s\n",
            "Epoch: 7, Loss: 0.08206646144390106  (Learning rate: [0.05], Time: 3.1866s\n",
            "Epoch: 8, Loss: 0.08196084201335907  (Learning rate: [0.05], Time: 3.1857s\n",
            "Epoch: 9, Loss: 0.0811527818441391  (Learning rate: [0.05], Time: 3.1879s\n",
            "Epoch: 10, Loss: 0.0781247541308403  (Learning rate: [0.05], Time: 3.1993s\n",
            "Epoch: 11, Loss: 0.07729245722293854  (Learning rate: [0.05], Time: 3.1924s\n",
            "Epoch: 12, Loss: 0.07774801552295685  (Learning rate: [0.05], Time: 3.1961s\n",
            "Epoch: 13, Loss: 0.07783713191747665  (Learning rate: [0.05], Time: 3.1933s\n",
            "Epoch: 14, Loss: 0.07746719568967819  (Learning rate: [0.05], Time: 3.2363s\n",
            "Epoch: 15, Loss: 0.07682927697896957  (Learning rate: [0.05], Time: 3.1997s\n",
            "Epoch: 16, Loss: 0.0763559490442276  (Learning rate: [0.05], Time: 3.1879s\n",
            "Epoch: 17, Loss: 0.07616925984621048  (Learning rate: [0.05], Time: 3.1822s\n",
            "Epoch: 18, Loss: 0.07600852102041245  (Learning rate: [0.05], Time: 3.1798s\n",
            "Epoch: 19, Loss: 0.07570009678602219  (Learning rate: [0.05], Time: 3.1905s\n",
            "Epoch: 20, Loss: 0.07499127089977264  (Learning rate: [0.05], Time: 3.2284s\n",
            "Epoch: 21, Loss: 0.07470300793647766  (Learning rate: [0.05], Time: 3.204s\n",
            "Epoch: 22, Loss: 0.07475347071886063  (Learning rate: [0.05], Time: 3.2056s\n",
            "Epoch: 23, Loss: 0.07440963387489319  (Learning rate: [0.05], Time: 3.2047s\n",
            "Epoch: 24, Loss: 0.07399674504995346  (Learning rate: [0.05], Time: 3.1973s\n",
            "Epoch: 25, Loss: 0.07400310784578323  (Learning rate: [0.05], Time: 3.1815s\n",
            "Epoch: 26, Loss: 0.07394352555274963  (Learning rate: [0.05], Time: 3.1927s\n",
            "Epoch: 27, Loss: 0.07347430288791656  (Learning rate: [0.05], Time: 3.2185s\n",
            "Epoch: 28, Loss: 0.07293403893709183  (Learning rate: [0.05], Time: 3.2279s\n",
            "Epoch: 29, Loss: 0.0727870911359787  (Learning rate: [0.05], Time: 3.2122s\n",
            "Epoch: 30, Loss: 0.07287084311246872  (Learning rate: [0.05], Time: 3.2048s\n",
            "Epoch: 31, Loss: 0.07281798124313354  (Learning rate: [0.05], Time: 3.2043s\n",
            "Epoch: 32, Loss: 0.07264023274183273  (Learning rate: [0.05], Time: 3.2076s\n",
            "Epoch: 33, Loss: 0.07244670391082764  (Learning rate: [0.05], Time: 3.1984s\n",
            "Epoch: 34, Loss: 0.07238537073135376  (Learning rate: [0.05], Time: 3.2094s\n",
            "Epoch: 35, Loss: 0.0723705068230629  (Learning rate: [0.05], Time: 3.2135s\n",
            "Epoch: 36, Loss: 0.07216818630695343  (Learning rate: [0.05], Time: 3.2049s\n",
            "Epoch: 37, Loss: 0.07190706580877304  (Learning rate: [0.05], Time: 3.2129s\n",
            "Epoch: 38, Loss: 0.07182293385267258  (Learning rate: [0.05], Time: 3.2057s\n",
            "Epoch: 39, Loss: 0.07181543856859207  (Learning rate: [0.05], Time: 3.2012s\n",
            "Epoch: 40, Loss: 0.07169337570667267  (Learning rate: [0.05], Time: 3.2001s\n",
            "Epoch: 41, Loss: 0.07155097275972366  (Learning rate: [0.05], Time: 3.2088s\n",
            "Epoch: 42, Loss: 0.07150048762559891  (Learning rate: [0.05], Time: 3.2155s\n",
            "Epoch: 43, Loss: 0.07145680487155914  (Learning rate: [0.05], Time: 3.2187s\n",
            "Epoch: 44, Loss: 0.07134336978197098  (Learning rate: [0.05], Time: 3.194s\n",
            "Epoch: 45, Loss: 0.07121623307466507  (Learning rate: [0.05], Time: 3.2083s\n",
            "Epoch: 46, Loss: 0.07112980633974075  (Learning rate: [0.05], Time: 3.2142s\n",
            "Epoch: 47, Loss: 0.07103818655014038  (Learning rate: [0.05], Time: 3.2184s\n",
            "Epoch: 48, Loss: 0.07093702256679535  (Learning rate: [0.05], Time: 3.2119s\n",
            "Epoch: 49, Loss: 0.07087438553571701  (Learning rate: [0.05], Time: 3.2129s\n",
            "Epoch: 50, Loss: 0.07081394642591476  (Learning rate: [0.05], Time: 3.2119s\n",
            "Epoch: 51, Loss: 0.07073593139648438  (Learning rate: [0.05], Time: 3.2169s\n",
            "Epoch: 52, Loss: 0.07065541297197342  (Learning rate: [0.05], Time: 3.2163s\n",
            "Epoch: 53, Loss: 0.0705813318490982  (Learning rate: [0.05], Time: 3.2141s\n",
            "Epoch: 54, Loss: 0.0704951211810112  (Learning rate: [0.05], Time: 3.2097s\n",
            "Epoch: 55, Loss: 0.07038285583257675  (Learning rate: [0.05], Time: 3.2041s\n",
            "Epoch: 56, Loss: 0.07029272615909576  (Learning rate: [0.05], Time: 3.2089s\n",
            "Epoch: 57, Loss: 0.07022920250892639  (Learning rate: [0.05], Time: 3.2216s\n",
            "Epoch: 58, Loss: 0.07015187293291092  (Learning rate: [0.05], Time: 3.231s\n",
            "Epoch: 59, Loss: 0.07002672553062439  (Learning rate: [0.05], Time: 3.2022s\n",
            "Epoch: 60, Loss: 0.06994003802537918  (Learning rate: [0.05], Time: 3.2099s\n",
            "Epoch: 61, Loss: 0.06988663971424103  (Learning rate: [0.05], Time: 3.216s\n",
            "Epoch: 62, Loss: 0.06980281323194504  (Learning rate: [0.05], Time: 3.2106s\n",
            "Epoch: 63, Loss: 0.06970680505037308  (Learning rate: [0.05], Time: 3.2077s\n",
            "Epoch: 64, Loss: 0.0696323961019516  (Learning rate: [0.05], Time: 3.2174s\n",
            "Epoch: 65, Loss: 0.06955764442682266  (Learning rate: [0.05], Time: 3.2208s\n",
            "Epoch: 66, Loss: 0.06946124136447906  (Learning rate: [0.05], Time: 3.2105s\n",
            "Epoch: 67, Loss: 0.06937135010957718  (Learning rate: [0.05], Time: 3.217s\n",
            "Epoch: 68, Loss: 0.06930258870124817  (Learning rate: [0.05], Time: 3.2089s\n",
            "Epoch: 69, Loss: 0.06922812759876251  (Learning rate: [0.05], Time: 3.2057s\n",
            "Epoch: 70, Loss: 0.06913447380065918  (Learning rate: [0.05], Time: 3.2129s\n",
            "Epoch: 71, Loss: 0.06905677169561386  (Learning rate: [0.05], Time: 3.2247s\n",
            "Epoch: 72, Loss: 0.06898780167102814  (Learning rate: [0.05], Time: 3.2214s\n",
            "Epoch: 73, Loss: 0.06890281289815903  (Learning rate: [0.05], Time: 3.2019s\n",
            "Epoch: 74, Loss: 0.06882485002279282  (Learning rate: [0.05], Time: 3.2118s\n",
            "Epoch: 75, Loss: 0.06875825673341751  (Learning rate: [0.05], Time: 3.2073s\n",
            "Epoch: 76, Loss: 0.06868725270032883  (Learning rate: [0.05], Time: 3.2151s\n",
            "Epoch: 77, Loss: 0.06861485540866852  (Learning rate: [0.05], Time: 3.2211s\n",
            "Epoch: 78, Loss: 0.0685446560382843  (Learning rate: [0.05], Time: 3.2308s\n",
            "Epoch: 79, Loss: 0.06847783178091049  (Learning rate: [0.05], Time: 3.2253s\n",
            "Epoch: 80, Loss: 0.06840971857309341  (Learning rate: [0.05], Time: 3.2042s\n",
            "Epoch: 81, Loss: 0.06833793967962265  (Learning rate: [0.05], Time: 3.2145s\n",
            "Epoch: 82, Loss: 0.06827093660831451  (Learning rate: [0.05], Time: 3.2075s\n",
            "Epoch: 83, Loss: 0.06820947676897049  (Learning rate: [0.05], Time: 3.2104s\n",
            "Epoch: 84, Loss: 0.0681489035487175  (Learning rate: [0.05], Time: 3.2085s\n",
            "Epoch: 85, Loss: 0.0680888444185257  (Learning rate: [0.05], Time: 3.2083s\n",
            "Epoch: 86, Loss: 0.06802989542484283  (Learning rate: [0.05], Time: 3.2076s\n",
            "Epoch: 87, Loss: 0.0679730474948883  (Learning rate: [0.05], Time: 3.2109s\n",
            "Epoch: 88, Loss: 0.06791657954454422  (Learning rate: [0.05], Time: 3.2047s\n",
            "Epoch: 89, Loss: 0.06786227971315384  (Learning rate: [0.05], Time: 3.2122s\n",
            "Epoch: 90, Loss: 0.06781073659658432  (Learning rate: [0.05], Time: 3.2134s\n",
            "Epoch: 91, Loss: 0.06775916367769241  (Learning rate: [0.05], Time: 3.2025s\n",
            "Epoch: 92, Loss: 0.06770899891853333  (Learning rate: [0.05], Time: 3.2055s\n",
            "Epoch: 93, Loss: 0.06766106188297272  (Learning rate: [0.05], Time: 3.2081s\n",
            "Epoch: 94, Loss: 0.06761796027421951  (Learning rate: [0.05], Time: 3.2213s\n",
            "Epoch: 95, Loss: 0.06757186353206635  (Learning rate: [0.05], Time: 3.2065s\n",
            "Epoch: 96, Loss: 0.06753361225128174  (Learning rate: [0.05], Time: 3.2048s\n",
            "Epoch: 97, Loss: 0.06747471541166306  (Learning rate: [0.05], Time: 3.2076s\n",
            "Epoch: 98, Loss: 0.0674186572432518  (Learning rate: [0.05], Time: 3.2044s\n",
            "Epoch: 99, Loss: 0.06736912578344345  (Learning rate: [0.05], Time: 3.197s\n",
            "Epoch: 100, Loss: 0.06733104586601257  (Learning rate: [0.05], Time: 3.2606s\n",
            "Epoch: 101, Loss: 0.06729839742183685  (Learning rate: [0.05], Time: 3.2189s\n",
            "Epoch: 102, Loss: 0.06725386530160904  (Learning rate: [0.05], Time: 3.2086s\n",
            "Epoch: 103, Loss: 0.06720855832099915  (Learning rate: [0.05], Time: 3.2121s\n",
            "Epoch: 104, Loss: 0.06716026365756989  (Learning rate: [0.05], Time: 3.2051s\n",
            "Epoch: 105, Loss: 0.06711982190608978  (Learning rate: [0.05], Time: 3.2072s\n",
            "Epoch: 106, Loss: 0.06708619743585587  (Learning rate: [0.05], Time: 3.2087s\n",
            "Epoch: 107, Loss: 0.06705424189567566  (Learning rate: [0.05], Time: 3.2064s\n",
            "Epoch: 108, Loss: 0.06702977418899536  (Learning rate: [0.05], Time: 3.2202s\n",
            "Epoch: 109, Loss: 0.06699224561452866  (Learning rate: [0.05], Time: 3.2134s\n",
            "Epoch: 110, Loss: 0.06696464866399765  (Learning rate: [0.05], Time: 3.1996s\n",
            "Epoch: 111, Loss: 0.06691130250692368  (Learning rate: [0.05], Time: 3.2167s\n",
            "Epoch: 112, Loss: 0.06686538457870483  (Learning rate: [0.05], Time: 3.2096s\n",
            "Epoch: 113, Loss: 0.06682638823986053  (Learning rate: [0.05], Time: 3.21s\n",
            "Epoch: 114, Loss: 0.06679783016443253  (Learning rate: [0.05], Time: 3.2133s\n",
            "Epoch: 115, Loss: 0.066778764128685  (Learning rate: [0.05], Time: 3.2085s\n",
            "Epoch: 116, Loss: 0.06675857305526733  (Learning rate: [0.05], Time: 3.2187s\n",
            "Epoch: 117, Loss: 0.06675655394792557  (Learning rate: [0.05], Time: 3.2049s\n",
            "Epoch: 118, Loss: 0.06670326739549637  (Learning rate: [0.05], Time: 3.206s\n",
            "Epoch: 119, Loss: 0.06665496528148651  (Learning rate: [0.05], Time: 3.2047s\n",
            "Epoch: 120, Loss: 0.0666133314371109  (Learning rate: [0.05], Time: 3.212s\n",
            "Epoch: 121, Loss: 0.06659767776727676  (Learning rate: [0.05], Time: 3.2174s\n",
            "Epoch: 122, Loss: 0.06659522652626038  (Learning rate: [0.05], Time: 3.2167s\n",
            "Epoch: 123, Loss: 0.06656046211719513  (Learning rate: [0.05], Time: 3.2133s\n",
            "Epoch: 124, Loss: 0.06652206927537918  (Learning rate: [0.05], Time: 3.2062s\n",
            "Epoch: 125, Loss: 0.06648284941911697  (Learning rate: [0.05], Time: 3.2149s\n",
            "Epoch: 126, Loss: 0.0664624273777008  (Learning rate: [0.05], Time: 3.2073s\n",
            "Epoch: 127, Loss: 0.06645408272743225  (Learning rate: [0.05], Time: 3.2072s\n",
            "Epoch: 128, Loss: 0.06643334776163101  (Learning rate: [0.05], Time: 3.2372s\n",
            "Epoch: 129, Loss: 0.06640958786010742  (Learning rate: [0.05], Time: 3.2141s\n",
            "Epoch: 130, Loss: 0.06637255847454071  (Learning rate: [0.05], Time: 3.2171s\n",
            "Epoch: 131, Loss: 0.06634342670440674  (Learning rate: [0.05], Time: 3.2123s\n",
            "Epoch: 132, Loss: 0.0663229301571846  (Learning rate: [0.05], Time: 3.2192s\n",
            "Epoch: 133, Loss: 0.06630963087081909  (Learning rate: [0.05], Time: 3.2182s\n",
            "Epoch: 134, Loss: 0.06630589067935944  (Learning rate: [0.05], Time: 3.2147s\n",
            "Epoch: 135, Loss: 0.06630178540945053  (Learning rate: [0.05], Time: 3.2066s\n",
            "Epoch: 136, Loss: 0.06632092595100403  (Learning rate: [0.05], Time: 3.207s\n",
            "Epoch: 137, Loss: 0.06627458333969116  (Learning rate: [0.05], Time: 3.2054s\n",
            "Epoch: 138, Loss: 0.06623212993144989  (Learning rate: [0.05], Time: 3.2039s\n",
            "Epoch: 139, Loss: 0.06619183719158173  (Learning rate: [0.05], Time: 3.1976s\n",
            "Epoch: 140, Loss: 0.06618954241275787  (Learning rate: [0.05], Time: 3.2014s\n",
            "Epoch: 141, Loss: 0.06620471924543381  (Learning rate: [0.05], Time: 3.2047s\n",
            "Epoch: 142, Loss: 0.0661730244755745  (Learning rate: [0.05], Time: 3.2062s\n",
            "Epoch: 143, Loss: 0.06613637506961823  (Learning rate: [0.05], Time: 3.2071s\n",
            "Epoch: 144, Loss: 0.06611457467079163  (Learning rate: [0.05], Time: 3.2117s\n",
            "Epoch: 145, Loss: 0.06611510366201401  (Learning rate: [0.05], Time: 3.2104s\n",
            "Epoch: 146, Loss: 0.06611721962690353  (Learning rate: [0.05], Time: 3.2063s\n",
            "Epoch: 147, Loss: 0.06608738005161285  (Learning rate: [0.05], Time: 3.2076s\n",
            "Epoch: 148, Loss: 0.06605987250804901  (Learning rate: [0.05], Time: 3.2278s\n",
            "Epoch: 149, Loss: 0.06604645401239395  (Learning rate: [0.05], Time: 3.2047s\n",
            "Epoch: 150, Loss: 0.06604506075382233  (Learning rate: [0.05], Time: 3.2181s\n",
            "Epoch: 151, Loss: 0.06605342030525208  (Learning rate: [0.05], Time: 3.2174s\n",
            "Epoch: 152, Loss: 0.06605201214551926  (Learning rate: [0.05], Time: 3.2179s\n",
            "Epoch: 153, Loss: 0.06605828553438187  (Learning rate: [0.05], Time: 3.2161s\n",
            "Epoch: 154, Loss: 0.06601862609386444  (Learning rate: [0.05], Time: 3.2105s\n",
            "Epoch: 155, Loss: 0.06598345935344696  (Learning rate: [0.05], Time: 3.1939s\n",
            "Epoch: 156, Loss: 0.06596485525369644  (Learning rate: [0.05], Time: 3.1943s\n",
            "Epoch: 157, Loss: 0.06596934795379639  (Learning rate: [0.05], Time: 3.2085s\n",
            "Epoch: 158, Loss: 0.06597959995269775  (Learning rate: [0.05], Time: 3.1978s\n",
            "Epoch: 159, Loss: 0.0659598782658577  (Learning rate: [0.05], Time: 3.2187s\n",
            "Epoch: 160, Loss: 0.06593529880046844  (Learning rate: [0.05], Time: 3.2148s\n",
            "Epoch: 161, Loss: 0.06591286510229111  (Learning rate: [0.05], Time: 3.1997s\n",
            "Epoch: 162, Loss: 0.06590612977743149  (Learning rate: [0.05], Time: 3.1992s\n",
            "Epoch: 163, Loss: 0.06591042876243591  (Learning rate: [0.05], Time: 3.1944s\n",
            "Epoch: 164, Loss: 0.06591390818357468  (Learning rate: [0.05], Time: 3.1994s\n",
            "Epoch: 165, Loss: 0.06592658907175064  (Learning rate: [0.05], Time: 3.2177s\n",
            "Epoch: 166, Loss: 0.06592115759849548  (Learning rate: [0.05], Time: 3.2014s\n",
            "Epoch: 167, Loss: 0.06591979414224625  (Learning rate: [0.05], Time: 3.2129s\n",
            "Epoch: 168, Loss: 0.06587338447570801  (Learning rate: [0.05], Time: 3.2019s\n",
            "Epoch: 169, Loss: 0.06584184616804123  (Learning rate: [0.05], Time: 3.1977s\n",
            "Epoch: 170, Loss: 0.0658392384648323  (Learning rate: [0.05], Time: 3.1991s\n",
            "Epoch: 171, Loss: 0.06585001200437546  (Learning rate: [0.05], Time: 3.2051s\n",
            "Epoch: 172, Loss: 0.06585437804460526  (Learning rate: [0.05], Time: 3.2006s\n",
            "Epoch: 173, Loss: 0.0658261701464653  (Learning rate: [0.05], Time: 3.1919s\n",
            "Epoch: 174, Loss: 0.065802663564682  (Learning rate: [0.05], Time: 3.211s\n",
            "Epoch: 175, Loss: 0.06579232215881348  (Learning rate: [0.05], Time: 3.2435s\n",
            "Epoch: 176, Loss: 0.06579454243183136  (Learning rate: [0.05], Time: 3.2036s\n",
            "Epoch: 177, Loss: 0.0658084973692894  (Learning rate: [0.05], Time: 3.2422s\n",
            "Epoch: 178, Loss: 0.06582241505384445  (Learning rate: [0.05], Time: 3.1956s\n",
            "Epoch: 179, Loss: 0.06586272269487381  (Learning rate: [0.05], Time: 3.2071s\n",
            "Epoch: 180, Loss: 0.06584803014993668  (Learning rate: [0.05], Time: 3.2042s\n",
            "Epoch: 181, Loss: 0.06583157926797867  (Learning rate: [0.05], Time: 3.2124s\n",
            "Epoch: 182, Loss: 0.06576158851385117  (Learning rate: [0.05], Time: 3.229s\n",
            "Epoch: 183, Loss: 0.06575018912553787  (Learning rate: [0.05], Time: 3.2237s\n",
            "Epoch: 184, Loss: 0.06578703224658966  (Learning rate: [0.05], Time: 3.1846s\n",
            "Epoch: 185, Loss: 0.06578173488378525  (Learning rate: [0.05], Time: 3.1789s\n",
            "Epoch: 186, Loss: 0.06574813276529312  (Learning rate: [0.05], Time: 3.181s\n",
            "Epoch: 187, Loss: 0.06572409719228745  (Learning rate: [0.05], Time: 3.1764s\n",
            "Epoch: 188, Loss: 0.0657392367720604  (Learning rate: [0.05], Time: 3.1884s\n",
            "Epoch: 189, Loss: 0.06576098501682281  (Learning rate: [0.05], Time: 3.2081s\n",
            "Epoch: 190, Loss: 0.06573669612407684  (Learning rate: [0.05], Time: 3.2268s\n",
            "Epoch: 191, Loss: 0.06570915877819061  (Learning rate: [0.05], Time: 3.1991s\n",
            "Epoch: 192, Loss: 0.06569734960794449  (Learning rate: [0.05], Time: 3.1994s\n",
            "Epoch: 193, Loss: 0.06570500880479813  (Learning rate: [0.05], Time: 3.1963s\n",
            "Epoch: 194, Loss: 0.06572336703538895  (Learning rate: [0.05], Time: 3.1832s\n",
            "Epoch: 195, Loss: 0.06572826206684113  (Learning rate: [0.05], Time: 3.2038s\n",
            "Epoch: 196, Loss: 0.06573207676410675  (Learning rate: [0.05], Time: 3.1903s\n",
            "Epoch: 197, Loss: 0.06570449471473694  (Learning rate: [0.05], Time: 3.1887s\n",
            "Epoch: 198, Loss: 0.06568128615617752  (Learning rate: [0.05], Time: 3.183s\n",
            "Epoch: 199, Loss: 0.06566573679447174  (Learning rate: [0.05], Time: 3.2417s\n",
            "Epoch: 200, Loss: 0.06566667556762695  (Learning rate: [0.05], Time: 3.2075s\n",
            "Epoch: 201, Loss: 0.06567732989788055  (Learning rate: [0.05], Time: 3.2008s\n",
            "Epoch: 202, Loss: 0.0656822919845581  (Learning rate: [0.05], Time: 3.1914s\n",
            "Epoch: 203, Loss: 0.06568629294633865  (Learning rate: [0.05], Time: 3.2094s\n",
            "Epoch: 204, Loss: 0.06567303091287613  (Learning rate: [0.05], Time: 3.2062s\n",
            "Epoch: 205, Loss: 0.06566323339939117  (Learning rate: [0.05], Time: 3.2157s\n",
            "Epoch: 206, Loss: 0.06564825773239136  (Learning rate: [0.05], Time: 3.217s\n",
            "Epoch: 207, Loss: 0.06563640385866165  (Learning rate: [0.05], Time: 3.2069s\n",
            "Epoch: 208, Loss: 0.06562823057174683  (Learning rate: [0.05], Time: 3.2072s\n",
            "Epoch: 209, Loss: 0.06562335044145584  (Learning rate: [0.05], Time: 3.2095s\n",
            "Epoch: 210, Loss: 0.06562108546495438  (Learning rate: [0.05], Time: 3.2086s\n",
            "Epoch: 211, Loss: 0.06562238931655884  (Learning rate: [0.05], Time: 3.2107s\n",
            "Epoch: 212, Loss: 0.06563525646924973  (Learning rate: [0.05], Time: 3.2023s\n",
            "Epoch: 213, Loss: 0.06566525250673294  (Learning rate: [0.05], Time: 3.2116s\n",
            "Epoch: 214, Loss: 0.06576388329267502  (Learning rate: [0.05], Time: 3.2027s\n",
            "Epoch: 215, Loss: 0.06578041613101959  (Learning rate: [0.05], Time: 3.2028s\n",
            "Epoch: 216, Loss: 0.06577631086111069  (Learning rate: [0.05], Time: 3.2109s\n",
            "Epoch: 217, Loss: 0.06561898440122604  (Learning rate: [0.05], Time: 3.2s\n",
            "Epoch: 218, Loss: 0.06565186381340027  (Learning rate: [0.05], Time: 3.2034s\n",
            "Epoch: 219, Loss: 0.06577861309051514  (Learning rate: [0.05], Time: 3.1948s\n",
            "Epoch: 220, Loss: 0.06567581743001938  (Learning rate: [0.05], Time: 3.2187s\n",
            "Epoch: 221, Loss: 0.06559527665376663  (Learning rate: [0.05], Time: 3.2121s\n",
            "Epoch: 222, Loss: 0.065681092441082  (Learning rate: [0.05], Time: 3.2253s\n",
            "Epoch: 223, Loss: 0.06570365279912949  (Learning rate: [0.05], Time: 3.2095s\n",
            "Epoch: 224, Loss: 0.06563388556241989  (Learning rate: [0.05], Time: 3.2023s\n",
            "Epoch: 225, Loss: 0.06559694558382034  (Learning rate: [0.05], Time: 3.2057s\n",
            "Epoch: 226, Loss: 0.06565921753644943  (Learning rate: [0.05], Time: 3.2069s\n",
            "Epoch: 227, Loss: 0.06572110950946808  (Learning rate: [0.05], Time: 3.207s\n",
            "Epoch: 228, Loss: 0.06558382511138916  (Learning rate: [0.05], Time: 3.224s\n",
            "Epoch: 229, Loss: 0.06560326367616653  (Learning rate: [0.05], Time: 3.2035s\n",
            "Epoch: 230, Loss: 0.06569923460483551  (Learning rate: [0.05], Time: 3.2101s\n",
            "Epoch: 231, Loss: 0.06560744345188141  (Learning rate: [0.05], Time: 3.2046s\n",
            "Epoch: 232, Loss: 0.06556232273578644  (Learning rate: [0.05], Time: 3.2073s\n",
            "Epoch: 233, Loss: 0.06558122485876083  (Learning rate: [0.05], Time: 3.2041s\n",
            "Epoch: 234, Loss: 0.0656147450208664  (Learning rate: [0.05], Time: 3.2114s\n",
            "Epoch: 235, Loss: 0.06559132784605026  (Learning rate: [0.05], Time: 3.2178s\n",
            "Epoch: 236, Loss: 0.06553038209676743  (Learning rate: [0.05], Time: 3.2183s\n",
            "Epoch: 237, Loss: 0.06553884595632553  (Learning rate: [0.05], Time: 3.2001s\n",
            "Epoch: 238, Loss: 0.06558819115161896  (Learning rate: [0.05], Time: 3.2018s\n",
            "Epoch: 239, Loss: 0.06555606424808502  (Learning rate: [0.05], Time: 3.2043s\n",
            "Epoch: 240, Loss: 0.06552334129810333  (Learning rate: [0.05], Time: 3.1956s\n",
            "Epoch: 241, Loss: 0.06548930704593658  (Learning rate: [0.05], Time: 3.2024s\n",
            "Epoch: 242, Loss: 0.06551728397607803  (Learning rate: [0.05], Time: 3.2093s\n",
            "Epoch: 243, Loss: 0.065549835562706  (Learning rate: [0.05], Time: 3.208s\n",
            "Epoch: 244, Loss: 0.06551869958639145  (Learning rate: [0.05], Time: 3.2045s\n",
            "Epoch: 245, Loss: 0.06549631059169769  (Learning rate: [0.05], Time: 3.1976s\n",
            "Epoch: 246, Loss: 0.06545141339302063  (Learning rate: [0.05], Time: 3.212s\n",
            "Epoch: 247, Loss: 0.0654437318444252  (Learning rate: [0.05], Time: 3.2067s\n",
            "Epoch: 248, Loss: 0.06546304374933243  (Learning rate: [0.05], Time: 3.2175s\n",
            "Epoch: 249, Loss: 0.06546355783939362  (Learning rate: [0.05], Time: 3.2056s\n",
            "Epoch: 250, Loss: 0.06552053987979889  (Learning rate: [0.05], Time: 3.2336s\n",
            "Epoch: 251, Loss: 0.06549712270498276  (Learning rate: [0.05], Time: 3.2152s\n",
            "Epoch: 252, Loss: 0.06549663096666336  (Learning rate: [0.05], Time: 3.2192s\n",
            "Epoch: 253, Loss: 0.06543149799108505  (Learning rate: [0.05], Time: 3.2013s\n",
            "Epoch: 254, Loss: 0.06539332866668701  (Learning rate: [0.05], Time: 3.2033s\n",
            "Epoch: 255, Loss: 0.06536421179771423  (Learning rate: [0.05], Time: 3.1989s\n",
            "Epoch: 256, Loss: 0.0653667077422142  (Learning rate: [0.05], Time: 3.1905s\n",
            "Epoch: 257, Loss: 0.06538937240839005  (Learning rate: [0.05], Time: 3.212s\n",
            "Epoch: 258, Loss: 0.06544623523950577  (Learning rate: [0.05], Time: 3.221s\n",
            "Epoch: 259, Loss: 0.06560883671045303  (Learning rate: [0.05], Time: 3.1992s\n",
            "Epoch: 260, Loss: 0.06552714854478836  (Learning rate: [0.05], Time: 3.2068s\n",
            "Epoch: 261, Loss: 0.06544690579175949  (Learning rate: [0.05], Time: 3.213s\n",
            "Epoch: 262, Loss: 0.06532891094684601  (Learning rate: [0.05], Time: 3.218s\n",
            "Epoch: 263, Loss: 0.0653708204627037  (Learning rate: [0.05], Time: 3.2108s\n",
            "Epoch: 264, Loss: 0.06551775336265564  (Learning rate: [0.05], Time: 3.2014s\n",
            "Epoch: 265, Loss: 0.06545055657625198  (Learning rate: [0.05], Time: 3.2002s\n",
            "Epoch: 266, Loss: 0.06533652544021606  (Learning rate: [0.05], Time: 3.1996s\n",
            "Epoch: 267, Loss: 0.06528406590223312  (Learning rate: [0.05], Time: 3.1865s\n",
            "Epoch: 268, Loss: 0.06530112028121948  (Learning rate: [0.05], Time: 3.1718s\n",
            "Epoch: 269, Loss: 0.06539104133844376  (Learning rate: [0.05], Time: 3.1729s\n",
            "Epoch: 270, Loss: 0.06536167114973068  (Learning rate: [0.05], Time: 3.1821s\n",
            "Epoch: 271, Loss: 0.0653267428278923  (Learning rate: [0.05], Time: 3.1847s\n",
            "Epoch: 272, Loss: 0.06526000797748566  (Learning rate: [0.05], Time: 3.179s\n",
            "Epoch: 273, Loss: 0.0652327686548233  (Learning rate: [0.05], Time: 3.1875s\n",
            "Epoch: 274, Loss: 0.06527162343263626  (Learning rate: [0.05], Time: 3.1887s\n",
            "Epoch: 275, Loss: 0.06531030684709549  (Learning rate: [0.05], Time: 3.1874s\n",
            "Epoch: 276, Loss: 0.06541083753108978  (Learning rate: [0.05], Time: 3.1757s\n",
            "Epoch: 277, Loss: 0.06536892801523209  (Learning rate: [0.05], Time: 3.1853s\n",
            "Epoch: 278, Loss: 0.06533664464950562  (Learning rate: [0.05], Time: 3.1789s\n",
            "Epoch: 279, Loss: 0.06523948907852173  (Learning rate: [0.05], Time: 3.1927s\n",
            "Epoch: 280, Loss: 0.06520335376262665  (Learning rate: [0.05], Time: 3.1784s\n",
            "Epoch: 281, Loss: 0.06532742828130722  (Learning rate: [0.05], Time: 3.1841s\n",
            "Epoch: 282, Loss: 0.06543569266796112  (Learning rate: [0.05], Time: 3.2131s\n",
            "Epoch: 283, Loss: 0.06556056439876556  (Learning rate: [0.05], Time: 3.2049s\n",
            "Epoch: 284, Loss: 0.06524401158094406  (Learning rate: [0.05], Time: 3.2083s\n",
            "Epoch: 285, Loss: 0.06522568315267563  (Learning rate: [0.05], Time: 3.2007s\n",
            "Epoch: 286, Loss: 0.06545935571193695  (Learning rate: [0.05], Time: 3.2052s\n",
            "Epoch: 287, Loss: 0.06534261256456375  (Learning rate: [0.05], Time: 3.2017s\n",
            "Epoch: 288, Loss: 0.0652175173163414  (Learning rate: [0.05], Time: 3.2259s\n",
            "Epoch: 289, Loss: 0.06514569371938705  (Learning rate: [0.05], Time: 3.2139s\n",
            "Epoch: 290, Loss: 0.0652647614479065  (Learning rate: [0.05], Time: 3.2091s\n",
            "Epoch: 291, Loss: 0.0653674453496933  (Learning rate: [0.05], Time: 3.2017s\n",
            "Epoch: 292, Loss: 0.06526687741279602  (Learning rate: [0.05], Time: 3.2062s\n",
            "Epoch: 293, Loss: 0.06516468524932861  (Learning rate: [0.05], Time: 3.2047s\n",
            "Epoch: 294, Loss: 0.06513112783432007  (Learning rate: [0.05], Time: 3.197s\n",
            "Epoch: 295, Loss: 0.06520698964595795  (Learning rate: [0.05], Time: 3.2061s\n",
            "Epoch: 296, Loss: 0.06527350097894669  (Learning rate: [0.05], Time: 3.1915s\n",
            "Epoch: 297, Loss: 0.06515438854694366  (Learning rate: [0.05], Time: 3.1897s\n",
            "Epoch: 298, Loss: 0.06511202454566956  (Learning rate: [0.05], Time: 3.2164s\n",
            "Epoch: 299, Loss: 0.06513311713933945  (Learning rate: [0.05], Time: 3.181s\n",
            "Epoch: 300, Loss: 0.0652131736278534  (Learning rate: [0.025], Time: 3.1867s\n",
            "Epoch: 301, Loss: 0.06526941806077957  (Learning rate: [0.025], Time: 3.1833s\n",
            "Epoch: 302, Loss: 0.06507228314876556  (Learning rate: [0.025], Time: 3.2035s\n",
            "Epoch: 303, Loss: 0.0651995912194252  (Learning rate: [0.025], Time: 3.1805s\n",
            "Epoch: 304, Loss: 0.06507832556962967  (Learning rate: [0.025], Time: 3.1862s\n",
            "Epoch: 305, Loss: 0.0651371031999588  (Learning rate: [0.025], Time: 3.1959s\n",
            "Epoch: 306, Loss: 0.06507854908704758  (Learning rate: [0.025], Time: 3.2168s\n",
            "Epoch: 307, Loss: 0.0651012435555458  (Learning rate: [0.025], Time: 3.2207s\n",
            "Epoch: 308, Loss: 0.06505479663610458  (Learning rate: [0.025], Time: 3.212s\n",
            "Epoch: 309, Loss: 0.06507722288370132  (Learning rate: [0.025], Time: 3.2113s\n",
            "Epoch: 310, Loss: 0.065052829682827  (Learning rate: [0.025], Time: 3.2154s\n",
            "Epoch: 311, Loss: 0.06537944823503494  (Learning rate: [0.025], Time: 3.2025s\n",
            "Epoch: 312, Loss: 0.06509628891944885  (Learning rate: [0.025], Time: 3.2081s\n",
            "Epoch: 313, Loss: 0.06505069136619568  (Learning rate: [0.025], Time: 3.2174s\n",
            "Epoch: 314, Loss: 0.06505412608385086  (Learning rate: [0.025], Time: 3.2315s\n",
            "Epoch: 315, Loss: 0.06503905355930328  (Learning rate: [0.025], Time: 3.2147s\n",
            "Epoch: 316, Loss: 0.06502345204353333  (Learning rate: [0.025], Time: 3.2186s\n",
            "Epoch: 317, Loss: 0.0650283545255661  (Learning rate: [0.025], Time: 3.2134s\n",
            "Epoch: 318, Loss: 0.06500241905450821  (Learning rate: [0.025], Time: 3.2102s\n",
            "Epoch: 319, Loss: 0.06501414626836777  (Learning rate: [0.025], Time: 3.2199s\n",
            "Epoch: 320, Loss: 0.0649881511926651  (Learning rate: [0.025], Time: 3.2125s\n",
            "Epoch: 321, Loss: 0.06500089168548584  (Learning rate: [0.025], Time: 3.2165s\n",
            "Epoch: 322, Loss: 0.0649695098400116  (Learning rate: [0.025], Time: 3.2012s\n",
            "Epoch: 323, Loss: 0.06498508900403976  (Learning rate: [0.025], Time: 3.2059s\n",
            "Epoch: 324, Loss: 0.06496115773916245  (Learning rate: [0.025], Time: 3.203s\n",
            "Epoch: 325, Loss: 0.0649690181016922  (Learning rate: [0.025], Time: 3.2003s\n",
            "Epoch: 326, Loss: 0.06494767218828201  (Learning rate: [0.025], Time: 3.2034s\n",
            "Epoch: 327, Loss: 0.06495470553636551  (Learning rate: [0.025], Time: 3.2011s\n",
            "Epoch: 328, Loss: 0.0649404525756836  (Learning rate: [0.025], Time: 3.2133s\n",
            "Epoch: 329, Loss: 0.06494373828172684  (Learning rate: [0.025], Time: 3.2165s\n",
            "Epoch: 330, Loss: 0.06493207812309265  (Learning rate: [0.025], Time: 3.2313s\n",
            "Epoch: 331, Loss: 0.06492848694324493  (Learning rate: [0.025], Time: 3.1942s\n",
            "Epoch: 332, Loss: 0.06492730230093002  (Learning rate: [0.025], Time: 3.2123s\n",
            "Epoch: 333, Loss: 0.06491246074438095  (Learning rate: [0.025], Time: 3.2156s\n",
            "Epoch: 334, Loss: 0.06491982936859131  (Learning rate: [0.025], Time: 3.1973s\n",
            "Epoch: 335, Loss: 0.06490911543369293  (Learning rate: [0.025], Time: 3.2282s\n",
            "Epoch: 336, Loss: 0.06490069627761841  (Learning rate: [0.025], Time: 3.2096s\n",
            "Epoch: 337, Loss: 0.06489492207765579  (Learning rate: [0.025], Time: 3.2263s\n",
            "Epoch: 338, Loss: 0.06487887352705002  (Learning rate: [0.025], Time: 3.2108s\n",
            "Epoch: 339, Loss: 0.06488292664289474  (Learning rate: [0.025], Time: 3.2085s\n",
            "Epoch: 340, Loss: 0.06486587971448898  (Learning rate: [0.025], Time: 3.2195s\n",
            "Epoch: 341, Loss: 0.06486383080482483  (Learning rate: [0.025], Time: 3.2066s\n",
            "Epoch: 342, Loss: 0.0648566260933876  (Learning rate: [0.025], Time: 3.2115s\n",
            "Epoch: 343, Loss: 0.06484469771385193  (Learning rate: [0.025], Time: 3.2155s\n",
            "Epoch: 344, Loss: 0.06484009325504303  (Learning rate: [0.025], Time: 3.2128s\n",
            "Epoch: 345, Loss: 0.06482849270105362  (Learning rate: [0.025], Time: 3.2172s\n",
            "Epoch: 346, Loss: 0.0648205354809761  (Learning rate: [0.025], Time: 3.2061s\n",
            "Epoch: 347, Loss: 0.06480925530195236  (Learning rate: [0.025], Time: 3.2078s\n",
            "Epoch: 348, Loss: 0.0648028776049614  (Learning rate: [0.025], Time: 3.2061s\n",
            "Epoch: 349, Loss: 0.06479249149560928  (Learning rate: [0.025], Time: 3.213s\n",
            "Epoch: 350, Loss: 0.06478618830442429  (Learning rate: [0.025], Time: 3.2126s\n",
            "Epoch: 351, Loss: 0.06477724015712738  (Learning rate: [0.025], Time: 3.205s\n",
            "Epoch: 352, Loss: 0.06477265805006027  (Learning rate: [0.025], Time: 3.2058s\n",
            "Epoch: 353, Loss: 0.06471854448318481  (Learning rate: [0.025], Time: 3.2002s\n",
            "Epoch: 354, Loss: 0.06476093828678131  (Learning rate: [0.025], Time: 3.2007s\n",
            "Epoch: 355, Loss: 0.06482836604118347  (Learning rate: [0.025], Time: 3.2109s\n",
            "Epoch: 356, Loss: 0.06474278122186661  (Learning rate: [0.025], Time: 3.2081s\n",
            "Epoch: 357, Loss: 0.06470032781362534  (Learning rate: [0.025], Time: 3.2001s\n",
            "Epoch: 358, Loss: 0.06463342159986496  (Learning rate: [0.025], Time: 3.1995s\n",
            "Epoch: 359, Loss: 0.06465909630060196  (Learning rate: [0.025], Time: 3.1973s\n",
            "Epoch: 360, Loss: 0.06458541005849838  (Learning rate: [0.025], Time: 3.1976s\n",
            "Epoch: 361, Loss: 0.06455092877149582  (Learning rate: [0.025], Time: 3.1998s\n",
            "Epoch: 362, Loss: 0.06449644267559052  (Learning rate: [0.025], Time: 3.2053s\n",
            "Epoch: 363, Loss: 0.06448201835155487  (Learning rate: [0.025], Time: 3.2067s\n",
            "Epoch: 364, Loss: 0.06444147974252701  (Learning rate: [0.025], Time: 3.202s\n",
            "Epoch: 365, Loss: 0.0643429085612297  (Learning rate: [0.025], Time: 3.2085s\n",
            "Epoch: 366, Loss: 0.06431177258491516  (Learning rate: [0.025], Time: 3.2042s\n",
            "Epoch: 367, Loss: 0.06429534405469894  (Learning rate: [0.025], Time: 3.2016s\n",
            "Epoch: 368, Loss: 0.06420277804136276  (Learning rate: [0.025], Time: 3.1985s\n",
            "Epoch: 369, Loss: 0.06414328515529633  (Learning rate: [0.025], Time: 3.195s\n",
            "Epoch: 370, Loss: 0.06410201638936996  (Learning rate: [0.025], Time: 3.2002s\n",
            "Epoch: 371, Loss: 0.0640193298459053  (Learning rate: [0.025], Time: 3.1999s\n",
            "Epoch: 372, Loss: 0.0639616921544075  (Learning rate: [0.025], Time: 3.1941s\n",
            "Epoch: 373, Loss: 0.06390582025051117  (Learning rate: [0.025], Time: 3.1987s\n",
            "Epoch: 374, Loss: 0.06382438540458679  (Learning rate: [0.025], Time: 3.2131s\n",
            "Epoch: 375, Loss: 0.06376869231462479  (Learning rate: [0.025], Time: 3.2015s\n",
            "Epoch: 376, Loss: 0.06370853632688522  (Learning rate: [0.025], Time: 3.1979s\n",
            "Epoch: 377, Loss: 0.06361890584230423  (Learning rate: [0.025], Time: 3.2129s\n",
            "Epoch: 378, Loss: 0.06354907155036926  (Learning rate: [0.025], Time: 3.196s\n",
            "Epoch: 379, Loss: 0.06349533796310425  (Learning rate: [0.025], Time: 3.2017s\n",
            "Epoch: 380, Loss: 0.06342421472072601  (Learning rate: [0.025], Time: 3.2136s\n",
            "Epoch: 381, Loss: 0.06335467100143433  (Learning rate: [0.025], Time: 3.2076s\n",
            "Epoch: 382, Loss: 0.06328213959932327  (Learning rate: [0.025], Time: 3.213s\n",
            "Epoch: 383, Loss: 0.06321162730455399  (Learning rate: [0.025], Time: 3.195s\n",
            "Epoch: 384, Loss: 0.0631471499800682  (Learning rate: [0.025], Time: 3.2068s\n",
            "Epoch: 385, Loss: 0.06308095902204514  (Learning rate: [0.025], Time: 3.199s\n",
            "Epoch: 386, Loss: 0.06301257014274597  (Learning rate: [0.025], Time: 3.1971s\n",
            "Epoch: 387, Loss: 0.0629512295126915  (Learning rate: [0.025], Time: 3.2019s\n",
            "Epoch: 388, Loss: 0.06289752572774887  (Learning rate: [0.025], Time: 3.1998s\n",
            "Epoch: 389, Loss: 0.06282942742109299  (Learning rate: [0.025], Time: 3.2109s\n",
            "Epoch: 390, Loss: 0.06278721988201141  (Learning rate: [0.025], Time: 3.202s\n",
            "Epoch: 391, Loss: 0.06274409592151642  (Learning rate: [0.025], Time: 3.2082s\n",
            "Epoch: 392, Loss: 0.06267775595188141  (Learning rate: [0.025], Time: 3.2081s\n",
            "Epoch: 393, Loss: 0.06261061877012253  (Learning rate: [0.025], Time: 3.2023s\n",
            "Epoch: 394, Loss: 0.06254922598600388  (Learning rate: [0.025], Time: 3.2277s\n",
            "Epoch: 395, Loss: 0.06248687207698822  (Learning rate: [0.025], Time: 3.2014s\n",
            "Epoch: 396, Loss: 0.062429752200841904  (Learning rate: [0.025], Time: 3.2114s\n",
            "Epoch: 397, Loss: 0.06236009672284126  (Learning rate: [0.025], Time: 3.2144s\n",
            "Epoch: 398, Loss: 0.06231682375073433  (Learning rate: [0.025], Time: 3.1983s\n",
            "Epoch: 399, Loss: 0.062264297157526016  (Learning rate: [0.025], Time: 3.208s\n",
            "Epoch: 400, Loss: 0.06218903511762619  (Learning rate: [0.025], Time: 3.2132s\n",
            "Epoch: 401, Loss: 0.06211905553936958  (Learning rate: [0.025], Time: 3.2501s\n",
            "Epoch: 402, Loss: 0.06201910972595215  (Learning rate: [0.025], Time: 3.1919s\n",
            "Epoch: 403, Loss: 0.061905886977910995  (Learning rate: [0.025], Time: 3.2116s\n",
            "Epoch: 404, Loss: 0.06188888102769852  (Learning rate: [0.025], Time: 3.2146s\n",
            "Epoch: 405, Loss: 0.061794109642505646  (Learning rate: [0.025], Time: 3.1978s\n",
            "Epoch: 406, Loss: 0.061996929347515106  (Learning rate: [0.025], Time: 3.2046s\n",
            "Epoch: 407, Loss: 0.06181385740637779  (Learning rate: [0.025], Time: 3.192s\n",
            "Epoch: 408, Loss: 0.06170263886451721  (Learning rate: [0.025], Time: 3.1941s\n",
            "Epoch: 409, Loss: 0.061891667544841766  (Learning rate: [0.025], Time: 3.2015s\n",
            "Epoch: 410, Loss: 0.061549168080091476  (Learning rate: [0.025], Time: 3.2044s\n",
            "Epoch: 411, Loss: 0.06149240583181381  (Learning rate: [0.025], Time: 3.2112s\n",
            "Epoch: 412, Loss: 0.061205919831991196  (Learning rate: [0.025], Time: 3.2104s\n",
            "Epoch: 413, Loss: 0.061243701726198196  (Learning rate: [0.025], Time: 3.2048s\n",
            "Epoch: 414, Loss: 0.06098397448658943  (Learning rate: [0.025], Time: 3.2071s\n",
            "Epoch: 415, Loss: 0.061080098152160645  (Learning rate: [0.025], Time: 3.1987s\n",
            "Epoch: 416, Loss: 0.0608125664293766  (Learning rate: [0.025], Time: 3.1997s\n",
            "Epoch: 417, Loss: 0.06081235036253929  (Learning rate: [0.025], Time: 3.198s\n",
            "Epoch: 418, Loss: 0.060554057359695435  (Learning rate: [0.025], Time: 3.2147s\n",
            "Epoch: 419, Loss: 0.060596972703933716  (Learning rate: [0.025], Time: 3.2235s\n",
            "Epoch: 420, Loss: 0.06037520617246628  (Learning rate: [0.025], Time: 3.2052s\n",
            "Epoch: 421, Loss: 0.06038341671228409  (Learning rate: [0.025], Time: 3.206s\n",
            "Epoch: 422, Loss: 0.06024090200662613  (Learning rate: [0.025], Time: 3.1953s\n",
            "Epoch: 423, Loss: 0.060131728649139404  (Learning rate: [0.025], Time: 3.2075s\n",
            "Epoch: 424, Loss: 0.06012796238064766  (Learning rate: [0.025], Time: 3.2074s\n",
            "Epoch: 425, Loss: 0.059970103204250336  (Learning rate: [0.025], Time: 3.2007s\n",
            "Epoch: 426, Loss: 0.05992705374956131  (Learning rate: [0.025], Time: 3.2366s\n",
            "Epoch: 427, Loss: 0.059719376266002655  (Learning rate: [0.025], Time: 3.2063s\n",
            "Epoch: 428, Loss: 0.05972690135240555  (Learning rate: [0.025], Time: 3.1991s\n",
            "Epoch: 429, Loss: 0.05963372439146042  (Learning rate: [0.025], Time: 3.2262s\n",
            "Epoch: 430, Loss: 0.05958399549126625  (Learning rate: [0.025], Time: 3.1948s\n",
            "Epoch: 431, Loss: 0.05956023558974266  (Learning rate: [0.025], Time: 3.191s\n",
            "Epoch: 432, Loss: 0.059447478502988815  (Learning rate: [0.025], Time: 3.1951s\n",
            "Epoch: 433, Loss: 0.05945999547839165  (Learning rate: [0.025], Time: 3.2016s\n",
            "Epoch: 434, Loss: 0.05934702232480049  (Learning rate: [0.025], Time: 3.2135s\n",
            "Epoch: 435, Loss: 0.05934128537774086  (Learning rate: [0.025], Time: 3.219s\n",
            "Epoch: 436, Loss: 0.05927940458059311  (Learning rate: [0.025], Time: 3.2032s\n",
            "Epoch: 437, Loss: 0.05922674387693405  (Learning rate: [0.025], Time: 3.2047s\n",
            "Epoch: 438, Loss: 0.05920661613345146  (Learning rate: [0.025], Time: 3.2042s\n",
            "Epoch: 439, Loss: 0.059134963899850845  (Learning rate: [0.025], Time: 3.1928s\n",
            "Epoch: 440, Loss: 0.05911600589752197  (Learning rate: [0.025], Time: 3.2012s\n",
            "Epoch: 441, Loss: 0.059076305478811264  (Learning rate: [0.025], Time: 3.2078s\n",
            "Epoch: 442, Loss: 0.05902939289808273  (Learning rate: [0.025], Time: 3.2198s\n",
            "Epoch: 443, Loss: 0.059002671390771866  (Learning rate: [0.025], Time: 3.2036s\n",
            "Epoch: 444, Loss: 0.05896811559796333  (Learning rate: [0.025], Time: 3.1973s\n",
            "Epoch: 445, Loss: 0.058915551751852036  (Learning rate: [0.025], Time: 3.2015s\n",
            "Epoch: 446, Loss: 0.05889977887272835  (Learning rate: [0.025], Time: 3.1982s\n",
            "Epoch: 447, Loss: 0.058867257088422775  (Learning rate: [0.025], Time: 3.2049s\n",
            "Epoch: 448, Loss: 0.05883082374930382  (Learning rate: [0.025], Time: 3.1946s\n",
            "Epoch: 449, Loss: 0.05880110338330269  (Learning rate: [0.025], Time: 3.2089s\n",
            "Epoch: 450, Loss: 0.05877087265253067  (Learning rate: [0.025], Time: 3.2179s\n",
            "Epoch: 451, Loss: 0.05874069407582283  (Learning rate: [0.025], Time: 3.2138s\n",
            "Epoch: 452, Loss: 0.05870435759425163  (Learning rate: [0.025], Time: 3.2042s\n",
            "Epoch: 453, Loss: 0.05868037790060043  (Learning rate: [0.025], Time: 3.2337s\n",
            "Epoch: 454, Loss: 0.058649174869060516  (Learning rate: [0.025], Time: 3.2063s\n",
            "Epoch: 455, Loss: 0.05862656235694885  (Learning rate: [0.025], Time: 3.2176s\n",
            "Epoch: 456, Loss: 0.05859651789069176  (Learning rate: [0.025], Time: 3.2164s\n",
            "Epoch: 457, Loss: 0.05857386812567711  (Learning rate: [0.025], Time: 3.2212s\n",
            "Epoch: 458, Loss: 0.058561816811561584  (Learning rate: [0.025], Time: 3.1993s\n",
            "Epoch: 459, Loss: 0.058556508272886276  (Learning rate: [0.025], Time: 3.2012s\n",
            "Epoch: 460, Loss: 0.05851244181394577  (Learning rate: [0.025], Time: 3.2012s\n",
            "Epoch: 461, Loss: 0.058498088270425797  (Learning rate: [0.025], Time: 3.2257s\n",
            "Epoch: 462, Loss: 0.05849623307585716  (Learning rate: [0.025], Time: 3.1984s\n",
            "Epoch: 463, Loss: 0.05850203335285187  (Learning rate: [0.025], Time: 3.2014s\n",
            "Epoch: 464, Loss: 0.05858848989009857  (Learning rate: [0.025], Time: 3.2117s\n",
            "Epoch: 465, Loss: 0.05865822359919548  (Learning rate: [0.025], Time: 3.2185s\n",
            "Epoch: 466, Loss: 0.058526743203401566  (Learning rate: [0.025], Time: 3.1927s\n",
            "Epoch: 467, Loss: 0.05839470773935318  (Learning rate: [0.025], Time: 3.2022s\n",
            "Epoch: 468, Loss: 0.05839068070054054  (Learning rate: [0.025], Time: 3.21s\n",
            "Epoch: 469, Loss: 0.05842597410082817  (Learning rate: [0.025], Time: 3.2159s\n",
            "Epoch: 470, Loss: 0.05836259201169014  (Learning rate: [0.025], Time: 3.2018s\n",
            "Epoch: 471, Loss: 0.05829905346035957  (Learning rate: [0.025], Time: 3.2241s\n",
            "Epoch: 472, Loss: 0.0583057627081871  (Learning rate: [0.025], Time: 3.2076s\n",
            "Epoch: 473, Loss: 0.058304548263549805  (Learning rate: [0.025], Time: 3.2055s\n",
            "Epoch: 474, Loss: 0.058231379836797714  (Learning rate: [0.025], Time: 3.2008s\n",
            "Epoch: 475, Loss: 0.058211393654346466  (Learning rate: [0.025], Time: 3.2087s\n",
            "Epoch: 476, Loss: 0.05821480602025986  (Learning rate: [0.025], Time: 3.2095s\n",
            "Epoch: 477, Loss: 0.05818500369787216  (Learning rate: [0.025], Time: 3.203s\n",
            "Epoch: 478, Loss: 0.05814460664987564  (Learning rate: [0.025], Time: 3.2006s\n",
            "Epoch: 479, Loss: 0.05811701714992523  (Learning rate: [0.025], Time: 3.2228s\n",
            "Epoch: 480, Loss: 0.05813068151473999  (Learning rate: [0.025], Time: 3.2153s\n",
            "Epoch: 481, Loss: 0.05812617763876915  (Learning rate: [0.025], Time: 3.2055s\n",
            "Epoch: 482, Loss: 0.058106936514377594  (Learning rate: [0.025], Time: 3.2045s\n",
            "Epoch: 483, Loss: 0.05809042602777481  (Learning rate: [0.025], Time: 3.205s\n",
            "Epoch: 484, Loss: 0.058055244386196136  (Learning rate: [0.025], Time: 3.1995s\n",
            "Epoch: 485, Loss: 0.05804932117462158  (Learning rate: [0.025], Time: 3.2107s\n",
            "Epoch: 486, Loss: 0.058052875101566315  (Learning rate: [0.025], Time: 3.209s\n",
            "Epoch: 487, Loss: 0.05794879049062729  (Learning rate: [0.025], Time: 3.2115s\n",
            "Epoch: 488, Loss: 0.05785074457526207  (Learning rate: [0.025], Time: 3.2056s\n",
            "Epoch: 489, Loss: 0.05782283470034599  (Learning rate: [0.025], Time: 3.1906s\n",
            "Epoch: 490, Loss: 0.05786312744021416  (Learning rate: [0.025], Time: 3.2155s\n",
            "Epoch: 491, Loss: 0.0578642301261425  (Learning rate: [0.025], Time: 3.2021s\n",
            "Epoch: 492, Loss: 0.05783608928322792  (Learning rate: [0.025], Time: 3.2039s\n",
            "Epoch: 493, Loss: 0.05777063965797424  (Learning rate: [0.025], Time: 3.2236s\n",
            "Epoch: 494, Loss: 0.057709209620952606  (Learning rate: [0.025], Time: 3.2128s\n",
            "Epoch: 495, Loss: 0.05769657716155052  (Learning rate: [0.025], Time: 3.2148s\n",
            "Epoch: 496, Loss: 0.05771339312195778  (Learning rate: [0.025], Time: 3.1947s\n",
            "Epoch: 497, Loss: 0.05800411105155945  (Learning rate: [0.025], Time: 3.1983s\n",
            "Epoch: 498, Loss: 0.05831029266119003  (Learning rate: [0.025], Time: 3.1968s\n",
            "Epoch: 499, Loss: 0.05874928459525108  (Learning rate: [0.025], Time: 3.1968s\n",
            "Epoch: 500, Loss: 0.057958658784627914  (Learning rate: [0.025], Time: 3.2036s\n",
            "Epoch: 501, Loss: 0.0587998665869236  (Learning rate: [0.025], Time: 3.2047s\n",
            "Epoch: 502, Loss: 0.058278024196624756  (Learning rate: [0.025], Time: 3.219s\n",
            "Epoch: 503, Loss: 0.058048177510499954  (Learning rate: [0.025], Time: 3.2122s\n",
            "Epoch: 504, Loss: 0.05829985439777374  (Learning rate: [0.025], Time: 3.2045s\n",
            "Epoch: 505, Loss: 0.05782612785696983  (Learning rate: [0.025], Time: 3.2059s\n",
            "Epoch: 506, Loss: 0.05814946070313454  (Learning rate: [0.025], Time: 3.1972s\n",
            "Epoch: 507, Loss: 0.05770224705338478  (Learning rate: [0.025], Time: 3.1963s\n",
            "Epoch: 508, Loss: 0.05806538835167885  (Learning rate: [0.025], Time: 3.1994s\n",
            "Epoch: 509, Loss: 0.05759825184941292  (Learning rate: [0.025], Time: 3.2055s\n",
            "Epoch: 510, Loss: 0.05792209506034851  (Learning rate: [0.025], Time: 3.2338s\n",
            "Epoch: 511, Loss: 0.057593218982219696  (Learning rate: [0.025], Time: 3.2195s\n",
            "Epoch: 512, Loss: 0.05777232348918915  (Learning rate: [0.025], Time: 3.1929s\n",
            "Epoch: 513, Loss: 0.05755450576543808  (Learning rate: [0.025], Time: 3.2024s\n",
            "Epoch: 514, Loss: 0.05767865478992462  (Learning rate: [0.025], Time: 3.1998s\n",
            "Epoch: 515, Loss: 0.05749687924981117  (Learning rate: [0.025], Time: 3.2047s\n",
            "Epoch: 516, Loss: 0.057568348944187164  (Learning rate: [0.025], Time: 3.201s\n",
            "Epoch: 517, Loss: 0.05749456584453583  (Learning rate: [0.025], Time: 3.2675s\n",
            "Epoch: 518, Loss: 0.05747130140662193  (Learning rate: [0.025], Time: 3.1994s\n",
            "Epoch: 519, Loss: 0.057452138513326645  (Learning rate: [0.025], Time: 3.209s\n",
            "Epoch: 520, Loss: 0.05738144740462303  (Learning rate: [0.025], Time: 3.2054s\n",
            "Epoch: 521, Loss: 0.057417191565036774  (Learning rate: [0.025], Time: 3.205s\n",
            "Epoch: 522, Loss: 0.05732233077287674  (Learning rate: [0.025], Time: 3.2069s\n",
            "Epoch: 523, Loss: 0.05737694352865219  (Learning rate: [0.025], Time: 3.2088s\n",
            "Epoch: 524, Loss: 0.05726968124508858  (Learning rate: [0.025], Time: 3.2201s\n",
            "Epoch: 525, Loss: 0.05732625350356102  (Learning rate: [0.025], Time: 3.2081s\n",
            "Epoch: 526, Loss: 0.05724665895104408  (Learning rate: [0.025], Time: 3.2052s\n",
            "Epoch: 527, Loss: 0.057266075164079666  (Learning rate: [0.025], Time: 3.1999s\n",
            "Epoch: 528, Loss: 0.05721326917409897  (Learning rate: [0.025], Time: 3.2013s\n",
            "Epoch: 529, Loss: 0.057209860533475876  (Learning rate: [0.025], Time: 3.1987s\n",
            "Epoch: 530, Loss: 0.05718601122498512  (Learning rate: [0.025], Time: 3.2061s\n",
            "Epoch: 531, Loss: 0.05715338513255119  (Learning rate: [0.025], Time: 3.2056s\n",
            "Epoch: 532, Loss: 0.05715863034129143  (Learning rate: [0.025], Time: 3.2078s\n",
            "Epoch: 533, Loss: 0.057112157344818115  (Learning rate: [0.025], Time: 3.2045s\n",
            "Epoch: 534, Loss: 0.057121556252241135  (Learning rate: [0.025], Time: 3.2118s\n",
            "Epoch: 535, Loss: 0.057081788778305054  (Learning rate: [0.025], Time: 3.2076s\n",
            "Epoch: 536, Loss: 0.057078227400779724  (Learning rate: [0.025], Time: 3.1999s\n",
            "Epoch: 537, Loss: 0.05706382170319557  (Learning rate: [0.025], Time: 3.205s\n",
            "Epoch: 538, Loss: 0.05707189068198204  (Learning rate: [0.025], Time: 3.2018s\n",
            "Epoch: 539, Loss: 0.05714469030499458  (Learning rate: [0.025], Time: 3.2065s\n",
            "Epoch: 540, Loss: 0.057129260152578354  (Learning rate: [0.025], Time: 3.2106s\n",
            "Epoch: 541, Loss: 0.05729878693819046  (Learning rate: [0.025], Time: 3.2243s\n",
            "Epoch: 542, Loss: 0.057341743260622025  (Learning rate: [0.025], Time: 3.216s\n",
            "Epoch: 543, Loss: 0.057259850203990936  (Learning rate: [0.025], Time: 3.2105s\n",
            "Epoch: 544, Loss: 0.057198118418455124  (Learning rate: [0.025], Time: 3.2004s\n",
            "Epoch: 545, Loss: 0.05713774263858795  (Learning rate: [0.025], Time: 3.2011s\n",
            "Epoch: 546, Loss: 0.057202354073524475  (Learning rate: [0.025], Time: 3.2035s\n",
            "Epoch: 547, Loss: 0.05710317939519882  (Learning rate: [0.025], Time: 3.2173s\n",
            "Epoch: 548, Loss: 0.05706446245312691  (Learning rate: [0.025], Time: 3.2159s\n",
            "Epoch: 549, Loss: 0.05706150829792023  (Learning rate: [0.025], Time: 3.2046s\n",
            "Epoch: 550, Loss: 0.057038914412260056  (Learning rate: [0.025], Time: 3.2054s\n",
            "Epoch: 551, Loss: 0.056976594030857086  (Learning rate: [0.025], Time: 3.197s\n",
            "Epoch: 552, Loss: 0.05700604245066643  (Learning rate: [0.025], Time: 3.2057s\n",
            "Epoch: 553, Loss: 0.05701199546456337  (Learning rate: [0.025], Time: 3.2099s\n",
            "Epoch: 554, Loss: 0.05696382746100426  (Learning rate: [0.025], Time: 3.2099s\n",
            "Epoch: 555, Loss: 0.05693483725190163  (Learning rate: [0.025], Time: 3.2114s\n",
            "Epoch: 556, Loss: 0.0569361187517643  (Learning rate: [0.025], Time: 3.2117s\n",
            "Epoch: 557, Loss: 0.05692502111196518  (Learning rate: [0.025], Time: 3.2095s\n",
            "Epoch: 558, Loss: 0.05688026547431946  (Learning rate: [0.025], Time: 3.2143s\n",
            "Epoch: 559, Loss: 0.05685265362262726  (Learning rate: [0.025], Time: 3.2041s\n",
            "Epoch: 560, Loss: 0.05684731528162956  (Learning rate: [0.025], Time: 3.2063s\n",
            "Epoch: 561, Loss: 0.05683203414082527  (Learning rate: [0.025], Time: 3.2037s\n",
            "Epoch: 562, Loss: 0.05680348724126816  (Learning rate: [0.025], Time: 3.2185s\n",
            "Epoch: 563, Loss: 0.05676879361271858  (Learning rate: [0.025], Time: 3.2099s\n",
            "Epoch: 564, Loss: 0.056754931807518005  (Learning rate: [0.025], Time: 3.2142s\n",
            "Epoch: 565, Loss: 0.056755878031253815  (Learning rate: [0.025], Time: 3.2058s\n",
            "Epoch: 566, Loss: 0.05674278363585472  (Learning rate: [0.025], Time: 3.2051s\n",
            "Epoch: 567, Loss: 0.056712448596954346  (Learning rate: [0.025], Time: 3.2049s\n",
            "Epoch: 568, Loss: 0.056674908846616745  (Learning rate: [0.025], Time: 3.2011s\n",
            "Epoch: 569, Loss: 0.056672606617212296  (Learning rate: [0.025], Time: 3.2046s\n",
            "Epoch: 570, Loss: 0.056656960397958755  (Learning rate: [0.025], Time: 3.2274s\n",
            "Epoch: 571, Loss: 0.056638453155756  (Learning rate: [0.025], Time: 3.222s\n",
            "Epoch: 572, Loss: 0.05661722645163536  (Learning rate: [0.025], Time: 3.2081s\n",
            "Epoch: 573, Loss: 0.056619759649038315  (Learning rate: [0.025], Time: 3.2075s\n",
            "Epoch: 574, Loss: 0.05661167576909065  (Learning rate: [0.025], Time: 3.2107s\n",
            "Epoch: 575, Loss: 0.05660552531480789  (Learning rate: [0.025], Time: 3.208s\n",
            "Epoch: 576, Loss: 0.05660964548587799  (Learning rate: [0.025], Time: 3.2005s\n",
            "Epoch: 577, Loss: 0.05659355968236923  (Learning rate: [0.025], Time: 3.2188s\n",
            "Epoch: 578, Loss: 0.056583333760499954  (Learning rate: [0.025], Time: 3.2174s\n",
            "Epoch: 579, Loss: 0.05653325468301773  (Learning rate: [0.025], Time: 3.2122s\n",
            "Epoch: 580, Loss: 0.0564417839050293  (Learning rate: [0.025], Time: 3.2006s\n",
            "Epoch: 581, Loss: 0.056390438228845596  (Learning rate: [0.025], Time: 3.2145s\n",
            "Epoch: 582, Loss: 0.05634098872542381  (Learning rate: [0.025], Time: 3.2047s\n",
            "Epoch: 583, Loss: 0.056340206414461136  (Learning rate: [0.025], Time: 3.2041s\n",
            "Epoch: 584, Loss: 0.056323546916246414  (Learning rate: [0.025], Time: 3.2134s\n",
            "Epoch: 585, Loss: 0.0562741719186306  (Learning rate: [0.025], Time: 3.2158s\n",
            "Epoch: 586, Loss: 0.05622158572077751  (Learning rate: [0.025], Time: 3.234s\n",
            "Epoch: 587, Loss: 0.05621826648712158  (Learning rate: [0.025], Time: 3.2051s\n",
            "Epoch: 588, Loss: 0.056279703974723816  (Learning rate: [0.025], Time: 3.217s\n",
            "Epoch: 589, Loss: 0.05625956505537033  (Learning rate: [0.025], Time: 3.2044s\n",
            "Epoch: 590, Loss: 0.0561789944767952  (Learning rate: [0.025], Time: 3.2119s\n",
            "Epoch: 591, Loss: 0.05612044781446457  (Learning rate: [0.025], Time: 3.2057s\n",
            "Epoch: 592, Loss: 0.05603684484958649  (Learning rate: [0.025], Time: 3.2116s\n",
            "Epoch: 593, Loss: 0.05599769949913025  (Learning rate: [0.025], Time: 3.2174s\n",
            "Epoch: 594, Loss: 0.05591179430484772  (Learning rate: [0.025], Time: 3.2535s\n",
            "Epoch: 595, Loss: 0.05589061602950096  (Learning rate: [0.025], Time: 3.2105s\n",
            "Epoch: 596, Loss: 0.05584575980901718  (Learning rate: [0.025], Time: 3.2019s\n",
            "Epoch: 597, Loss: 0.055792469531297684  (Learning rate: [0.025], Time: 3.2047s\n",
            "Epoch: 598, Loss: 0.055751603096723557  (Learning rate: [0.025], Time: 3.1965s\n",
            "Epoch: 599, Loss: 0.05567392706871033  (Learning rate: [0.025], Time: 3.2152s\n",
            "Epoch: 600, Loss: 0.05564623698592186  (Learning rate: [0.0125], Time: 3.2134s\n",
            "Epoch: 601, Loss: 0.05559925734996796  (Learning rate: [0.0125], Time: 3.2036s\n",
            "Epoch: 602, Loss: 0.0555245578289032  (Learning rate: [0.0125], Time: 3.2037s\n",
            "Epoch: 603, Loss: 0.05551515892148018  (Learning rate: [0.0125], Time: 3.2082s\n",
            "Epoch: 604, Loss: 0.05548380687832832  (Learning rate: [0.0125], Time: 3.2071s\n",
            "Epoch: 605, Loss: 0.055466122925281525  (Learning rate: [0.0125], Time: 3.2103s\n",
            "Epoch: 606, Loss: 0.05542420968413353  (Learning rate: [0.0125], Time: 3.2112s\n",
            "Epoch: 607, Loss: 0.055406056344509125  (Learning rate: [0.0125], Time: 3.2187s\n",
            "Epoch: 608, Loss: 0.05538292974233627  (Learning rate: [0.0125], Time: 3.1956s\n",
            "Epoch: 609, Loss: 0.05535420402884483  (Learning rate: [0.0125], Time: 3.2095s\n",
            "Epoch: 610, Loss: 0.05533050373196602  (Learning rate: [0.0125], Time: 3.2024s\n",
            "Epoch: 611, Loss: 0.055304087698459625  (Learning rate: [0.0125], Time: 3.1964s\n",
            "Epoch: 612, Loss: 0.05528423190116882  (Learning rate: [0.0125], Time: 3.2006s\n",
            "Epoch: 613, Loss: 0.055255528539419174  (Learning rate: [0.0125], Time: 3.2108s\n",
            "Epoch: 614, Loss: 0.05523303523659706  (Learning rate: [0.0125], Time: 3.2109s\n",
            "Epoch: 615, Loss: 0.05520891025662422  (Learning rate: [0.0125], Time: 3.218s\n",
            "Epoch: 616, Loss: 0.055186573415994644  (Learning rate: [0.0125], Time: 3.2104s\n",
            "Epoch: 617, Loss: 0.05516192689538002  (Learning rate: [0.0125], Time: 3.2026s\n",
            "Epoch: 618, Loss: 0.05514068901538849  (Learning rate: [0.0125], Time: 3.2055s\n",
            "Epoch: 619, Loss: 0.05511711910367012  (Learning rate: [0.0125], Time: 3.2077s\n",
            "Epoch: 620, Loss: 0.05509468913078308  (Learning rate: [0.0125], Time: 3.209s\n",
            "Epoch: 621, Loss: 0.055072885006666183  (Learning rate: [0.0125], Time: 3.2125s\n",
            "Epoch: 622, Loss: 0.05505146458745003  (Learning rate: [0.0125], Time: 3.2186s\n",
            "Epoch: 623, Loss: 0.055028654634952545  (Learning rate: [0.0125], Time: 3.2072s\n",
            "Epoch: 624, Loss: 0.055007774382829666  (Learning rate: [0.0125], Time: 3.2068s\n",
            "Epoch: 625, Loss: 0.05498598888516426  (Learning rate: [0.0125], Time: 3.2008s\n",
            "Epoch: 626, Loss: 0.05496616289019585  (Learning rate: [0.0125], Time: 3.2104s\n",
            "Epoch: 627, Loss: 0.054944634437561035  (Learning rate: [0.0125], Time: 3.1977s\n",
            "Epoch: 628, Loss: 0.05492323637008667  (Learning rate: [0.0125], Time: 3.2167s\n",
            "Epoch: 629, Loss: 0.05490447208285332  (Learning rate: [0.0125], Time: 3.2195s\n",
            "Epoch: 630, Loss: 0.05488366261124611  (Learning rate: [0.0125], Time: 3.2096s\n",
            "Epoch: 631, Loss: 0.05486294627189636  (Learning rate: [0.0125], Time: 3.2052s\n",
            "Epoch: 632, Loss: 0.05483907833695412  (Learning rate: [0.0125], Time: 3.2076s\n",
            "Epoch: 633, Loss: 0.05482131987810135  (Learning rate: [0.0125], Time: 3.2058s\n",
            "Epoch: 634, Loss: 0.05479712784290314  (Learning rate: [0.0125], Time: 3.2042s\n",
            "Epoch: 635, Loss: 0.054779499769210815  (Learning rate: [0.0125], Time: 3.2114s\n",
            "Epoch: 636, Loss: 0.05474582314491272  (Learning rate: [0.0125], Time: 3.2139s\n",
            "Epoch: 637, Loss: 0.054715581238269806  (Learning rate: [0.0125], Time: 3.2158s\n",
            "Epoch: 638, Loss: 0.05504259094595909  (Learning rate: [0.0125], Time: 3.2084s\n",
            "Epoch: 639, Loss: 0.0550854317843914  (Learning rate: [0.0125], Time: 3.2166s\n",
            "Epoch: 640, Loss: 0.05478565767407417  (Learning rate: [0.0125], Time: 3.2059s\n",
            "Epoch: 641, Loss: 0.05480686202645302  (Learning rate: [0.0125], Time: 3.201s\n",
            "Epoch: 642, Loss: 0.054888222366571426  (Learning rate: [0.0125], Time: 3.2096s\n",
            "Epoch: 643, Loss: 0.05467355251312256  (Learning rate: [0.0125], Time: 3.208s\n",
            "Epoch: 644, Loss: 0.05472491681575775  (Learning rate: [0.0125], Time: 3.2169s\n",
            "Epoch: 645, Loss: 0.05471421405673027  (Learning rate: [0.0125], Time: 3.2155s\n",
            "Epoch: 646, Loss: 0.0546041838824749  (Learning rate: [0.0125], Time: 3.2072s\n",
            "Epoch: 647, Loss: 0.05461031571030617  (Learning rate: [0.0125], Time: 3.2031s\n",
            "Epoch: 648, Loss: 0.05462063476443291  (Learning rate: [0.0125], Time: 3.2136s\n",
            "Epoch: 649, Loss: 0.05452637001872063  (Learning rate: [0.0125], Time: 3.2089s\n",
            "Epoch: 650, Loss: 0.054511699825525284  (Learning rate: [0.0125], Time: 3.2108s\n",
            "Epoch: 651, Loss: 0.05452531576156616  (Learning rate: [0.0125], Time: 3.212s\n",
            "Epoch: 652, Loss: 0.05444446578621864  (Learning rate: [0.0125], Time: 3.216s\n",
            "Epoch: 653, Loss: 0.054433342069387436  (Learning rate: [0.0125], Time: 3.2039s\n",
            "Epoch: 654, Loss: 0.054448582231998444  (Learning rate: [0.0125], Time: 3.2071s\n",
            "Epoch: 655, Loss: 0.05436499044299126  (Learning rate: [0.0125], Time: 3.2072s\n",
            "Epoch: 656, Loss: 0.05436281859874725  (Learning rate: [0.0125], Time: 3.2095s\n",
            "Epoch: 657, Loss: 0.0543508380651474  (Learning rate: [0.0125], Time: 3.1999s\n",
            "Epoch: 658, Loss: 0.05429179221391678  (Learning rate: [0.0125], Time: 3.2075s\n",
            "Epoch: 659, Loss: 0.05428892374038696  (Learning rate: [0.0125], Time: 3.2277s\n",
            "Epoch: 660, Loss: 0.054264675825834274  (Learning rate: [0.0125], Time: 3.2032s\n",
            "Epoch: 661, Loss: 0.054222509264945984  (Learning rate: [0.0125], Time: 3.2066s\n",
            "Epoch: 662, Loss: 0.05420855060219765  (Learning rate: [0.0125], Time: 3.2141s\n",
            "Epoch: 663, Loss: 0.05418495461344719  (Learning rate: [0.0125], Time: 3.2065s\n",
            "Epoch: 664, Loss: 0.05415029078722  (Learning rate: [0.0125], Time: 3.203s\n",
            "Epoch: 665, Loss: 0.054131340235471725  (Learning rate: [0.0125], Time: 3.2104s\n",
            "Epoch: 666, Loss: 0.05410933122038841  (Learning rate: [0.0125], Time: 3.2228s\n",
            "Epoch: 667, Loss: 0.054073113948106766  (Learning rate: [0.0125], Time: 3.214s\n",
            "Epoch: 668, Loss: 0.05405508354306221  (Learning rate: [0.0125], Time: 3.1991s\n",
            "Epoch: 669, Loss: 0.054026711732149124  (Learning rate: [0.0125], Time: 3.2026s\n",
            "Epoch: 670, Loss: 0.05399448052048683  (Learning rate: [0.0125], Time: 3.2033s\n",
            "Epoch: 671, Loss: 0.053978338837623596  (Learning rate: [0.0125], Time: 3.2063s\n",
            "Epoch: 672, Loss: 0.05395181104540825  (Learning rate: [0.0125], Time: 3.2152s\n",
            "Epoch: 673, Loss: 0.053922176361083984  (Learning rate: [0.0125], Time: 3.2053s\n",
            "Epoch: 674, Loss: 0.05390297994017601  (Learning rate: [0.0125], Time: 3.212s\n",
            "Epoch: 675, Loss: 0.05388878658413887  (Learning rate: [0.0125], Time: 3.2022s\n",
            "Epoch: 676, Loss: 0.05387024208903313  (Learning rate: [0.0125], Time: 3.2029s\n",
            "Epoch: 677, Loss: 0.05384949594736099  (Learning rate: [0.0125], Time: 3.2079s\n",
            "Epoch: 678, Loss: 0.053827326744794846  (Learning rate: [0.0125], Time: 3.1939s\n",
            "Epoch: 679, Loss: 0.05378478765487671  (Learning rate: [0.0125], Time: 3.2071s\n",
            "Epoch: 680, Loss: 0.053761303424835205  (Learning rate: [0.0125], Time: 3.2022s\n",
            "Epoch: 681, Loss: 0.053750958293676376  (Learning rate: [0.0125], Time: 3.2134s\n",
            "Epoch: 682, Loss: 0.053713180124759674  (Learning rate: [0.0125], Time: 3.2084s\n",
            "Epoch: 683, Loss: 0.053680211305618286  (Learning rate: [0.0125], Time: 3.2069s\n",
            "Epoch: 684, Loss: 0.05365734547376633  (Learning rate: [0.0125], Time: 3.2096s\n",
            "Epoch: 685, Loss: 0.05363777279853821  (Learning rate: [0.0125], Time: 3.2048s\n",
            "Epoch: 686, Loss: 0.05361552536487579  (Learning rate: [0.0125], Time: 3.2151s\n",
            "Epoch: 687, Loss: 0.053589172661304474  (Learning rate: [0.0125], Time: 3.2089s\n",
            "Epoch: 688, Loss: 0.053557537496089935  (Learning rate: [0.0125], Time: 3.2062s\n",
            "Epoch: 689, Loss: 0.05353696644306183  (Learning rate: [0.0125], Time: 3.2163s\n",
            "Epoch: 690, Loss: 0.053510211408138275  (Learning rate: [0.0125], Time: 3.2188s\n",
            "Epoch: 691, Loss: 0.05349189043045044  (Learning rate: [0.0125], Time: 3.2229s\n",
            "Epoch: 692, Loss: 0.05345968157052994  (Learning rate: [0.0125], Time: 3.2099s\n",
            "Epoch: 693, Loss: 0.05342378094792366  (Learning rate: [0.0125], Time: 3.2125s\n",
            "Epoch: 694, Loss: 0.05341383069753647  (Learning rate: [0.0125], Time: 3.2163s\n",
            "Epoch: 695, Loss: 0.05338101461529732  (Learning rate: [0.0125], Time: 3.2052s\n",
            "Epoch: 696, Loss: 0.053376469761133194  (Learning rate: [0.0125], Time: 3.2221s\n",
            "Epoch: 697, Loss: 0.053358204662799835  (Learning rate: [0.0125], Time: 3.2155s\n",
            "Epoch: 698, Loss: 0.05333242565393448  (Learning rate: [0.0125], Time: 3.205s\n",
            "Epoch: 699, Loss: 0.053280316293239594  (Learning rate: [0.0125], Time: 3.2062s\n",
            "Epoch: 700, Loss: 0.05323181673884392  (Learning rate: [0.0125], Time: 3.205s\n",
            "Epoch: 701, Loss: 0.05320693179965019  (Learning rate: [0.0125], Time: 3.2095s\n",
            "Epoch: 702, Loss: 0.05314457789063454  (Learning rate: [0.0125], Time: 3.2072s\n",
            "Epoch: 703, Loss: 0.05309658870100975  (Learning rate: [0.0125], Time: 3.2253s\n",
            "Epoch: 704, Loss: 0.05303880572319031  (Learning rate: [0.0125], Time: 3.2135s\n",
            "Epoch: 705, Loss: 0.053003549575805664  (Learning rate: [0.0125], Time: 3.1955s\n",
            "Epoch: 706, Loss: 0.052959881722927094  (Learning rate: [0.0125], Time: 3.2042s\n",
            "Epoch: 707, Loss: 0.052895963191986084  (Learning rate: [0.0125], Time: 3.2014s\n",
            "Epoch: 708, Loss: 0.05285096913576126  (Learning rate: [0.0125], Time: 3.2071s\n",
            "Epoch: 709, Loss: 0.05278341844677925  (Learning rate: [0.0125], Time: 3.1964s\n",
            "Epoch: 710, Loss: 0.05272078514099121  (Learning rate: [0.0125], Time: 3.2134s\n",
            "Epoch: 711, Loss: 0.052666664123535156  (Learning rate: [0.0125], Time: 3.2396s\n",
            "Epoch: 712, Loss: 0.05260451138019562  (Learning rate: [0.0125], Time: 3.2184s\n",
            "Epoch: 713, Loss: 0.052547525614500046  (Learning rate: [0.0125], Time: 3.204s\n",
            "Epoch: 714, Loss: 0.05248527228832245  (Learning rate: [0.0125], Time: 3.2061s\n",
            "Epoch: 715, Loss: 0.05242696776986122  (Learning rate: [0.0125], Time: 3.2109s\n",
            "Epoch: 716, Loss: 0.05237242579460144  (Learning rate: [0.0125], Time: 3.2063s\n",
            "Epoch: 717, Loss: 0.0523163340985775  (Learning rate: [0.0125], Time: 3.2049s\n",
            "Epoch: 718, Loss: 0.05226268246769905  (Learning rate: [0.0125], Time: 3.2166s\n",
            "Epoch: 719, Loss: 0.05223618075251579  (Learning rate: [0.0125], Time: 3.2193s\n",
            "Epoch: 720, Loss: 0.05219978839159012  (Learning rate: [0.0125], Time: 3.2311s\n",
            "Epoch: 721, Loss: 0.052135273814201355  (Learning rate: [0.0125], Time: 3.21s\n",
            "Epoch: 722, Loss: 0.05208868905901909  (Learning rate: [0.0125], Time: 3.1999s\n",
            "Epoch: 723, Loss: 0.052076827734708786  (Learning rate: [0.0125], Time: 3.1949s\n",
            "Epoch: 724, Loss: 0.05201209336519241  (Learning rate: [0.0125], Time: 3.2028s\n",
            "Epoch: 725, Loss: 0.05193901062011719  (Learning rate: [0.0125], Time: 3.2018s\n",
            "Epoch: 726, Loss: 0.051923952996730804  (Learning rate: [0.0125], Time: 3.2153s\n",
            "Epoch: 727, Loss: 0.05190040171146393  (Learning rate: [0.0125], Time: 3.2146s\n",
            "Epoch: 728, Loss: 0.05181475356221199  (Learning rate: [0.0125], Time: 3.2151s\n",
            "Epoch: 729, Loss: 0.05178389325737953  (Learning rate: [0.0125], Time: 3.2059s\n",
            "Epoch: 730, Loss: 0.051771290600299835  (Learning rate: [0.0125], Time: 3.1992s\n",
            "Epoch: 731, Loss: 0.051690492779016495  (Learning rate: [0.0125], Time: 3.2048s\n",
            "Epoch: 732, Loss: 0.051654472947120667  (Learning rate: [0.0125], Time: 3.2062s\n",
            "Epoch: 733, Loss: 0.051640644669532776  (Learning rate: [0.0125], Time: 3.2104s\n",
            "Epoch: 734, Loss: 0.051578227430582047  (Learning rate: [0.0125], Time: 3.2157s\n",
            "Epoch: 735, Loss: 0.05154810845851898  (Learning rate: [0.0125], Time: 3.1895s\n",
            "Epoch: 736, Loss: 0.05152101814746857  (Learning rate: [0.0125], Time: 3.1983s\n",
            "Epoch: 737, Loss: 0.05147524178028107  (Learning rate: [0.0125], Time: 3.1883s\n",
            "Epoch: 738, Loss: 0.05144428461790085  (Learning rate: [0.0125], Time: 3.1946s\n",
            "Epoch: 739, Loss: 0.05141754820942879  (Learning rate: [0.0125], Time: 3.1918s\n",
            "Epoch: 740, Loss: 0.0513688400387764  (Learning rate: [0.0125], Time: 3.1929s\n",
            "Epoch: 741, Loss: 0.05137057229876518  (Learning rate: [0.0125], Time: 3.2105s\n",
            "Epoch: 742, Loss: 0.05134822800755501  (Learning rate: [0.0125], Time: 3.2061s\n",
            "Epoch: 743, Loss: 0.05129629001021385  (Learning rate: [0.0125], Time: 3.175s\n",
            "Epoch: 744, Loss: 0.05127633363008499  (Learning rate: [0.0125], Time: 3.1919s\n",
            "Epoch: 745, Loss: 0.051231637597084045  (Learning rate: [0.0125], Time: 3.1869s\n",
            "Epoch: 746, Loss: 0.051229290664196014  (Learning rate: [0.0125], Time: 3.1947s\n",
            "Epoch: 747, Loss: 0.05119284614920616  (Learning rate: [0.0125], Time: 3.1836s\n",
            "Epoch: 748, Loss: 0.051147714257240295  (Learning rate: [0.0125], Time: 3.177s\n",
            "Epoch: 749, Loss: 0.05114966630935669  (Learning rate: [0.0125], Time: 3.1773s\n",
            "Epoch: 750, Loss: 0.05111430957913399  (Learning rate: [0.0125], Time: 3.1821s\n",
            "Epoch: 751, Loss: 0.0510982871055603  (Learning rate: [0.0125], Time: 3.184s\n",
            "Epoch: 752, Loss: 0.051065146923065186  (Learning rate: [0.0125], Time: 3.1827s\n",
            "Epoch: 753, Loss: 0.05103256553411484  (Learning rate: [0.0125], Time: 3.1799s\n",
            "Epoch: 754, Loss: 0.051022227853536606  (Learning rate: [0.0125], Time: 3.1793s\n",
            "Epoch: 755, Loss: 0.05100442096590996  (Learning rate: [0.0125], Time: 3.1889s\n",
            "Epoch: 756, Loss: 0.050982069224119186  (Learning rate: [0.0125], Time: 3.1908s\n",
            "Epoch: 757, Loss: 0.05095644295215607  (Learning rate: [0.0125], Time: 3.1862s\n",
            "Epoch: 758, Loss: 0.05093425139784813  (Learning rate: [0.0125], Time: 3.1966s\n",
            "Epoch: 759, Loss: 0.05091739445924759  (Learning rate: [0.0125], Time: 3.206s\n",
            "Epoch: 760, Loss: 0.05090182274580002  (Learning rate: [0.0125], Time: 3.201s\n",
            "Epoch: 761, Loss: 0.050878338515758514  (Learning rate: [0.0125], Time: 3.188s\n",
            "Epoch: 762, Loss: 0.0508575402200222  (Learning rate: [0.0125], Time: 3.1838s\n",
            "Epoch: 763, Loss: 0.05083636939525604  (Learning rate: [0.0125], Time: 3.1931s\n",
            "Epoch: 764, Loss: 0.05081746727228165  (Learning rate: [0.0125], Time: 3.1939s\n",
            "Epoch: 765, Loss: 0.05080742761492729  (Learning rate: [0.0125], Time: 3.189s\n",
            "Epoch: 766, Loss: 0.05078617110848427  (Learning rate: [0.0125], Time: 3.1841s\n",
            "Epoch: 767, Loss: 0.05077367648482323  (Learning rate: [0.0125], Time: 3.2078s\n",
            "Epoch: 768, Loss: 0.05075334385037422  (Learning rate: [0.0125], Time: 3.2279s\n",
            "Epoch: 769, Loss: 0.05074556916952133  (Learning rate: [0.0125], Time: 3.1974s\n",
            "Epoch: 770, Loss: 0.05074016749858856  (Learning rate: [0.0125], Time: 3.1989s\n",
            "Epoch: 771, Loss: 0.0507352352142334  (Learning rate: [0.0125], Time: 3.2009s\n",
            "Epoch: 772, Loss: 0.050735823810100555  (Learning rate: [0.0125], Time: 3.2009s\n",
            "Epoch: 773, Loss: 0.050732024013996124  (Learning rate: [0.0125], Time: 3.2019s\n",
            "Epoch: 774, Loss: 0.05070647597312927  (Learning rate: [0.0125], Time: 3.1983s\n",
            "Epoch: 775, Loss: 0.05068283528089523  (Learning rate: [0.0125], Time: 3.2047s\n",
            "Epoch: 776, Loss: 0.05062895640730858  (Learning rate: [0.0125], Time: 3.2147s\n",
            "Epoch: 777, Loss: 0.05061086267232895  (Learning rate: [0.0125], Time: 3.2068s\n",
            "Epoch: 778, Loss: 0.050598446279764175  (Learning rate: [0.0125], Time: 3.1959s\n",
            "Epoch: 779, Loss: 0.05058791860938072  (Learning rate: [0.0125], Time: 3.1934s\n",
            "Epoch: 780, Loss: 0.05057314783334732  (Learning rate: [0.0125], Time: 3.2045s\n",
            "Epoch: 781, Loss: 0.050555646419525146  (Learning rate: [0.0125], Time: 3.1953s\n",
            "Epoch: 782, Loss: 0.050550200045108795  (Learning rate: [0.0125], Time: 3.1977s\n",
            "Epoch: 783, Loss: 0.05054299160838127  (Learning rate: [0.0125], Time: 3.2235s\n",
            "Epoch: 784, Loss: 0.05052471160888672  (Learning rate: [0.0125], Time: 3.2123s\n",
            "Epoch: 785, Loss: 0.050498172640800476  (Learning rate: [0.0125], Time: 3.2084s\n",
            "Epoch: 786, Loss: 0.05048541724681854  (Learning rate: [0.0125], Time: 3.2063s\n",
            "Epoch: 787, Loss: 0.05047346651554108  (Learning rate: [0.0125], Time: 3.2011s\n",
            "Epoch: 788, Loss: 0.05046718195080757  (Learning rate: [0.0125], Time: 3.1944s\n",
            "Epoch: 789, Loss: 0.05046481266617775  (Learning rate: [0.0125], Time: 3.2019s\n",
            "Epoch: 790, Loss: 0.05046265199780464  (Learning rate: [0.0125], Time: 3.203s\n",
            "Epoch: 791, Loss: 0.05044673755764961  (Learning rate: [0.0125], Time: 3.2022s\n",
            "Epoch: 792, Loss: 0.05041108652949333  (Learning rate: [0.0125], Time: 3.193s\n",
            "Epoch: 793, Loss: 0.05040329694747925  (Learning rate: [0.0125], Time: 3.2008s\n",
            "Epoch: 794, Loss: 0.05040605366230011  (Learning rate: [0.0125], Time: 3.1974s\n",
            "Epoch: 795, Loss: 0.05038931593298912  (Learning rate: [0.0125], Time: 3.2062s\n",
            "Epoch: 796, Loss: 0.050392843782901764  (Learning rate: [0.0125], Time: 3.2026s\n",
            "Epoch: 797, Loss: 0.05036447197198868  (Learning rate: [0.0125], Time: 3.2084s\n",
            "Epoch: 798, Loss: 0.05034578964114189  (Learning rate: [0.0125], Time: 3.2043s\n",
            "Epoch: 799, Loss: 0.05032724514603615  (Learning rate: [0.0125], Time: 3.2177s\n",
            "Epoch: 800, Loss: 0.0503152459859848  (Learning rate: [0.0125], Time: 3.1988s\n",
            "Epoch: 801, Loss: 0.05031663551926613  (Learning rate: [0.0125], Time: 3.202s\n",
            "Epoch: 802, Loss: 0.05028687044978142  (Learning rate: [0.0125], Time: 3.2006s\n",
            "Epoch: 803, Loss: 0.050270259380340576  (Learning rate: [0.0125], Time: 3.209s\n",
            "Epoch: 804, Loss: 0.05024873465299606  (Learning rate: [0.0125], Time: 3.1983s\n",
            "Epoch: 805, Loss: 0.05024163797497749  (Learning rate: [0.0125], Time: 3.1938s\n",
            "Epoch: 806, Loss: 0.05022789537906647  (Learning rate: [0.0125], Time: 3.2104s\n",
            "Epoch: 807, Loss: 0.05020958185195923  (Learning rate: [0.0125], Time: 3.1993s\n",
            "Epoch: 808, Loss: 0.05019893869757652  (Learning rate: [0.0125], Time: 3.1959s\n",
            "Epoch: 809, Loss: 0.050184085965156555  (Learning rate: [0.0125], Time: 3.2229s\n",
            "Epoch: 810, Loss: 0.050169676542282104  (Learning rate: [0.0125], Time: 3.2097s\n",
            "Epoch: 811, Loss: 0.05016224458813667  (Learning rate: [0.0125], Time: 3.1983s\n",
            "Epoch: 812, Loss: 0.050161659717559814  (Learning rate: [0.0125], Time: 3.2069s\n",
            "Epoch: 813, Loss: 0.0501580610871315  (Learning rate: [0.0125], Time: 3.1916s\n",
            "Epoch: 814, Loss: 0.050153698772192  (Learning rate: [0.0125], Time: 3.2168s\n",
            "Epoch: 815, Loss: 0.05015283450484276  (Learning rate: [0.0125], Time: 3.2078s\n",
            "Epoch: 816, Loss: 0.05014413595199585  (Learning rate: [0.0125], Time: 3.2059s\n",
            "Epoch: 817, Loss: 0.05013422667980194  (Learning rate: [0.0125], Time: 3.1984s\n",
            "Epoch: 818, Loss: 0.05012134835124016  (Learning rate: [0.0125], Time: 3.2513s\n",
            "Epoch: 819, Loss: 0.05007597431540489  (Learning rate: [0.0125], Time: 3.1877s\n",
            "Epoch: 820, Loss: 0.05013781785964966  (Learning rate: [0.0125], Time: 3.1777s\n",
            "Epoch: 821, Loss: 0.0501299686729908  (Learning rate: [0.0125], Time: 3.1829s\n",
            "Epoch: 822, Loss: 0.05006015673279762  (Learning rate: [0.0125], Time: 3.1931s\n",
            "Epoch: 823, Loss: 0.05010801553726196  (Learning rate: [0.0125], Time: 3.208s\n",
            "Epoch: 824, Loss: 0.05004086717963219  (Learning rate: [0.0125], Time: 3.1994s\n",
            "Epoch: 825, Loss: 0.05004569888114929  (Learning rate: [0.0125], Time: 3.1919s\n",
            "Epoch: 826, Loss: 0.04999375343322754  (Learning rate: [0.0125], Time: 3.1852s\n",
            "Epoch: 827, Loss: 0.05000809207558632  (Learning rate: [0.0125], Time: 3.1855s\n",
            "Epoch: 828, Loss: 0.04993744194507599  (Learning rate: [0.0125], Time: 3.1829s\n",
            "Epoch: 829, Loss: 0.04997505620121956  (Learning rate: [0.0125], Time: 3.1866s\n",
            "Epoch: 830, Loss: 0.04990550875663757  (Learning rate: [0.0125], Time: 3.1995s\n",
            "Epoch: 831, Loss: 0.04989556595683098  (Learning rate: [0.0125], Time: 3.1968s\n",
            "Epoch: 832, Loss: 0.04987786337733269  (Learning rate: [0.0125], Time: 3.1804s\n",
            "Epoch: 833, Loss: 0.049851421266794205  (Learning rate: [0.0125], Time: 3.184s\n",
            "Epoch: 834, Loss: 0.04982325807213783  (Learning rate: [0.0125], Time: 3.1736s\n",
            "Epoch: 835, Loss: 0.04981919378042221  (Learning rate: [0.0125], Time: 3.1796s\n",
            "Epoch: 836, Loss: 0.049777109175920486  (Learning rate: [0.0125], Time: 3.1857s\n",
            "Epoch: 837, Loss: 0.049758244305849075  (Learning rate: [0.0125], Time: 3.1767s\n",
            "Epoch: 838, Loss: 0.04974847286939621  (Learning rate: [0.0125], Time: 3.1823s\n",
            "Epoch: 839, Loss: 0.04971727728843689  (Learning rate: [0.0125], Time: 3.1887s\n",
            "Epoch: 840, Loss: 0.04972396790981293  (Learning rate: [0.0125], Time: 3.1915s\n",
            "Epoch: 841, Loss: 0.049690548330545425  (Learning rate: [0.0125], Time: 3.1832s\n",
            "Epoch: 842, Loss: 0.04966914653778076  (Learning rate: [0.0125], Time: 3.1867s\n",
            "Epoch: 843, Loss: 0.04964913800358772  (Learning rate: [0.0125], Time: 3.2176s\n",
            "Epoch: 844, Loss: 0.049617938697338104  (Learning rate: [0.0125], Time: 3.2041s\n",
            "Epoch: 845, Loss: 0.04960733652114868  (Learning rate: [0.0125], Time: 3.202s\n",
            "Epoch: 846, Loss: 0.04958898201584816  (Learning rate: [0.0125], Time: 3.2074s\n",
            "Epoch: 847, Loss: 0.04957665130496025  (Learning rate: [0.0125], Time: 3.2091s\n",
            "Epoch: 848, Loss: 0.04955073446035385  (Learning rate: [0.0125], Time: 3.2163s\n",
            "Epoch: 849, Loss: 0.04952890798449516  (Learning rate: [0.0125], Time: 3.2023s\n",
            "Epoch: 850, Loss: 0.049505140632390976  (Learning rate: [0.0125], Time: 3.2003s\n",
            "Epoch: 851, Loss: 0.04948853701353073  (Learning rate: [0.0125], Time: 3.2214s\n",
            "Epoch: 852, Loss: 0.04947506636381149  (Learning rate: [0.0125], Time: 3.2011s\n",
            "Epoch: 853, Loss: 0.04945976659655571  (Learning rate: [0.0125], Time: 3.2088s\n",
            "Epoch: 854, Loss: 0.04945451021194458  (Learning rate: [0.0125], Time: 3.2023s\n",
            "Epoch: 855, Loss: 0.049402642995119095  (Learning rate: [0.0125], Time: 3.2129s\n",
            "Epoch: 856, Loss: 0.04937881976366043  (Learning rate: [0.0125], Time: 3.212s\n",
            "Epoch: 857, Loss: 0.049359988421201706  (Learning rate: [0.0125], Time: 3.202s\n",
            "Epoch: 858, Loss: 0.04934235289692879  (Learning rate: [0.0125], Time: 3.2003s\n",
            "Epoch: 859, Loss: 0.0493306964635849  (Learning rate: [0.0125], Time: 3.2029s\n",
            "Epoch: 860, Loss: 0.049310725182294846  (Learning rate: [0.0125], Time: 3.2084s\n",
            "Epoch: 861, Loss: 0.04930929094552994  (Learning rate: [0.0125], Time: 3.21s\n",
            "Epoch: 862, Loss: 0.04929191991686821  (Learning rate: [0.0125], Time: 3.2033s\n",
            "Epoch: 863, Loss: 0.04930159077048302  (Learning rate: [0.0125], Time: 3.2172s\n",
            "Epoch: 864, Loss: 0.04932422563433647  (Learning rate: [0.0125], Time: 3.2068s\n",
            "Epoch: 865, Loss: 0.049271997064352036  (Learning rate: [0.0125], Time: 3.2063s\n",
            "Epoch: 866, Loss: 0.04926688224077225  (Learning rate: [0.0125], Time: 3.1974s\n",
            "Epoch: 867, Loss: 0.049272794276475906  (Learning rate: [0.0125], Time: 3.1994s\n",
            "Epoch: 868, Loss: 0.04921869561076164  (Learning rate: [0.0125], Time: 3.2056s\n",
            "Epoch: 869, Loss: 0.049214836210012436  (Learning rate: [0.0125], Time: 3.2092s\n",
            "Epoch: 870, Loss: 0.04919198155403137  (Learning rate: [0.0125], Time: 3.2113s\n",
            "Epoch: 871, Loss: 0.049145109951496124  (Learning rate: [0.0125], Time: 3.215s\n",
            "Epoch: 872, Loss: 0.049087345600128174  (Learning rate: [0.0125], Time: 3.2115s\n",
            "Epoch: 873, Loss: 0.049046508967876434  (Learning rate: [0.0125], Time: 3.2043s\n",
            "Epoch: 874, Loss: 0.049039799720048904  (Learning rate: [0.0125], Time: 3.2101s\n",
            "Epoch: 875, Loss: 0.04900366812944412  (Learning rate: [0.0125], Time: 3.2087s\n",
            "Epoch: 876, Loss: 0.048971496522426605  (Learning rate: [0.0125], Time: 3.2089s\n",
            "Epoch: 877, Loss: 0.048908766359090805  (Learning rate: [0.0125], Time: 3.202s\n",
            "Epoch: 878, Loss: 0.04889053478837013  (Learning rate: [0.0125], Time: 3.2097s\n",
            "Epoch: 879, Loss: 0.048874422907829285  (Learning rate: [0.0125], Time: 3.2096s\n",
            "Epoch: 880, Loss: 0.04883187636733055  (Learning rate: [0.0125], Time: 3.212s\n",
            "Epoch: 881, Loss: 0.04879181832075119  (Learning rate: [0.0125], Time: 3.1855s\n",
            "Epoch: 882, Loss: 0.04875136539340019  (Learning rate: [0.0125], Time: 3.1912s\n",
            "Epoch: 883, Loss: 0.048723313957452774  (Learning rate: [0.0125], Time: 3.2028s\n",
            "Epoch: 884, Loss: 0.048691947013139725  (Learning rate: [0.0125], Time: 3.2011s\n",
            "Epoch: 885, Loss: 0.04866408556699753  (Learning rate: [0.0125], Time: 3.2161s\n",
            "Epoch: 886, Loss: 0.04863443598151207  (Learning rate: [0.0125], Time: 3.2253s\n",
            "Epoch: 887, Loss: 0.04860544577240944  (Learning rate: [0.0125], Time: 3.2034s\n",
            "Epoch: 888, Loss: 0.04856983572244644  (Learning rate: [0.0125], Time: 3.1867s\n",
            "Epoch: 889, Loss: 0.04853281006217003  (Learning rate: [0.0125], Time: 3.187s\n",
            "Epoch: 890, Loss: 0.04850462079048157  (Learning rate: [0.0125], Time: 3.2039s\n",
            "Epoch: 891, Loss: 0.048473868519067764  (Learning rate: [0.0125], Time: 3.187s\n",
            "Epoch: 892, Loss: 0.048445507884025574  (Learning rate: [0.0125], Time: 3.1929s\n",
            "Epoch: 893, Loss: 0.048423342406749725  (Learning rate: [0.0125], Time: 3.2002s\n",
            "Epoch: 894, Loss: 0.04840441420674324  (Learning rate: [0.0125], Time: 3.2039s\n",
            "Epoch: 895, Loss: 0.04839440807700157  (Learning rate: [0.0125], Time: 3.202s\n",
            "Epoch: 896, Loss: 0.0483870729804039  (Learning rate: [0.0125], Time: 3.209s\n",
            "Epoch: 897, Loss: 0.04836227744817734  (Learning rate: [0.0125], Time: 3.1917s\n",
            "Epoch: 898, Loss: 0.04833083599805832  (Learning rate: [0.0125], Time: 3.1819s\n",
            "Epoch: 899, Loss: 0.048311587423086166  (Learning rate: [0.0125], Time: 3.1858s\n",
            "Epoch: 900, Loss: 0.04834476858377457  (Learning rate: [0.00625], Time: 3.1831s\n",
            "Epoch: 901, Loss: 0.04842875525355339  (Learning rate: [0.00625], Time: 3.1815s\n",
            "Epoch: 902, Loss: 0.048198360949754715  (Learning rate: [0.00625], Time: 3.1824s\n",
            "Epoch: 903, Loss: 0.04834474250674248  (Learning rate: [0.00625], Time: 3.1919s\n",
            "Epoch: 904, Loss: 0.0481756255030632  (Learning rate: [0.00625], Time: 3.1924s\n",
            "Epoch: 905, Loss: 0.04827220365405083  (Learning rate: [0.00625], Time: 3.183s\n",
            "Epoch: 906, Loss: 0.04815847426652908  (Learning rate: [0.00625], Time: 3.1861s\n",
            "Epoch: 907, Loss: 0.048209309577941895  (Learning rate: [0.00625], Time: 3.1915s\n",
            "Epoch: 908, Loss: 0.04813192039728165  (Learning rate: [0.00625], Time: 3.2053s\n",
            "Epoch: 909, Loss: 0.04815821349620819  (Learning rate: [0.00625], Time: 3.1978s\n",
            "Epoch: 910, Loss: 0.0481049083173275  (Learning rate: [0.00625], Time: 3.2154s\n",
            "Epoch: 911, Loss: 0.04811222851276398  (Learning rate: [0.00625], Time: 3.2165s\n",
            "Epoch: 912, Loss: 0.048075154423713684  (Learning rate: [0.00625], Time: 3.1912s\n",
            "Epoch: 913, Loss: 0.048072125762701035  (Learning rate: [0.00625], Time: 3.1873s\n",
            "Epoch: 914, Loss: 0.048043109476566315  (Learning rate: [0.00625], Time: 3.2055s\n",
            "Epoch: 915, Loss: 0.04803474619984627  (Learning rate: [0.00625], Time: 3.2142s\n",
            "Epoch: 916, Loss: 0.04801032692193985  (Learning rate: [0.00625], Time: 3.2054s\n",
            "Epoch: 917, Loss: 0.04799637570977211  (Learning rate: [0.00625], Time: 3.2064s\n",
            "Epoch: 918, Loss: 0.04797579348087311  (Learning rate: [0.00625], Time: 3.1835s\n",
            "Epoch: 919, Loss: 0.04795482009649277  (Learning rate: [0.00625], Time: 3.2904s\n",
            "Epoch: 920, Loss: 0.0480131059885025  (Learning rate: [0.00625], Time: 3.1864s\n",
            "Epoch: 921, Loss: 0.04812716692686081  (Learning rate: [0.00625], Time: 3.1969s\n",
            "Epoch: 922, Loss: 0.047955360263586044  (Learning rate: [0.00625], Time: 3.2044s\n",
            "Epoch: 923, Loss: 0.048014044761657715  (Learning rate: [0.00625], Time: 3.1964s\n",
            "Epoch: 924, Loss: 0.04795440286397934  (Learning rate: [0.00625], Time: 3.1978s\n",
            "Epoch: 925, Loss: 0.047927334904670715  (Learning rate: [0.00625], Time: 3.1932s\n",
            "Epoch: 926, Loss: 0.04793939366936684  (Learning rate: [0.00625], Time: 3.1844s\n",
            "Epoch: 927, Loss: 0.04789426177740097  (Learning rate: [0.00625], Time: 3.2s\n",
            "Epoch: 928, Loss: 0.047891076654195786  (Learning rate: [0.00625], Time: 3.2047s\n",
            "Epoch: 929, Loss: 0.04786468297243118  (Learning rate: [0.00625], Time: 3.1998s\n",
            "Epoch: 930, Loss: 0.04785958305001259  (Learning rate: [0.00625], Time: 3.1859s\n",
            "Epoch: 931, Loss: 0.047829531133174896  (Learning rate: [0.00625], Time: 3.199s\n",
            "Epoch: 932, Loss: 0.04782497510313988  (Learning rate: [0.00625], Time: 3.1902s\n",
            "Epoch: 933, Loss: 0.04779643937945366  (Learning rate: [0.00625], Time: 3.1892s\n",
            "Epoch: 934, Loss: 0.047792740166187286  (Learning rate: [0.00625], Time: 3.2442s\n",
            "Epoch: 935, Loss: 0.04776952415704727  (Learning rate: [0.00625], Time: 3.2019s\n",
            "Epoch: 936, Loss: 0.047754041850566864  (Learning rate: [0.00625], Time: 3.1949s\n",
            "Epoch: 937, Loss: 0.04774767905473709  (Learning rate: [0.00625], Time: 3.1972s\n",
            "Epoch: 938, Loss: 0.04772021993994713  (Learning rate: [0.00625], Time: 3.1921s\n",
            "Epoch: 939, Loss: 0.04772021993994713  (Learning rate: [0.00625], Time: 3.1971s\n",
            "Epoch: 940, Loss: 0.047695182263851166  (Learning rate: [0.00625], Time: 3.1981s\n",
            "Epoch: 941, Loss: 0.04768504574894905  (Learning rate: [0.00625], Time: 3.1955s\n",
            "Epoch: 942, Loss: 0.047672078013420105  (Learning rate: [0.00625], Time: 3.1928s\n",
            "Epoch: 943, Loss: 0.04765551909804344  (Learning rate: [0.00625], Time: 3.2s\n",
            "Epoch: 944, Loss: 0.047641728073358536  (Learning rate: [0.00625], Time: 3.2062s\n",
            "Epoch: 945, Loss: 0.047628939151763916  (Learning rate: [0.00625], Time: 3.2s\n",
            "Epoch: 946, Loss: 0.04761344939470291  (Learning rate: [0.00625], Time: 3.1955s\n",
            "Epoch: 947, Loss: 0.04760124161839485  (Learning rate: [0.00625], Time: 3.1976s\n",
            "Epoch: 948, Loss: 0.04758719727396965  (Learning rate: [0.00625], Time: 3.1969s\n",
            "Epoch: 949, Loss: 0.047572728246450424  (Learning rate: [0.00625], Time: 3.21s\n",
            "Epoch: 950, Loss: 0.04756123200058937  (Learning rate: [0.00625], Time: 3.2019s\n",
            "Epoch: 951, Loss: 0.047544997185468674  (Learning rate: [0.00625], Time: 3.2123s\n",
            "Epoch: 952, Loss: 0.04753292351961136  (Learning rate: [0.00625], Time: 3.2068s\n",
            "Epoch: 953, Loss: 0.04751657322049141  (Learning rate: [0.00625], Time: 3.2066s\n",
            "Epoch: 954, Loss: 0.04751389101147652  (Learning rate: [0.00625], Time: 3.2039s\n",
            "Epoch: 955, Loss: 0.04750237986445427  (Learning rate: [0.00625], Time: 3.1971s\n",
            "Epoch: 956, Loss: 0.0474865660071373  (Learning rate: [0.00625], Time: 3.201s\n",
            "Epoch: 957, Loss: 0.04747376590967178  (Learning rate: [0.00625], Time: 3.1952s\n",
            "Epoch: 958, Loss: 0.04745873436331749  (Learning rate: [0.00625], Time: 3.1999s\n",
            "Epoch: 959, Loss: 0.04744656756520271  (Learning rate: [0.00625], Time: 3.2192s\n",
            "Epoch: 960, Loss: 0.04743245989084244  (Learning rate: [0.00625], Time: 3.2112s\n",
            "Epoch: 961, Loss: 0.04741693660616875  (Learning rate: [0.00625], Time: 3.2059s\n",
            "Epoch: 962, Loss: 0.04740661755204201  (Learning rate: [0.00625], Time: 3.2004s\n",
            "Epoch: 963, Loss: 0.04738997668027878  (Learning rate: [0.00625], Time: 3.2076s\n",
            "Epoch: 964, Loss: 0.04737798124551773  (Learning rate: [0.00625], Time: 3.2066s\n",
            "Epoch: 965, Loss: 0.04736334830522537  (Learning rate: [0.00625], Time: 3.1969s\n",
            "Epoch: 966, Loss: 0.047351937741041183  (Learning rate: [0.00625], Time: 3.2179s\n",
            "Epoch: 967, Loss: 0.04733605310320854  (Learning rate: [0.00625], Time: 3.2091s\n",
            "Epoch: 968, Loss: 0.04732350632548332  (Learning rate: [0.00625], Time: 3.201s\n",
            "Epoch: 969, Loss: 0.0473097525537014  (Learning rate: [0.00625], Time: 3.2002s\n",
            "Epoch: 970, Loss: 0.0472961962223053  (Learning rate: [0.00625], Time: 3.2071s\n",
            "Epoch: 971, Loss: 0.04728164151310921  (Learning rate: [0.00625], Time: 3.2048s\n",
            "Epoch: 972, Loss: 0.047267235815525055  (Learning rate: [0.00625], Time: 3.1985s\n",
            "Epoch: 973, Loss: 0.04724863916635513  (Learning rate: [0.00625], Time: 3.2049s\n",
            "Epoch: 974, Loss: 0.04723417013883591  (Learning rate: [0.00625], Time: 3.2173s\n",
            "Epoch: 975, Loss: 0.04722151532769203  (Learning rate: [0.00625], Time: 3.2182s\n",
            "Epoch: 976, Loss: 0.04719939082860947  (Learning rate: [0.00625], Time: 3.2017s\n",
            "Epoch: 977, Loss: 0.04718821123242378  (Learning rate: [0.00625], Time: 3.203s\n",
            "Epoch: 978, Loss: 0.04717497155070305  (Learning rate: [0.00625], Time: 3.1938s\n",
            "Epoch: 979, Loss: 0.0471537783741951  (Learning rate: [0.00625], Time: 3.198s\n",
            "Epoch: 980, Loss: 0.047145456075668335  (Learning rate: [0.00625], Time: 3.1898s\n",
            "Epoch: 981, Loss: 0.047127943485975266  (Learning rate: [0.00625], Time: 3.2016s\n",
            "Epoch: 982, Loss: 0.04711301997303963  (Learning rate: [0.00625], Time: 3.2118s\n",
            "Epoch: 983, Loss: 0.04709961265325546  (Learning rate: [0.00625], Time: 3.2168s\n",
            "Epoch: 984, Loss: 0.04708148166537285  (Learning rate: [0.00625], Time: 3.2102s\n",
            "Epoch: 985, Loss: 0.04706833139061928  (Learning rate: [0.00625], Time: 3.2064s\n",
            "Epoch: 986, Loss: 0.04705274477601051  (Learning rate: [0.00625], Time: 3.197s\n",
            "Epoch: 987, Loss: 0.04703834280371666  (Learning rate: [0.00625], Time: 3.1877s\n",
            "Epoch: 988, Loss: 0.047024764120578766  (Learning rate: [0.00625], Time: 3.1903s\n",
            "Epoch: 989, Loss: 0.047008439898490906  (Learning rate: [0.00625], Time: 3.2041s\n",
            "Epoch: 990, Loss: 0.046994898468256  (Learning rate: [0.00625], Time: 3.2033s\n",
            "Epoch: 991, Loss: 0.04697927460074425  (Learning rate: [0.00625], Time: 3.1987s\n",
            "Epoch: 992, Loss: 0.04696458578109741  (Learning rate: [0.00625], Time: 3.1934s\n",
            "Epoch: 993, Loss: 0.04695085436105728  (Learning rate: [0.00625], Time: 3.2101s\n",
            "Epoch: 994, Loss: 0.04693545028567314  (Learning rate: [0.00625], Time: 3.1989s\n",
            "Epoch: 995, Loss: 0.04692123830318451  (Learning rate: [0.00625], Time: 3.2024s\n",
            "Epoch: 996, Loss: 0.04690692201256752  (Learning rate: [0.00625], Time: 3.2029s\n",
            "Epoch: 997, Loss: 0.04689206928014755  (Learning rate: [0.00625], Time: 3.2052s\n",
            "Epoch: 998, Loss: 0.04687800630927086  (Learning rate: [0.00625], Time: 3.2188s\n",
            "Epoch: 999, Loss: 0.0468638651072979  (Learning rate: [0.00625], Time: 3.2156s\n",
            "Epoch: 1000, Loss: 0.046849239617586136  (Learning rate: [0.00625], Time: 3.2054s\n",
            "Epoch: 1001, Loss: 0.04683505371212959  (Learning rate: [0.00625], Time: 3.1965s\n",
            "Epoch: 1002, Loss: 0.04682081565260887  (Learning rate: [0.00625], Time: 3.1896s\n",
            "Epoch: 1003, Loss: 0.046806443482637405  (Learning rate: [0.00625], Time: 3.1975s\n",
            "Epoch: 1004, Loss: 0.046792421489953995  (Learning rate: [0.00625], Time: 3.201s\n",
            "Epoch: 1005, Loss: 0.04677833244204521  (Learning rate: [0.00625], Time: 3.1941s\n",
            "Epoch: 1006, Loss: 0.04676410183310509  (Learning rate: [0.00625], Time: 3.2195s\n",
            "Epoch: 1007, Loss: 0.046750057488679886  (Learning rate: [0.00625], Time: 3.2187s\n",
            "Epoch: 1008, Loss: 0.046736206859350204  (Learning rate: [0.00625], Time: 3.2252s\n",
            "Epoch: 1009, Loss: 0.04672219231724739  (Learning rate: [0.00625], Time: 3.1896s\n",
            "Epoch: 1010, Loss: 0.046708106994628906  (Learning rate: [0.00625], Time: 3.1851s\n",
            "Epoch: 1011, Loss: 0.046694375574588776  (Learning rate: [0.00625], Time: 3.2472s\n",
            "Epoch: 1012, Loss: 0.04668060317635536  (Learning rate: [0.00625], Time: 3.1983s\n",
            "Epoch: 1013, Loss: 0.046666715294122696  (Learning rate: [0.00625], Time: 3.194s\n",
            "Epoch: 1014, Loss: 0.04665283486247063  (Learning rate: [0.00625], Time: 3.2176s\n",
            "Epoch: 1015, Loss: 0.04663922265172005  (Learning rate: [0.00625], Time: 3.2058s\n",
            "Epoch: 1016, Loss: 0.0466255247592926  (Learning rate: [0.00625], Time: 3.1987s\n",
            "Epoch: 1017, Loss: 0.04661202430725098  (Learning rate: [0.00625], Time: 3.1958s\n",
            "Epoch: 1018, Loss: 0.0465984120965004  (Learning rate: [0.00625], Time: 3.2014s\n",
            "Epoch: 1019, Loss: 0.04658512771129608  (Learning rate: [0.00625], Time: 3.2135s\n",
            "Epoch: 1020, Loss: 0.046571776270866394  (Learning rate: [0.00625], Time: 3.198s\n",
            "Epoch: 1021, Loss: 0.04655831679701805  (Learning rate: [0.00625], Time: 3.2151s\n",
            "Epoch: 1022, Loss: 0.04654565826058388  (Learning rate: [0.00625], Time: 3.236s\n",
            "Epoch: 1023, Loss: 0.04653449356555939  (Learning rate: [0.00625], Time: 3.2048s\n",
            "Epoch: 1024, Loss: 0.04652196168899536  (Learning rate: [0.00625], Time: 3.2208s\n",
            "Epoch: 1025, Loss: 0.046510886400938034  (Learning rate: [0.00625], Time: 3.1977s\n",
            "Epoch: 1026, Loss: 0.046497371047735214  (Learning rate: [0.00625], Time: 3.1994s\n",
            "Epoch: 1027, Loss: 0.04648418724536896  (Learning rate: [0.00625], Time: 3.1984s\n",
            "Epoch: 1028, Loss: 0.04647291079163551  (Learning rate: [0.00625], Time: 3.2053s\n",
            "Epoch: 1029, Loss: 0.046461693942546844  (Learning rate: [0.00625], Time: 3.2129s\n",
            "Epoch: 1030, Loss: 0.04644787311553955  (Learning rate: [0.00625], Time: 3.2038s\n",
            "Epoch: 1031, Loss: 0.04643455147743225  (Learning rate: [0.00625], Time: 3.189s\n",
            "Epoch: 1032, Loss: 0.04641980305314064  (Learning rate: [0.00625], Time: 3.1846s\n",
            "Epoch: 1033, Loss: 0.04640839248895645  (Learning rate: [0.00625], Time: 3.1982s\n",
            "Epoch: 1034, Loss: 0.04639695957303047  (Learning rate: [0.00625], Time: 3.2107s\n",
            "Epoch: 1035, Loss: 0.046380504965782166  (Learning rate: [0.00625], Time: 3.1924s\n",
            "Epoch: 1036, Loss: 0.04636586457490921  (Learning rate: [0.00625], Time: 3.2001s\n",
            "Epoch: 1037, Loss: 0.046353135257959366  (Learning rate: [0.00625], Time: 3.2047s\n",
            "Epoch: 1038, Loss: 0.04633939266204834  (Learning rate: [0.00625], Time: 3.2138s\n",
            "Epoch: 1039, Loss: 0.046324100345373154  (Learning rate: [0.00625], Time: 3.2018s\n",
            "Epoch: 1040, Loss: 0.04631151631474495  (Learning rate: [0.00625], Time: 3.2096s\n",
            "Epoch: 1041, Loss: 0.0462985634803772  (Learning rate: [0.00625], Time: 3.1974s\n",
            "Epoch: 1042, Loss: 0.046284906566143036  (Learning rate: [0.00625], Time: 3.1985s\n",
            "Epoch: 1043, Loss: 0.04627171903848648  (Learning rate: [0.00625], Time: 3.2102s\n",
            "Epoch: 1044, Loss: 0.04626431688666344  (Learning rate: [0.00625], Time: 3.2021s\n",
            "Epoch: 1045, Loss: 0.046257637441158295  (Learning rate: [0.00625], Time: 3.2132s\n",
            "Epoch: 1046, Loss: 0.04625407233834267  (Learning rate: [0.00625], Time: 3.2206s\n",
            "Epoch: 1047, Loss: 0.04623997211456299  (Learning rate: [0.00625], Time: 3.2069s\n",
            "Epoch: 1048, Loss: 0.04622211679816246  (Learning rate: [0.00625], Time: 3.2004s\n",
            "Epoch: 1049, Loss: 0.04620372876524925  (Learning rate: [0.00625], Time: 3.2129s\n",
            "Epoch: 1050, Loss: 0.04619356617331505  (Learning rate: [0.00625], Time: 3.1983s\n",
            "Epoch: 1051, Loss: 0.046175792813301086  (Learning rate: [0.00625], Time: 3.2026s\n",
            "Epoch: 1052, Loss: 0.04615377262234688  (Learning rate: [0.00625], Time: 3.2134s\n",
            "Epoch: 1053, Loss: 0.04614171385765076  (Learning rate: [0.00625], Time: 3.2077s\n",
            "Epoch: 1054, Loss: 0.046129800379276276  (Learning rate: [0.00625], Time: 3.1798s\n",
            "Epoch: 1055, Loss: 0.046112705022096634  (Learning rate: [0.00625], Time: 3.1904s\n",
            "Epoch: 1056, Loss: 0.04608369618654251  (Learning rate: [0.00625], Time: 3.1867s\n",
            "Epoch: 1057, Loss: 0.04606502875685692  (Learning rate: [0.00625], Time: 3.194s\n",
            "Epoch: 1058, Loss: 0.04604502022266388  (Learning rate: [0.00625], Time: 3.1965s\n",
            "Epoch: 1059, Loss: 0.04603196308016777  (Learning rate: [0.00625], Time: 3.1918s\n",
            "Epoch: 1060, Loss: 0.04602234438061714  (Learning rate: [0.00625], Time: 3.1866s\n",
            "Epoch: 1061, Loss: 0.046009037643671036  (Learning rate: [0.00625], Time: 3.2017s\n",
            "Epoch: 1062, Loss: 0.0459858737885952  (Learning rate: [0.00625], Time: 3.2019s\n",
            "Epoch: 1063, Loss: 0.04597470909357071  (Learning rate: [0.00625], Time: 3.1927s\n",
            "Epoch: 1064, Loss: 0.04595676809549332  (Learning rate: [0.00625], Time: 3.1865s\n",
            "Epoch: 1065, Loss: 0.04594020918011665  (Learning rate: [0.00625], Time: 3.1915s\n",
            "Epoch: 1066, Loss: 0.04592416435480118  (Learning rate: [0.00625], Time: 3.1885s\n",
            "Epoch: 1067, Loss: 0.04590817913413048  (Learning rate: [0.00625], Time: 3.1956s\n",
            "Epoch: 1068, Loss: 0.045891303569078445  (Learning rate: [0.00625], Time: 3.2021s\n",
            "Epoch: 1069, Loss: 0.04587442800402641  (Learning rate: [0.00625], Time: 3.2173s\n",
            "Epoch: 1070, Loss: 0.04584651440382004  (Learning rate: [0.00625], Time: 3.2136s\n",
            "Epoch: 1071, Loss: 0.045823127031326294  (Learning rate: [0.00625], Time: 3.2063s\n",
            "Epoch: 1072, Loss: 0.045806337147951126  (Learning rate: [0.00625], Time: 3.1954s\n",
            "Epoch: 1073, Loss: 0.045790888369083405  (Learning rate: [0.00625], Time: 3.2024s\n",
            "Epoch: 1074, Loss: 0.04578206688165665  (Learning rate: [0.00625], Time: 3.2068s\n",
            "Epoch: 1075, Loss: 0.04577160254120827  (Learning rate: [0.00625], Time: 3.2004s\n",
            "Epoch: 1076, Loss: 0.04574410989880562  (Learning rate: [0.00625], Time: 3.2059s\n",
            "Epoch: 1077, Loss: 0.04571438953280449  (Learning rate: [0.00625], Time: 3.2211s\n",
            "Epoch: 1078, Loss: 0.045685335993766785  (Learning rate: [0.00625], Time: 3.2124s\n",
            "Epoch: 1079, Loss: 0.04566557705402374  (Learning rate: [0.00625], Time: 3.2074s\n",
            "Epoch: 1080, Loss: 0.045654296875  (Learning rate: [0.00625], Time: 3.2042s\n",
            "Epoch: 1081, Loss: 0.045637547969818115  (Learning rate: [0.00625], Time: 3.2042s\n",
            "Epoch: 1082, Loss: 0.045623451471328735  (Learning rate: [0.00625], Time: 3.1951s\n",
            "Epoch: 1083, Loss: 0.045600369572639465  (Learning rate: [0.00625], Time: 3.2007s\n",
            "Epoch: 1084, Loss: 0.045569974929094315  (Learning rate: [0.00625], Time: 3.1981s\n",
            "Epoch: 1085, Loss: 0.04554956406354904  (Learning rate: [0.00625], Time: 3.2007s\n",
            "Epoch: 1086, Loss: 0.04552881792187691  (Learning rate: [0.00625], Time: 3.1969s\n",
            "Epoch: 1087, Loss: 0.04551837965846062  (Learning rate: [0.00625], Time: 3.2057s\n",
            "Epoch: 1088, Loss: 0.04550381004810333  (Learning rate: [0.00625], Time: 3.2193s\n",
            "Epoch: 1089, Loss: 0.04548279568552971  (Learning rate: [0.00625], Time: 3.2028s\n",
            "Epoch: 1090, Loss: 0.04546323046088219  (Learning rate: [0.00625], Time: 3.2022s\n",
            "Epoch: 1091, Loss: 0.04544197767972946  (Learning rate: [0.00625], Time: 3.2109s\n",
            "Epoch: 1092, Loss: 0.04541639983654022  (Learning rate: [0.00625], Time: 3.2041s\n",
            "Epoch: 1093, Loss: 0.04539219290018082  (Learning rate: [0.00625], Time: 3.2018s\n",
            "Epoch: 1094, Loss: 0.045367639511823654  (Learning rate: [0.00625], Time: 3.2s\n",
            "Epoch: 1095, Loss: 0.045346781611442566  (Learning rate: [0.00625], Time: 3.1993s\n",
            "Epoch: 1096, Loss: 0.045329030603170395  (Learning rate: [0.00625], Time: 3.1969s\n",
            "Epoch: 1097, Loss: 0.045312028378248215  (Learning rate: [0.00625], Time: 3.1988s\n",
            "Epoch: 1098, Loss: 0.045298922806978226  (Learning rate: [0.00625], Time: 3.2095s\n",
            "Epoch: 1099, Loss: 0.04528558999300003  (Learning rate: [0.00625], Time: 3.2148s\n",
            "Epoch: 1100, Loss: 0.04527537152171135  (Learning rate: [0.00625], Time: 3.2119s\n",
            "Epoch: 1101, Loss: 0.045268625020980835  (Learning rate: [0.00625], Time: 3.2056s\n",
            "Epoch: 1102, Loss: 0.04524843022227287  (Learning rate: [0.00625], Time: 3.2031s\n",
            "Epoch: 1103, Loss: 0.04521119222044945  (Learning rate: [0.00625], Time: 3.1979s\n",
            "Epoch: 1104, Loss: 0.04517553001642227  (Learning rate: [0.00625], Time: 3.2041s\n",
            "Epoch: 1105, Loss: 0.045158009976148605  (Learning rate: [0.00625], Time: 3.1936s\n",
            "Epoch: 1106, Loss: 0.04514654725790024  (Learning rate: [0.00625], Time: 3.1972s\n",
            "Epoch: 1107, Loss: 0.04514021798968315  (Learning rate: [0.00625], Time: 3.218s\n",
            "Epoch: 1108, Loss: 0.04513067752122879  (Learning rate: [0.00625], Time: 3.2101s\n",
            "Epoch: 1109, Loss: 0.045102812349796295  (Learning rate: [0.00625], Time: 3.2086s\n",
            "Epoch: 1110, Loss: 0.045071665197610855  (Learning rate: [0.00625], Time: 3.2019s\n",
            "Epoch: 1111, Loss: 0.04504953324794769  (Learning rate: [0.00625], Time: 3.2027s\n",
            "Epoch: 1112, Loss: 0.04503929987549782  (Learning rate: [0.00625], Time: 3.2085s\n",
            "Epoch: 1113, Loss: 0.04504550248384476  (Learning rate: [0.00625], Time: 3.1986s\n",
            "Epoch: 1114, Loss: 0.045029498636722565  (Learning rate: [0.00625], Time: 3.1978s\n",
            "Epoch: 1115, Loss: 0.04499945417046547  (Learning rate: [0.00625], Time: 3.1988s\n",
            "Epoch: 1116, Loss: 0.04496770352125168  (Learning rate: [0.00625], Time: 3.2028s\n",
            "Epoch: 1117, Loss: 0.044947024434804916  (Learning rate: [0.00625], Time: 3.2081s\n",
            "Epoch: 1118, Loss: 0.044936735183000565  (Learning rate: [0.00625], Time: 3.2095s\n",
            "Epoch: 1119, Loss: 0.044938139617443085  (Learning rate: [0.00625], Time: 3.2007s\n",
            "Epoch: 1120, Loss: 0.04499712213873863  (Learning rate: [0.00625], Time: 3.202s\n",
            "Epoch: 1121, Loss: 0.04491087421774864  (Learning rate: [0.00625], Time: 3.19s\n",
            "Epoch: 1122, Loss: 0.04489973932504654  (Learning rate: [0.00625], Time: 3.1928s\n",
            "Epoch: 1123, Loss: 0.04486866295337677  (Learning rate: [0.00625], Time: 3.204s\n",
            "Epoch: 1124, Loss: 0.04487466812133789  (Learning rate: [0.00625], Time: 3.2137s\n",
            "Epoch: 1125, Loss: 0.0448492169380188  (Learning rate: [0.00625], Time: 3.2086s\n",
            "Epoch: 1126, Loss: 0.044828709214925766  (Learning rate: [0.00625], Time: 3.2118s\n",
            "Epoch: 1127, Loss: 0.04479754716157913  (Learning rate: [0.00625], Time: 3.1953s\n",
            "Epoch: 1128, Loss: 0.04479522258043289  (Learning rate: [0.00625], Time: 3.1954s\n",
            "Epoch: 1129, Loss: 0.044778402894735336  (Learning rate: [0.00625], Time: 3.1845s\n",
            "Epoch: 1130, Loss: 0.044756144285202026  (Learning rate: [0.00625], Time: 3.1904s\n",
            "Epoch: 1131, Loss: 0.04472718387842178  (Learning rate: [0.00625], Time: 3.2031s\n",
            "Epoch: 1132, Loss: 0.04471072927117348  (Learning rate: [0.00625], Time: 3.1965s\n",
            "Epoch: 1133, Loss: 0.04469886049628258  (Learning rate: [0.00625], Time: 3.2064s\n",
            "Epoch: 1134, Loss: 0.04467853158712387  (Learning rate: [0.00625], Time: 3.198s\n",
            "Epoch: 1135, Loss: 0.04466047137975693  (Learning rate: [0.00625], Time: 3.1872s\n",
            "Epoch: 1136, Loss: 0.044694166630506516  (Learning rate: [0.00625], Time: 3.2095s\n",
            "Epoch: 1137, Loss: 0.044695574790239334  (Learning rate: [0.00625], Time: 3.1867s\n",
            "Epoch: 1138, Loss: 0.0446615032851696  (Learning rate: [0.00625], Time: 3.1945s\n",
            "Epoch: 1139, Loss: 0.04464680701494217  (Learning rate: [0.00625], Time: 3.1928s\n",
            "Epoch: 1140, Loss: 0.04462286829948425  (Learning rate: [0.00625], Time: 3.2032s\n",
            "Epoch: 1141, Loss: 0.0446075014770031  (Learning rate: [0.00625], Time: 3.2068s\n",
            "Epoch: 1142, Loss: 0.0445857010781765  (Learning rate: [0.00625], Time: 3.2085s\n",
            "Epoch: 1143, Loss: 0.04456377029418945  (Learning rate: [0.00625], Time: 3.2069s\n",
            "Epoch: 1144, Loss: 0.04454977810382843  (Learning rate: [0.00625], Time: 3.2097s\n",
            "Epoch: 1145, Loss: 0.04453070089221001  (Learning rate: [0.00625], Time: 3.2016s\n",
            "Epoch: 1146, Loss: 0.044514693319797516  (Learning rate: [0.00625], Time: 3.2061s\n",
            "Epoch: 1147, Loss: 0.04449444264173508  (Learning rate: [0.00625], Time: 3.1923s\n",
            "Epoch: 1148, Loss: 0.044475018978118896  (Learning rate: [0.00625], Time: 3.2291s\n",
            "Epoch: 1149, Loss: 0.04445461928844452  (Learning rate: [0.00625], Time: 3.2037s\n",
            "Epoch: 1150, Loss: 0.04443814232945442  (Learning rate: [0.00625], Time: 3.2029s\n",
            "Epoch: 1151, Loss: 0.04442445561289787  (Learning rate: [0.00625], Time: 3.205s\n",
            "Epoch: 1152, Loss: 0.044405557215213776  (Learning rate: [0.00625], Time: 3.2198s\n",
            "Epoch: 1153, Loss: 0.04438646137714386  (Learning rate: [0.00625], Time: 3.2002s\n",
            "Epoch: 1154, Loss: 0.04436632990837097  (Learning rate: [0.00625], Time: 3.2137s\n",
            "Epoch: 1155, Loss: 0.044352516531944275  (Learning rate: [0.00625], Time: 3.2154s\n",
            "Epoch: 1156, Loss: 0.044331248849630356  (Learning rate: [0.00625], Time: 3.2072s\n",
            "Epoch: 1157, Loss: 0.044316451996564865  (Learning rate: [0.00625], Time: 3.203s\n",
            "Epoch: 1158, Loss: 0.044298626482486725  (Learning rate: [0.00625], Time: 3.2021s\n",
            "Epoch: 1159, Loss: 0.044280461966991425  (Learning rate: [0.00625], Time: 3.2101s\n",
            "Epoch: 1160, Loss: 0.04426530376076698  (Learning rate: [0.00625], Time: 3.2009s\n",
            "Epoch: 1161, Loss: 0.04425034299492836  (Learning rate: [0.00625], Time: 3.1989s\n",
            "Epoch: 1162, Loss: 0.04423415660858154  (Learning rate: [0.00625], Time: 3.1977s\n",
            "Epoch: 1163, Loss: 0.04421855881810188  (Learning rate: [0.00625], Time: 3.2145s\n",
            "Epoch: 1164, Loss: 0.04420321434736252  (Learning rate: [0.00625], Time: 3.2184s\n",
            "Epoch: 1165, Loss: 0.04418941214680672  (Learning rate: [0.00625], Time: 3.2063s\n",
            "Epoch: 1166, Loss: 0.04417716711759567  (Learning rate: [0.00625], Time: 3.2122s\n",
            "Epoch: 1167, Loss: 0.0441739596426487  (Learning rate: [0.00625], Time: 3.1917s\n",
            "Epoch: 1168, Loss: 0.04416360333561897  (Learning rate: [0.00625], Time: 3.2023s\n",
            "Epoch: 1169, Loss: 0.04414954409003258  (Learning rate: [0.00625], Time: 3.2061s\n",
            "Epoch: 1170, Loss: 0.04413485527038574  (Learning rate: [0.00625], Time: 3.2161s\n",
            "Epoch: 1171, Loss: 0.04410332813858986  (Learning rate: [0.00625], Time: 3.2342s\n",
            "Epoch: 1172, Loss: 0.04408842697739601  (Learning rate: [0.00625], Time: 3.2082s\n",
            "Epoch: 1173, Loss: 0.044083356857299805  (Learning rate: [0.00625], Time: 3.2122s\n",
            "Epoch: 1174, Loss: 0.04407225549221039  (Learning rate: [0.00625], Time: 3.2046s\n",
            "Epoch: 1175, Loss: 0.044055212289094925  (Learning rate: [0.00625], Time: 3.1946s\n",
            "Epoch: 1176, Loss: 0.04403746500611305  (Learning rate: [0.00625], Time: 3.196s\n",
            "Epoch: 1177, Loss: 0.04402409866452217  (Learning rate: [0.00625], Time: 3.194s\n",
            "Epoch: 1178, Loss: 0.04401358589529991  (Learning rate: [0.00625], Time: 3.2093s\n",
            "Epoch: 1179, Loss: 0.04399152472615242  (Learning rate: [0.00625], Time: 3.2173s\n",
            "Epoch: 1180, Loss: 0.04398071765899658  (Learning rate: [0.00625], Time: 3.208s\n",
            "Epoch: 1181, Loss: 0.0439678318798542  (Learning rate: [0.00625], Time: 3.2007s\n",
            "Epoch: 1182, Loss: 0.043947022408246994  (Learning rate: [0.00625], Time: 3.2031s\n",
            "Epoch: 1183, Loss: 0.04393576830625534  (Learning rate: [0.00625], Time: 3.1986s\n",
            "Epoch: 1184, Loss: 0.0439244769513607  (Learning rate: [0.00625], Time: 3.1984s\n",
            "Epoch: 1185, Loss: 0.043912265449762344  (Learning rate: [0.00625], Time: 3.1964s\n",
            "Epoch: 1186, Loss: 0.04390500858426094  (Learning rate: [0.00625], Time: 3.2101s\n",
            "Epoch: 1187, Loss: 0.043896742165088654  (Learning rate: [0.00625], Time: 3.2431s\n",
            "Epoch: 1188, Loss: 0.04388803243637085  (Learning rate: [0.00625], Time: 3.2046s\n",
            "Epoch: 1189, Loss: 0.04388007894158363  (Learning rate: [0.00625], Time: 3.2069s\n",
            "Epoch: 1190, Loss: 0.043858688324689865  (Learning rate: [0.00625], Time: 3.2092s\n",
            "Epoch: 1191, Loss: 0.04383516684174538  (Learning rate: [0.00625], Time: 3.1949s\n",
            "Epoch: 1192, Loss: 0.04381755739450455  (Learning rate: [0.00625], Time: 3.1965s\n",
            "Epoch: 1193, Loss: 0.04379741847515106  (Learning rate: [0.00625], Time: 3.2046s\n",
            "Epoch: 1194, Loss: 0.043780453503131866  (Learning rate: [0.00625], Time: 3.2163s\n",
            "Epoch: 1195, Loss: 0.04376838728785515  (Learning rate: [0.00625], Time: 3.2012s\n",
            "Epoch: 1196, Loss: 0.04376112297177315  (Learning rate: [0.00625], Time: 3.2018s\n",
            "Epoch: 1197, Loss: 0.043749045580625534  (Learning rate: [0.00625], Time: 3.2059s\n",
            "Epoch: 1198, Loss: 0.0437341071665287  (Learning rate: [0.00625], Time: 3.2055s\n",
            "Epoch: 1199, Loss: 0.04372011125087738  (Learning rate: [0.00625], Time: 3.2052s\n",
            "Epoch: 1200, Loss: 0.043707672506570816  (Learning rate: [0.003125], Time: 3.2041s\n",
            "Epoch: 1201, Loss: 0.043692849576473236  (Learning rate: [0.003125], Time: 3.2414s\n",
            "Epoch: 1202, Loss: 0.04367578402161598  (Learning rate: [0.003125], Time: 3.2102s\n",
            "Epoch: 1203, Loss: 0.04367527365684509  (Learning rate: [0.003125], Time: 3.2031s\n",
            "Epoch: 1204, Loss: 0.04366326704621315  (Learning rate: [0.003125], Time: 3.1984s\n",
            "Epoch: 1205, Loss: 0.04366086795926094  (Learning rate: [0.003125], Time: 3.1961s\n",
            "Epoch: 1206, Loss: 0.04364968091249466  (Learning rate: [0.003125], Time: 3.1827s\n",
            "Epoch: 1207, Loss: 0.043647050857543945  (Learning rate: [0.003125], Time: 3.1975s\n",
            "Epoch: 1208, Loss: 0.04363719001412392  (Learning rate: [0.003125], Time: 3.192s\n",
            "Epoch: 1209, Loss: 0.04363328590989113  (Learning rate: [0.003125], Time: 3.2117s\n",
            "Epoch: 1210, Loss: 0.04362443834543228  (Learning rate: [0.003125], Time: 3.2151s\n",
            "Epoch: 1211, Loss: 0.043619852513074875  (Learning rate: [0.003125], Time: 3.1815s\n",
            "Epoch: 1212, Loss: 0.04361175000667572  (Learning rate: [0.003125], Time: 3.1847s\n",
            "Epoch: 1213, Loss: 0.043606389313936234  (Learning rate: [0.003125], Time: 3.1931s\n",
            "Epoch: 1214, Loss: 0.043599050492048264  (Learning rate: [0.003125], Time: 3.1844s\n",
            "Epoch: 1215, Loss: 0.043593473732471466  (Learning rate: [0.003125], Time: 3.1962s\n",
            "Epoch: 1216, Loss: 0.043586332350969315  (Learning rate: [0.003125], Time: 3.215s\n",
            "Epoch: 1217, Loss: 0.04358045384287834  (Learning rate: [0.003125], Time: 3.2064s\n",
            "Epoch: 1218, Loss: 0.043573882430791855  (Learning rate: [0.003125], Time: 3.2143s\n",
            "Epoch: 1219, Loss: 0.04356761276721954  (Learning rate: [0.003125], Time: 3.2006s\n",
            "Epoch: 1220, Loss: 0.04356113448739052  (Learning rate: [0.003125], Time: 3.2003s\n",
            "Epoch: 1221, Loss: 0.04355455935001373  (Learning rate: [0.003125], Time: 3.2011s\n",
            "Epoch: 1222, Loss: 0.043548211455345154  (Learning rate: [0.003125], Time: 3.2018s\n",
            "Epoch: 1223, Loss: 0.04354154318571091  (Learning rate: [0.003125], Time: 3.2092s\n",
            "Epoch: 1224, Loss: 0.043535228818655014  (Learning rate: [0.003125], Time: 3.2164s\n",
            "Epoch: 1225, Loss: 0.043528519570827484  (Learning rate: [0.003125], Time: 3.2139s\n",
            "Epoch: 1226, Loss: 0.04352201521396637  (Learning rate: [0.003125], Time: 3.2137s\n",
            "Epoch: 1227, Loss: 0.04351504519581795  (Learning rate: [0.003125], Time: 3.2022s\n",
            "Epoch: 1228, Loss: 0.04350849613547325  (Learning rate: [0.003125], Time: 3.2073s\n",
            "Epoch: 1229, Loss: 0.04350152239203453  (Learning rate: [0.003125], Time: 3.203s\n",
            "Epoch: 1230, Loss: 0.04349467158317566  (Learning rate: [0.003125], Time: 3.2037s\n",
            "Epoch: 1231, Loss: 0.043487776070833206  (Learning rate: [0.003125], Time: 3.2092s\n",
            "Epoch: 1232, Loss: 0.04348083585500717  (Learning rate: [0.003125], Time: 3.2152s\n",
            "Epoch: 1233, Loss: 0.04347344487905502  (Learning rate: [0.003125], Time: 3.2166s\n",
            "Epoch: 1234, Loss: 0.04346610978245735  (Learning rate: [0.003125], Time: 3.2033s\n",
            "Epoch: 1235, Loss: 0.043458592146635056  (Learning rate: [0.003125], Time: 3.2433s\n",
            "Epoch: 1236, Loss: 0.043449994176626205  (Learning rate: [0.003125], Time: 3.2202s\n",
            "Epoch: 1237, Loss: 0.0434408001601696  (Learning rate: [0.003125], Time: 3.2086s\n",
            "Epoch: 1238, Loss: 0.04343097284436226  (Learning rate: [0.003125], Time: 3.2338s\n",
            "Epoch: 1239, Loss: 0.04342178255319595  (Learning rate: [0.003125], Time: 3.2046s\n",
            "Epoch: 1240, Loss: 0.043414440006017685  (Learning rate: [0.003125], Time: 3.2175s\n",
            "Epoch: 1241, Loss: 0.04340529069304466  (Learning rate: [0.003125], Time: 3.2134s\n",
            "Epoch: 1242, Loss: 0.043396562337875366  (Learning rate: [0.003125], Time: 3.2122s\n",
            "Epoch: 1243, Loss: 0.04338717460632324  (Learning rate: [0.003125], Time: 3.2099s\n",
            "Epoch: 1244, Loss: 0.04337822645902634  (Learning rate: [0.003125], Time: 3.2062s\n",
            "Epoch: 1245, Loss: 0.0433695949614048  (Learning rate: [0.003125], Time: 3.2013s\n",
            "Epoch: 1246, Loss: 0.0433608740568161  (Learning rate: [0.003125], Time: 3.2061s\n",
            "Epoch: 1247, Loss: 0.0433523990213871  (Learning rate: [0.003125], Time: 3.2144s\n",
            "Epoch: 1248, Loss: 0.04334358498454094  (Learning rate: [0.003125], Time: 3.229s\n",
            "Epoch: 1249, Loss: 0.04333510622382164  (Learning rate: [0.003125], Time: 3.2103s\n",
            "Epoch: 1250, Loss: 0.04332677274942398  (Learning rate: [0.003125], Time: 3.2097s\n",
            "Epoch: 1251, Loss: 0.04331846907734871  (Learning rate: [0.003125], Time: 3.201s\n",
            "Epoch: 1252, Loss: 0.04331009462475777  (Learning rate: [0.003125], Time: 3.21s\n",
            "Epoch: 1253, Loss: 0.04330127313733101  (Learning rate: [0.003125], Time: 3.2241s\n",
            "Epoch: 1254, Loss: 0.043292853981256485  (Learning rate: [0.003125], Time: 3.203s\n",
            "Epoch: 1255, Loss: 0.04328463226556778  (Learning rate: [0.003125], Time: 3.2217s\n",
            "Epoch: 1256, Loss: 0.04327619820833206  (Learning rate: [0.003125], Time: 3.2081s\n",
            "Epoch: 1257, Loss: 0.04326779022812843  (Learning rate: [0.003125], Time: 3.2064s\n",
            "Epoch: 1258, Loss: 0.04325935244560242  (Learning rate: [0.003125], Time: 3.2064s\n",
            "Epoch: 1259, Loss: 0.043251000344753265  (Learning rate: [0.003125], Time: 3.2046s\n",
            "Epoch: 1260, Loss: 0.04324273392558098  (Learning rate: [0.003125], Time: 3.2051s\n",
            "Epoch: 1261, Loss: 0.04323430731892586  (Learning rate: [0.003125], Time: 3.2093s\n",
            "Epoch: 1262, Loss: 0.043226152658462524  (Learning rate: [0.003125], Time: 3.2086s\n",
            "Epoch: 1263, Loss: 0.04321802407503128  (Learning rate: [0.003125], Time: 3.2043s\n",
            "Epoch: 1264, Loss: 0.04320994019508362  (Learning rate: [0.003125], Time: 3.2139s\n",
            "Epoch: 1265, Loss: 0.043201714754104614  (Learning rate: [0.003125], Time: 3.1984s\n",
            "Epoch: 1266, Loss: 0.04319364205002785  (Learning rate: [0.003125], Time: 3.2079s\n",
            "Epoch: 1267, Loss: 0.04318564757704735  (Learning rate: [0.003125], Time: 3.1903s\n",
            "Epoch: 1268, Loss: 0.04317759349942207  (Learning rate: [0.003125], Time: 3.1983s\n",
            "Epoch: 1269, Loss: 0.04316951707005501  (Learning rate: [0.003125], Time: 3.1849s\n",
            "Epoch: 1270, Loss: 0.04316144064068794  (Learning rate: [0.003125], Time: 3.228s\n",
            "Epoch: 1271, Loss: 0.04315349459648132  (Learning rate: [0.003125], Time: 3.2011s\n",
            "Epoch: 1272, Loss: 0.04314552620053291  (Learning rate: [0.003125], Time: 3.2005s\n",
            "Epoch: 1273, Loss: 0.04313761368393898  (Learning rate: [0.003125], Time: 3.2047s\n",
            "Epoch: 1274, Loss: 0.04312968626618385  (Learning rate: [0.003125], Time: 3.2085s\n",
            "Epoch: 1275, Loss: 0.04312180355191231  (Learning rate: [0.003125], Time: 3.2045s\n",
            "Epoch: 1276, Loss: 0.04311390593647957  (Learning rate: [0.003125], Time: 3.1986s\n",
            "Epoch: 1277, Loss: 0.04310606047511101  (Learning rate: [0.003125], Time: 3.1987s\n",
            "Epoch: 1278, Loss: 0.04309821501374245  (Learning rate: [0.003125], Time: 3.2233s\n",
            "Epoch: 1279, Loss: 0.04309043660759926  (Learning rate: [0.003125], Time: 3.2107s\n",
            "Epoch: 1280, Loss: 0.043082643300294876  (Learning rate: [0.003125], Time: 3.2096s\n",
            "Epoch: 1281, Loss: 0.04307488724589348  (Learning rate: [0.003125], Time: 3.2054s\n",
            "Epoch: 1282, Loss: 0.043067142367362976  (Learning rate: [0.003125], Time: 3.2022s\n",
            "Epoch: 1283, Loss: 0.043059445917606354  (Learning rate: [0.003125], Time: 3.1904s\n",
            "Epoch: 1284, Loss: 0.04305175319314003  (Learning rate: [0.003125], Time: 3.1992s\n",
            "Epoch: 1285, Loss: 0.04304412007331848  (Learning rate: [0.003125], Time: 3.1976s\n",
            "Epoch: 1286, Loss: 0.043036557734012604  (Learning rate: [0.003125], Time: 3.2022s\n",
            "Epoch: 1287, Loss: 0.04302915558218956  (Learning rate: [0.003125], Time: 3.2128s\n",
            "Epoch: 1288, Loss: 0.043021902441978455  (Learning rate: [0.003125], Time: 3.1952s\n",
            "Epoch: 1289, Loss: 0.04301473870873451  (Learning rate: [0.003125], Time: 3.1984s\n",
            "Epoch: 1290, Loss: 0.04300708323717117  (Learning rate: [0.003125], Time: 3.1995s\n",
            "Epoch: 1291, Loss: 0.0429990217089653  (Learning rate: [0.003125], Time: 3.2076s\n",
            "Epoch: 1292, Loss: 0.04299094155430794  (Learning rate: [0.003125], Time: 3.2095s\n",
            "Epoch: 1293, Loss: 0.042983461171388626  (Learning rate: [0.003125], Time: 3.2011s\n",
            "Epoch: 1294, Loss: 0.042976394295692444  (Learning rate: [0.003125], Time: 3.2028s\n",
            "Epoch: 1295, Loss: 0.04296894744038582  (Learning rate: [0.003125], Time: 3.2149s\n",
            "Epoch: 1296, Loss: 0.04296087473630905  (Learning rate: [0.003125], Time: 3.199s\n",
            "Epoch: 1297, Loss: 0.04295270889997482  (Learning rate: [0.003125], Time: 3.2021s\n",
            "Epoch: 1298, Loss: 0.042944855988025665  (Learning rate: [0.003125], Time: 3.2007s\n",
            "Epoch: 1299, Loss: 0.042936671525239944  (Learning rate: [0.003125], Time: 3.2029s\n",
            "Epoch: 1300, Loss: 0.042928487062454224  (Learning rate: [0.003125], Time: 3.2034s\n",
            "Epoch: 1301, Loss: 0.04292131960391998  (Learning rate: [0.003125], Time: 3.1953s\n",
            "Epoch: 1302, Loss: 0.04291363060474396  (Learning rate: [0.003125], Time: 3.2132s\n",
            "Epoch: 1303, Loss: 0.04290551692247391  (Learning rate: [0.003125], Time: 3.2039s\n",
            "Epoch: 1304, Loss: 0.042897678911685944  (Learning rate: [0.003125], Time: 3.2009s\n",
            "Epoch: 1305, Loss: 0.0428900383412838  (Learning rate: [0.003125], Time: 3.2139s\n",
            "Epoch: 1306, Loss: 0.04288219287991524  (Learning rate: [0.003125], Time: 3.1942s\n",
            "Epoch: 1307, Loss: 0.04287398234009743  (Learning rate: [0.003125], Time: 3.2025s\n",
            "Epoch: 1308, Loss: 0.04286635294556618  (Learning rate: [0.003125], Time: 3.2029s\n",
            "Epoch: 1309, Loss: 0.042858466506004333  (Learning rate: [0.003125], Time: 3.2053s\n",
            "Epoch: 1310, Loss: 0.04285377264022827  (Learning rate: [0.003125], Time: 3.2055s\n",
            "Epoch: 1311, Loss: 0.042848408222198486  (Learning rate: [0.003125], Time: 3.2147s\n",
            "Epoch: 1312, Loss: 0.042839765548706055  (Learning rate: [0.003125], Time: 3.1991s\n",
            "Epoch: 1313, Loss: 0.0428311862051487  (Learning rate: [0.003125], Time: 3.1862s\n",
            "Epoch: 1314, Loss: 0.04282178729772568  (Learning rate: [0.003125], Time: 3.2045s\n",
            "Epoch: 1315, Loss: 0.04281408712267876  (Learning rate: [0.003125], Time: 3.2068s\n",
            "Epoch: 1316, Loss: 0.042806047946214676  (Learning rate: [0.003125], Time: 3.2127s\n",
            "Epoch: 1317, Loss: 0.042796432971954346  (Learning rate: [0.003125], Time: 3.2023s\n",
            "Epoch: 1318, Loss: 0.04278816282749176  (Learning rate: [0.003125], Time: 3.2112s\n",
            "Epoch: 1319, Loss: 0.0427803210914135  (Learning rate: [0.003125], Time: 3.2126s\n",
            "Epoch: 1320, Loss: 0.04277166724205017  (Learning rate: [0.003125], Time: 3.2127s\n",
            "Epoch: 1321, Loss: 0.04276278242468834  (Learning rate: [0.003125], Time: 3.1974s\n",
            "Epoch: 1322, Loss: 0.04275406897068024  (Learning rate: [0.003125], Time: 3.205s\n",
            "Epoch: 1323, Loss: 0.042745526880025864  (Learning rate: [0.003125], Time: 3.2107s\n",
            "Epoch: 1324, Loss: 0.042736295610666275  (Learning rate: [0.003125], Time: 3.2086s\n",
            "Epoch: 1325, Loss: 0.04272613674402237  (Learning rate: [0.003125], Time: 3.2169s\n",
            "Epoch: 1326, Loss: 0.04271514713764191  (Learning rate: [0.003125], Time: 3.2165s\n",
            "Epoch: 1327, Loss: 0.04270457848906517  (Learning rate: [0.003125], Time: 3.2087s\n",
            "Epoch: 1328, Loss: 0.0426960363984108  (Learning rate: [0.003125], Time: 3.2058s\n",
            "Epoch: 1329, Loss: 0.04268733784556389  (Learning rate: [0.003125], Time: 3.2028s\n",
            "Epoch: 1330, Loss: 0.04267914965748787  (Learning rate: [0.003125], Time: 3.2067s\n",
            "Epoch: 1331, Loss: 0.04267065227031708  (Learning rate: [0.003125], Time: 3.2093s\n",
            "Epoch: 1332, Loss: 0.04266167804598808  (Learning rate: [0.003125], Time: 3.2029s\n",
            "Epoch: 1333, Loss: 0.04265116900205612  (Learning rate: [0.003125], Time: 3.2106s\n",
            "Epoch: 1334, Loss: 0.04264228790998459  (Learning rate: [0.003125], Time: 3.2166s\n",
            "Epoch: 1335, Loss: 0.042633600533008575  (Learning rate: [0.003125], Time: 3.2166s\n",
            "Epoch: 1336, Loss: 0.042625103145837784  (Learning rate: [0.003125], Time: 3.2003s\n",
            "Epoch: 1337, Loss: 0.04261568933725357  (Learning rate: [0.003125], Time: 3.204s\n",
            "Epoch: 1338, Loss: 0.042606279253959656  (Learning rate: [0.003125], Time: 3.2075s\n",
            "Epoch: 1339, Loss: 0.04259731248021126  (Learning rate: [0.003125], Time: 3.2004s\n",
            "Epoch: 1340, Loss: 0.04258842021226883  (Learning rate: [0.003125], Time: 3.2003s\n",
            "Epoch: 1341, Loss: 0.04257959872484207  (Learning rate: [0.003125], Time: 3.204s\n",
            "Epoch: 1342, Loss: 0.042570360004901886  (Learning rate: [0.003125], Time: 3.2107s\n",
            "Epoch: 1343, Loss: 0.042560845613479614  (Learning rate: [0.003125], Time: 3.1995s\n",
            "Epoch: 1344, Loss: 0.042552076280117035  (Learning rate: [0.003125], Time: 3.2056s\n",
            "Epoch: 1345, Loss: 0.04254300519824028  (Learning rate: [0.003125], Time: 3.2088s\n",
            "Epoch: 1346, Loss: 0.04253379628062248  (Learning rate: [0.003125], Time: 3.1936s\n",
            "Epoch: 1347, Loss: 0.042524322867393494  (Learning rate: [0.003125], Time: 3.2004s\n",
            "Epoch: 1348, Loss: 0.042515505105257034  (Learning rate: [0.003125], Time: 3.1918s\n",
            "Epoch: 1349, Loss: 0.042506616562604904  (Learning rate: [0.003125], Time: 3.2103s\n",
            "Epoch: 1350, Loss: 0.042498063296079636  (Learning rate: [0.003125], Time: 3.1839s\n",
            "Epoch: 1351, Loss: 0.042488470673561096  (Learning rate: [0.003125], Time: 3.2316s\n",
            "Epoch: 1352, Loss: 0.0424795038998127  (Learning rate: [0.003125], Time: 3.1811s\n",
            "Epoch: 1353, Loss: 0.04247058555483818  (Learning rate: [0.003125], Time: 3.2037s\n",
            "Epoch: 1354, Loss: 0.04246172308921814  (Learning rate: [0.003125], Time: 3.1927s\n",
            "Epoch: 1355, Loss: 0.04245256632566452  (Learning rate: [0.003125], Time: 3.188s\n",
            "Epoch: 1356, Loss: 0.04244324192404747  (Learning rate: [0.003125], Time: 3.2032s\n",
            "Epoch: 1357, Loss: 0.04243399575352669  (Learning rate: [0.003125], Time: 3.2031s\n",
            "Epoch: 1358, Loss: 0.04242473840713501  (Learning rate: [0.003125], Time: 3.1946s\n",
            "Epoch: 1359, Loss: 0.04241566359996796  (Learning rate: [0.003125], Time: 3.1804s\n",
            "Epoch: 1360, Loss: 0.042406726628541946  (Learning rate: [0.003125], Time: 3.1809s\n",
            "Epoch: 1361, Loss: 0.0423978790640831  (Learning rate: [0.003125], Time: 3.1794s\n",
            "Epoch: 1362, Loss: 0.04238893464207649  (Learning rate: [0.003125], Time: 3.1816s\n",
            "Epoch: 1363, Loss: 0.042380206286907196  (Learning rate: [0.003125], Time: 3.1803s\n",
            "Epoch: 1364, Loss: 0.04237170144915581  (Learning rate: [0.003125], Time: 3.18s\n",
            "Epoch: 1365, Loss: 0.04236283153295517  (Learning rate: [0.003125], Time: 3.1796s\n",
            "Epoch: 1366, Loss: 0.04235360771417618  (Learning rate: [0.003125], Time: 3.2023s\n",
            "Epoch: 1367, Loss: 0.04234432801604271  (Learning rate: [0.003125], Time: 3.1814s\n",
            "Epoch: 1368, Loss: 0.04233531281352043  (Learning rate: [0.003125], Time: 3.1765s\n",
            "Epoch: 1369, Loss: 0.04232582077383995  (Learning rate: [0.003125], Time: 3.1825s\n",
            "Epoch: 1370, Loss: 0.0423160120844841  (Learning rate: [0.003125], Time: 3.1816s\n",
            "Epoch: 1371, Loss: 0.0423065684735775  (Learning rate: [0.003125], Time: 3.1819s\n",
            "Epoch: 1372, Loss: 0.04229753091931343  (Learning rate: [0.003125], Time: 3.1799s\n",
            "Epoch: 1373, Loss: 0.04228823259472847  (Learning rate: [0.003125], Time: 3.2016s\n",
            "Epoch: 1374, Loss: 0.042279183864593506  (Learning rate: [0.003125], Time: 3.1878s\n",
            "Epoch: 1375, Loss: 0.042270418256521225  (Learning rate: [0.003125], Time: 3.204s\n",
            "Epoch: 1376, Loss: 0.04226164519786835  (Learning rate: [0.003125], Time: 3.2063s\n",
            "Epoch: 1377, Loss: 0.04225369915366173  (Learning rate: [0.003125], Time: 3.197s\n",
            "Epoch: 1378, Loss: 0.042245179414749146  (Learning rate: [0.003125], Time: 3.1922s\n",
            "Epoch: 1379, Loss: 0.04223665967583656  (Learning rate: [0.003125], Time: 3.199s\n",
            "Epoch: 1380, Loss: 0.04222717881202698  (Learning rate: [0.003125], Time: 3.1929s\n",
            "Epoch: 1381, Loss: 0.042218390852212906  (Learning rate: [0.003125], Time: 3.202s\n",
            "Epoch: 1382, Loss: 0.0422101654112339  (Learning rate: [0.003125], Time: 3.2086s\n",
            "Epoch: 1383, Loss: 0.042198725044727325  (Learning rate: [0.003125], Time: 3.2094s\n",
            "Epoch: 1384, Loss: 0.0421898327767849  (Learning rate: [0.003125], Time: 3.1911s\n",
            "Epoch: 1385, Loss: 0.04218114912509918  (Learning rate: [0.003125], Time: 3.1954s\n",
            "Epoch: 1386, Loss: 0.042172353714704514  (Learning rate: [0.003125], Time: 3.1926s\n",
            "Epoch: 1387, Loss: 0.042164236307144165  (Learning rate: [0.003125], Time: 3.2008s\n",
            "Epoch: 1388, Loss: 0.042155638337135315  (Learning rate: [0.003125], Time: 3.1967s\n",
            "Epoch: 1389, Loss: 0.042146749794483185  (Learning rate: [0.003125], Time: 3.1914s\n",
            "Epoch: 1390, Loss: 0.042136628180742264  (Learning rate: [0.003125], Time: 3.2057s\n",
            "Epoch: 1391, Loss: 0.042127445340156555  (Learning rate: [0.003125], Time: 3.2123s\n",
            "Epoch: 1392, Loss: 0.04211804270744324  (Learning rate: [0.003125], Time: 3.204s\n",
            "Epoch: 1393, Loss: 0.042109422385692596  (Learning rate: [0.003125], Time: 3.2043s\n",
            "Epoch: 1394, Loss: 0.042100679129362106  (Learning rate: [0.003125], Time: 3.2088s\n",
            "Epoch: 1395, Loss: 0.042092349380254745  (Learning rate: [0.003125], Time: 3.2004s\n",
            "Epoch: 1396, Loss: 0.04208344966173172  (Learning rate: [0.003125], Time: 3.1991s\n",
            "Epoch: 1397, Loss: 0.04207583889365196  (Learning rate: [0.003125], Time: 3.2031s\n",
            "Epoch: 1398, Loss: 0.04206712543964386  (Learning rate: [0.003125], Time: 3.1954s\n",
            "Epoch: 1399, Loss: 0.042059481143951416  (Learning rate: [0.003125], Time: 3.21s\n",
            "Epoch: 1400, Loss: 0.04205051437020302  (Learning rate: [0.003125], Time: 3.2085s\n",
            "Epoch: 1401, Loss: 0.04204012081027031  (Learning rate: [0.003125], Time: 3.2027s\n",
            "Epoch: 1402, Loss: 0.042030178010463715  (Learning rate: [0.003125], Time: 3.196s\n",
            "Epoch: 1403, Loss: 0.04202660173177719  (Learning rate: [0.003125], Time: 3.201s\n",
            "Epoch: 1404, Loss: 0.04202103987336159  (Learning rate: [0.003125], Time: 3.2022s\n",
            "Epoch: 1405, Loss: 0.04201069474220276  (Learning rate: [0.003125], Time: 3.2015s\n",
            "Epoch: 1406, Loss: 0.04200100898742676  (Learning rate: [0.003125], Time: 3.2047s\n",
            "Epoch: 1407, Loss: 0.04199405014514923  (Learning rate: [0.003125], Time: 3.2134s\n",
            "Epoch: 1408, Loss: 0.04198402538895607  (Learning rate: [0.003125], Time: 3.2106s\n",
            "Epoch: 1409, Loss: 0.04197521135210991  (Learning rate: [0.003125], Time: 3.2004s\n",
            "Epoch: 1410, Loss: 0.04196590930223465  (Learning rate: [0.003125], Time: 3.1992s\n",
            "Epoch: 1411, Loss: 0.04195588454604149  (Learning rate: [0.003125], Time: 3.204s\n",
            "Epoch: 1412, Loss: 0.04194685444235802  (Learning rate: [0.003125], Time: 3.2064s\n",
            "Epoch: 1413, Loss: 0.04193885996937752  (Learning rate: [0.003125], Time: 3.2051s\n",
            "Epoch: 1414, Loss: 0.04192900285124779  (Learning rate: [0.003125], Time: 3.2183s\n",
            "Epoch: 1415, Loss: 0.0419195331633091  (Learning rate: [0.003125], Time: 3.2041s\n",
            "Epoch: 1416, Loss: 0.04190849885344505  (Learning rate: [0.003125], Time: 3.2093s\n",
            "Epoch: 1417, Loss: 0.04189900681376457  (Learning rate: [0.003125], Time: 3.2038s\n",
            "Epoch: 1418, Loss: 0.04189024865627289  (Learning rate: [0.003125], Time: 3.2103s\n",
            "Epoch: 1419, Loss: 0.04188160225749016  (Learning rate: [0.003125], Time: 3.2045s\n",
            "Epoch: 1420, Loss: 0.04187381640076637  (Learning rate: [0.003125], Time: 3.1958s\n",
            "Epoch: 1421, Loss: 0.04186546057462692  (Learning rate: [0.003125], Time: 3.1942s\n",
            "Epoch: 1422, Loss: 0.0418560691177845  (Learning rate: [0.003125], Time: 3.2054s\n",
            "Epoch: 1423, Loss: 0.04184671491384506  (Learning rate: [0.003125], Time: 3.206s\n",
            "Epoch: 1424, Loss: 0.04183689504861832  (Learning rate: [0.003125], Time: 3.2074s\n",
            "Epoch: 1425, Loss: 0.04182787984609604  (Learning rate: [0.003125], Time: 3.1974s\n",
            "Epoch: 1426, Loss: 0.04181992635130882  (Learning rate: [0.003125], Time: 3.2003s\n",
            "Epoch: 1427, Loss: 0.04181265830993652  (Learning rate: [0.003125], Time: 3.202s\n",
            "Epoch: 1428, Loss: 0.04180563986301422  (Learning rate: [0.003125], Time: 3.2351s\n",
            "Epoch: 1429, Loss: 0.04179833084344864  (Learning rate: [0.003125], Time: 3.1922s\n",
            "Epoch: 1430, Loss: 0.04179063066840172  (Learning rate: [0.003125], Time: 3.1929s\n",
            "Epoch: 1431, Loss: 0.04178343713283539  (Learning rate: [0.003125], Time: 3.2019s\n",
            "Epoch: 1432, Loss: 0.041775260120630264  (Learning rate: [0.003125], Time: 3.2037s\n",
            "Epoch: 1433, Loss: 0.041763871908187866  (Learning rate: [0.003125], Time: 3.194s\n",
            "Epoch: 1434, Loss: 0.04175109788775444  (Learning rate: [0.003125], Time: 3.1966s\n",
            "Epoch: 1435, Loss: 0.04174264892935753  (Learning rate: [0.003125], Time: 3.1995s\n",
            "Epoch: 1436, Loss: 0.04173719882965088  (Learning rate: [0.003125], Time: 3.1993s\n",
            "Epoch: 1437, Loss: 0.04173155501484871  (Learning rate: [0.003125], Time: 3.1958s\n",
            "Epoch: 1438, Loss: 0.04172007739543915  (Learning rate: [0.003125], Time: 3.1865s\n",
            "Epoch: 1439, Loss: 0.04170776531100273  (Learning rate: [0.003125], Time: 3.2227s\n",
            "Epoch: 1440, Loss: 0.04169938340783119  (Learning rate: [0.003125], Time: 3.2073s\n",
            "Epoch: 1441, Loss: 0.04169278219342232  (Learning rate: [0.003125], Time: 3.2154s\n",
            "Epoch: 1442, Loss: 0.04168632999062538  (Learning rate: [0.003125], Time: 3.1881s\n",
            "Epoch: 1443, Loss: 0.041677527129650116  (Learning rate: [0.003125], Time: 3.1897s\n",
            "Epoch: 1444, Loss: 0.041668571531772614  (Learning rate: [0.003125], Time: 3.2012s\n",
            "Epoch: 1445, Loss: 0.04165784269571304  (Learning rate: [0.003125], Time: 3.2s\n",
            "Epoch: 1446, Loss: 0.04164879024028778  (Learning rate: [0.003125], Time: 3.2226s\n",
            "Epoch: 1447, Loss: 0.04164163023233414  (Learning rate: [0.003125], Time: 3.2111s\n",
            "Epoch: 1448, Loss: 0.04163455218076706  (Learning rate: [0.003125], Time: 3.2132s\n",
            "Epoch: 1449, Loss: 0.04162565618753433  (Learning rate: [0.003125], Time: 3.1981s\n",
            "Epoch: 1450, Loss: 0.041615623980760574  (Learning rate: [0.003125], Time: 3.1905s\n",
            "Epoch: 1451, Loss: 0.041607409715652466  (Learning rate: [0.003125], Time: 3.1911s\n",
            "Epoch: 1452, Loss: 0.041597217321395874  (Learning rate: [0.003125], Time: 3.1991s\n",
            "Epoch: 1453, Loss: 0.04158846288919449  (Learning rate: [0.003125], Time: 3.2009s\n",
            "Epoch: 1454, Loss: 0.04158147796988487  (Learning rate: [0.003125], Time: 3.1944s\n",
            "Epoch: 1455, Loss: 0.041582632809877396  (Learning rate: [0.003125], Time: 3.2102s\n",
            "Epoch: 1456, Loss: 0.0415695458650589  (Learning rate: [0.003125], Time: 3.2052s\n",
            "Epoch: 1457, Loss: 0.04155511409044266  (Learning rate: [0.003125], Time: 3.1953s\n",
            "Epoch: 1458, Loss: 0.041536055505275726  (Learning rate: [0.003125], Time: 3.1928s\n",
            "Epoch: 1459, Loss: 0.041530683636665344  (Learning rate: [0.003125], Time: 3.1972s\n",
            "Epoch: 1460, Loss: 0.041521426290273666  (Learning rate: [0.003125], Time: 3.1914s\n",
            "Epoch: 1461, Loss: 0.041512832045555115  (Learning rate: [0.003125], Time: 3.201s\n",
            "Epoch: 1462, Loss: 0.041495777666568756  (Learning rate: [0.003125], Time: 3.2083s\n",
            "Epoch: 1463, Loss: 0.041481662541627884  (Learning rate: [0.003125], Time: 3.2166s\n",
            "Epoch: 1464, Loss: 0.04146890342235565  (Learning rate: [0.003125], Time: 3.2141s\n",
            "Epoch: 1465, Loss: 0.04146045073866844  (Learning rate: [0.003125], Time: 3.2021s\n",
            "Epoch: 1466, Loss: 0.04145095869898796  (Learning rate: [0.003125], Time: 3.1962s\n",
            "Epoch: 1467, Loss: 0.04143977537751198  (Learning rate: [0.003125], Time: 3.2008s\n",
            "Epoch: 1468, Loss: 0.04142938181757927  (Learning rate: [0.003125], Time: 3.2056s\n",
            "Epoch: 1469, Loss: 0.04141287878155708  (Learning rate: [0.003125], Time: 3.1979s\n",
            "Epoch: 1470, Loss: 0.041403044015169144  (Learning rate: [0.003125], Time: 3.2114s\n",
            "Epoch: 1471, Loss: 0.04139639437198639  (Learning rate: [0.003125], Time: 3.2067s\n",
            "Epoch: 1472, Loss: 0.041381556540727615  (Learning rate: [0.003125], Time: 3.2106s\n",
            "Epoch: 1473, Loss: 0.04136821627616882  (Learning rate: [0.003125], Time: 3.2077s\n",
            "Epoch: 1474, Loss: 0.04136083275079727  (Learning rate: [0.003125], Time: 3.1945s\n",
            "Epoch: 1475, Loss: 0.04134863242506981  (Learning rate: [0.003125], Time: 3.1973s\n",
            "Epoch: 1476, Loss: 0.04133691266179085  (Learning rate: [0.003125], Time: 3.1981s\n",
            "Epoch: 1477, Loss: 0.041325654834508896  (Learning rate: [0.003125], Time: 3.2215s\n",
            "Epoch: 1478, Loss: 0.041316065937280655  (Learning rate: [0.003125], Time: 3.2012s\n",
            "Epoch: 1479, Loss: 0.041303396224975586  (Learning rate: [0.003125], Time: 3.2195s\n",
            "Epoch: 1480, Loss: 0.0412931963801384  (Learning rate: [0.003125], Time: 3.2255s\n",
            "Epoch: 1481, Loss: 0.041283246129751205  (Learning rate: [0.003125], Time: 3.2268s\n",
            "Epoch: 1482, Loss: 0.04127167537808418  (Learning rate: [0.003125], Time: 3.1983s\n",
            "Epoch: 1483, Loss: 0.0412621945142746  (Learning rate: [0.003125], Time: 3.2137s\n",
            "Epoch: 1484, Loss: 0.04125278815627098  (Learning rate: [0.003125], Time: 3.2034s\n",
            "Epoch: 1485, Loss: 0.04124264046549797  (Learning rate: [0.003125], Time: 3.202s\n",
            "Epoch: 1486, Loss: 0.041232217103242874  (Learning rate: [0.003125], Time: 3.2119s\n",
            "Epoch: 1487, Loss: 0.041221555322408676  (Learning rate: [0.003125], Time: 3.2166s\n",
            "Epoch: 1488, Loss: 0.04121137782931328  (Learning rate: [0.003125], Time: 3.203s\n",
            "Epoch: 1489, Loss: 0.04120045527815819  (Learning rate: [0.003125], Time: 3.2088s\n",
            "Epoch: 1490, Loss: 0.04119102656841278  (Learning rate: [0.003125], Time: 3.2018s\n",
            "Epoch: 1491, Loss: 0.041178859770298004  (Learning rate: [0.003125], Time: 3.2157s\n",
            "Epoch: 1492, Loss: 0.041168808937072754  (Learning rate: [0.003125], Time: 3.2126s\n",
            "Epoch: 1493, Loss: 0.041158564388751984  (Learning rate: [0.003125], Time: 3.204s\n",
            "Epoch: 1494, Loss: 0.041147246956825256  (Learning rate: [0.003125], Time: 3.2258s\n",
            "Epoch: 1495, Loss: 0.041136741638183594  (Learning rate: [0.003125], Time: 3.2109s\n",
            "Epoch: 1496, Loss: 0.041127413511276245  (Learning rate: [0.003125], Time: 3.1982s\n",
            "Epoch: 1497, Loss: 0.04111722484230995  (Learning rate: [0.003125], Time: 3.2202s\n",
            "Epoch: 1498, Loss: 0.04110689088702202  (Learning rate: [0.003125], Time: 3.1995s\n",
            "Epoch: 1499, Loss: 0.04109793156385422  (Learning rate: [0.003125], Time: 3.196s\n",
            "Epoch: 1500, Loss: 0.041088610887527466  (Learning rate: [0.0015625], Time: 3.2071s\n",
            "Epoch: 1501, Loss: 0.04107818752527237  (Learning rate: [0.0015625], Time: 3.2022s\n",
            "Epoch: 1502, Loss: 0.041068729013204575  (Learning rate: [0.0015625], Time: 3.2149s\n",
            "Epoch: 1503, Loss: 0.04106525704264641  (Learning rate: [0.0015625], Time: 3.2073s\n",
            "Epoch: 1504, Loss: 0.0410584881901741  (Learning rate: [0.0015625], Time: 3.2111s\n",
            "Epoch: 1505, Loss: 0.041054099798202515  (Learning rate: [0.0015625], Time: 3.1972s\n",
            "Epoch: 1506, Loss: 0.04104762524366379  (Learning rate: [0.0015625], Time: 3.2147s\n",
            "Epoch: 1507, Loss: 0.04104338586330414  (Learning rate: [0.0015625], Time: 3.2018s\n",
            "Epoch: 1508, Loss: 0.04103691875934601  (Learning rate: [0.0015625], Time: 3.2213s\n",
            "Epoch: 1509, Loss: 0.04103255644440651  (Learning rate: [0.0015625], Time: 3.2132s\n",
            "Epoch: 1510, Loss: 0.041026756167411804  (Learning rate: [0.0015625], Time: 3.2164s\n",
            "Epoch: 1511, Loss: 0.04102180525660515  (Learning rate: [0.0015625], Time: 3.211s\n",
            "Epoch: 1512, Loss: 0.04101628437638283  (Learning rate: [0.0015625], Time: 3.21s\n",
            "Epoch: 1513, Loss: 0.04101139307022095  (Learning rate: [0.0015625], Time: 3.2124s\n",
            "Epoch: 1514, Loss: 0.041005704551935196  (Learning rate: [0.0015625], Time: 3.2088s\n",
            "Epoch: 1515, Loss: 0.0410008504986763  (Learning rate: [0.0015625], Time: 3.2004s\n",
            "Epoch: 1516, Loss: 0.04099538177251816  (Learning rate: [0.0015625], Time: 3.2024s\n",
            "Epoch: 1517, Loss: 0.04099017009139061  (Learning rate: [0.0015625], Time: 3.2176s\n",
            "Epoch: 1518, Loss: 0.040984950959682465  (Learning rate: [0.0015625], Time: 3.2131s\n",
            "Epoch: 1519, Loss: 0.040979620069265366  (Learning rate: [0.0015625], Time: 3.2109s\n",
            "Epoch: 1520, Loss: 0.040974393486976624  (Learning rate: [0.0015625], Time: 3.2038s\n",
            "Epoch: 1521, Loss: 0.0409691296517849  (Learning rate: [0.0015625], Time: 3.2098s\n",
            "Epoch: 1522, Loss: 0.04096384346485138  (Learning rate: [0.0015625], Time: 3.2085s\n",
            "Epoch: 1523, Loss: 0.04095861688256264  (Learning rate: [0.0015625], Time: 3.2051s\n",
            "Epoch: 1524, Loss: 0.04095347970724106  (Learning rate: [0.0015625], Time: 3.2159s\n",
            "Epoch: 1525, Loss: 0.04094817116856575  (Learning rate: [0.0015625], Time: 3.2203s\n",
            "Epoch: 1526, Loss: 0.04094310477375984  (Learning rate: [0.0015625], Time: 3.2107s\n",
            "Epoch: 1527, Loss: 0.040937840938568115  (Learning rate: [0.0015625], Time: 3.2085s\n",
            "Epoch: 1528, Loss: 0.04093273729085922  (Learning rate: [0.0015625], Time: 3.1948s\n",
            "Epoch: 1529, Loss: 0.040927618741989136  (Learning rate: [0.0015625], Time: 3.2013s\n",
            "Epoch: 1530, Loss: 0.04092240706086159  (Learning rate: [0.0015625], Time: 3.1936s\n",
            "Epoch: 1531, Loss: 0.04091731086373329  (Learning rate: [0.0015625], Time: 3.2032s\n",
            "Epoch: 1532, Loss: 0.04091215878725052  (Learning rate: [0.0015625], Time: 3.2122s\n",
            "Epoch: 1533, Loss: 0.04090699553489685  (Learning rate: [0.0015625], Time: 3.2205s\n",
            "Epoch: 1534, Loss: 0.04090191051363945  (Learning rate: [0.0015625], Time: 3.2048s\n",
            "Epoch: 1535, Loss: 0.040896762162446976  (Learning rate: [0.0015625], Time: 3.2142s\n",
            "Epoch: 1536, Loss: 0.0408916175365448  (Learning rate: [0.0015625], Time: 3.2048s\n",
            "Epoch: 1537, Loss: 0.04088657349348068  (Learning rate: [0.0015625], Time: 3.207s\n",
            "Epoch: 1538, Loss: 0.04088141769170761  (Learning rate: [0.0015625], Time: 3.1802s\n",
            "Epoch: 1539, Loss: 0.040876299142837524  (Learning rate: [0.0015625], Time: 3.1937s\n",
            "Epoch: 1540, Loss: 0.040871236473321915  (Learning rate: [0.0015625], Time: 3.2176s\n",
            "Epoch: 1541, Loss: 0.04086613282561302  (Learning rate: [0.0015625], Time: 3.2073s\n",
            "Epoch: 1542, Loss: 0.04086098447442055  (Learning rate: [0.0015625], Time: 3.2095s\n",
            "Epoch: 1543, Loss: 0.04085596650838852  (Learning rate: [0.0015625], Time: 3.1987s\n",
            "Epoch: 1544, Loss: 0.040850892663002014  (Learning rate: [0.0015625], Time: 3.1888s\n",
            "Epoch: 1545, Loss: 0.04084575176239014  (Learning rate: [0.0015625], Time: 3.1865s\n",
            "Epoch: 1546, Loss: 0.04084077104926109  (Learning rate: [0.0015625], Time: 3.1925s\n",
            "Epoch: 1547, Loss: 0.04083571955561638  (Learning rate: [0.0015625], Time: 3.194s\n",
            "Epoch: 1548, Loss: 0.040830567479133606  (Learning rate: [0.0015625], Time: 3.1944s\n",
            "Epoch: 1549, Loss: 0.04082563892006874  (Learning rate: [0.0015625], Time: 3.2126s\n",
            "Epoch: 1550, Loss: 0.04082060977816582  (Learning rate: [0.0015625], Time: 3.1859s\n",
            "Epoch: 1551, Loss: 0.04081545025110245  (Learning rate: [0.0015625], Time: 3.2042s\n",
            "Epoch: 1552, Loss: 0.04081059247255325  (Learning rate: [0.0015625], Time: 3.1882s\n",
            "Epoch: 1553, Loss: 0.04080556333065033  (Learning rate: [0.0015625], Time: 3.2184s\n",
            "Epoch: 1554, Loss: 0.04080040007829666  (Learning rate: [0.0015625], Time: 3.2014s\n",
            "Epoch: 1555, Loss: 0.040795594453811646  (Learning rate: [0.0015625], Time: 3.2004s\n",
            "Epoch: 1556, Loss: 0.04079054296016693  (Learning rate: [0.0015625], Time: 3.2213s\n",
            "Epoch: 1557, Loss: 0.04078539088368416  (Learning rate: [0.0015625], Time: 3.2289s\n",
            "Epoch: 1558, Loss: 0.04078061133623123  (Learning rate: [0.0015625], Time: 3.2085s\n",
            "Epoch: 1559, Loss: 0.040775541216135025  (Learning rate: [0.0015625], Time: 3.2184s\n",
            "Epoch: 1560, Loss: 0.04077040031552315  (Learning rate: [0.0015625], Time: 3.2101s\n",
            "Epoch: 1561, Loss: 0.04076559469103813  (Learning rate: [0.0015625], Time: 3.2156s\n",
            "Epoch: 1562, Loss: 0.04076056554913521  (Learning rate: [0.0015625], Time: 3.2046s\n",
            "Epoch: 1563, Loss: 0.04075540602207184  (Learning rate: [0.0015625], Time: 3.2181s\n",
            "Epoch: 1564, Loss: 0.040750652551651  (Learning rate: [0.0015625], Time: 3.209s\n",
            "Epoch: 1565, Loss: 0.040745627135038376  (Learning rate: [0.0015625], Time: 3.2103s\n",
            "Epoch: 1566, Loss: 0.0407404750585556  (Learning rate: [0.0015625], Time: 3.2162s\n",
            "Epoch: 1567, Loss: 0.04073575884103775  (Learning rate: [0.0015625], Time: 3.2126s\n",
            "Epoch: 1568, Loss: 0.040730711072683334  (Learning rate: [0.0015625], Time: 3.2107s\n",
            "Epoch: 1569, Loss: 0.04072562977671623  (Learning rate: [0.0015625], Time: 3.2066s\n",
            "Epoch: 1570, Loss: 0.04072092846035957  (Learning rate: [0.0015625], Time: 3.2105s\n",
            "Epoch: 1571, Loss: 0.04071587324142456  (Learning rate: [0.0015625], Time: 3.2226s\n",
            "Epoch: 1572, Loss: 0.040710821747779846  (Learning rate: [0.0015625], Time: 3.2103s\n",
            "Epoch: 1573, Loss: 0.040706146508455276  (Learning rate: [0.0015625], Time: 3.204s\n",
            "Epoch: 1574, Loss: 0.04070105776190758  (Learning rate: [0.0015625], Time: 3.2056s\n",
            "Epoch: 1575, Loss: 0.040696047246456146  (Learning rate: [0.0015625], Time: 3.203s\n",
            "Epoch: 1576, Loss: 0.04069136455655098  (Learning rate: [0.0015625], Time: 3.2148s\n",
            "Epoch: 1577, Loss: 0.04068624600768089  (Learning rate: [0.0015625], Time: 3.2108s\n",
            "Epoch: 1578, Loss: 0.04068128019571304  (Learning rate: [0.0015625], Time: 3.2215s\n",
            "Epoch: 1579, Loss: 0.04067651927471161  (Learning rate: [0.0015625], Time: 3.2199s\n",
            "Epoch: 1580, Loss: 0.040671467781066895  (Learning rate: [0.0015625], Time: 3.2022s\n",
            "Epoch: 1581, Loss: 0.040666524320840836  (Learning rate: [0.0015625], Time: 3.2092s\n",
            "Epoch: 1582, Loss: 0.04066167399287224  (Learning rate: [0.0015625], Time: 3.2042s\n",
            "Epoch: 1583, Loss: 0.04065675288438797  (Learning rate: [0.0015625], Time: 3.2016s\n",
            "Epoch: 1584, Loss: 0.040651824325323105  (Learning rate: [0.0015625], Time: 3.2043s\n",
            "Epoch: 1585, Loss: 0.040646884590387344  (Learning rate: [0.0015625], Time: 3.2002s\n",
            "Epoch: 1586, Loss: 0.040642112493515015  (Learning rate: [0.0015625], Time: 3.2146s\n",
            "Epoch: 1587, Loss: 0.04063725471496582  (Learning rate: [0.0015625], Time: 3.2193s\n",
            "Epoch: 1588, Loss: 0.040632251650094986  (Learning rate: [0.0015625], Time: 3.1987s\n",
            "Epoch: 1589, Loss: 0.040627505630254745  (Learning rate: [0.0015625], Time: 3.2067s\n",
            "Epoch: 1590, Loss: 0.04062250629067421  (Learning rate: [0.0015625], Time: 3.2039s\n",
            "Epoch: 1591, Loss: 0.04061753302812576  (Learning rate: [0.0015625], Time: 3.2035s\n",
            "Epoch: 1592, Loss: 0.04061277210712433  (Learning rate: [0.0015625], Time: 3.206s\n",
            "Epoch: 1593, Loss: 0.040607746690511703  (Learning rate: [0.0015625], Time: 3.2354s\n",
            "Epoch: 1594, Loss: 0.04060281068086624  (Learning rate: [0.0015625], Time: 3.2181s\n",
            "Epoch: 1595, Loss: 0.040598064661026  (Learning rate: [0.0015625], Time: 3.2083s\n",
            "Epoch: 1596, Loss: 0.04059310257434845  (Learning rate: [0.0015625], Time: 3.2184s\n",
            "Epoch: 1597, Loss: 0.04058815911412239  (Learning rate: [0.0015625], Time: 3.205s\n",
            "Epoch: 1598, Loss: 0.040583424270153046  (Learning rate: [0.0015625], Time: 3.2063s\n",
            "Epoch: 1599, Loss: 0.04057852551341057  (Learning rate: [0.0015625], Time: 3.1943s\n",
            "Epoch: 1600, Loss: 0.040573567152023315  (Learning rate: [0.0015625], Time: 3.1927s\n",
            "Epoch: 1601, Loss: 0.04056879132986069  (Learning rate: [0.0015625], Time: 3.2132s\n",
            "Epoch: 1602, Loss: 0.040563806891441345  (Learning rate: [0.0015625], Time: 3.2125s\n",
            "Epoch: 1603, Loss: 0.04055888205766678  (Learning rate: [0.0015625], Time: 3.207s\n",
            "Epoch: 1604, Loss: 0.04055402800440788  (Learning rate: [0.0015625], Time: 3.2146s\n",
            "Epoch: 1605, Loss: 0.04054904356598854  (Learning rate: [0.0015625], Time: 3.2007s\n",
            "Epoch: 1606, Loss: 0.0405440591275692  (Learning rate: [0.0015625], Time: 3.2053s\n",
            "Epoch: 1607, Loss: 0.040539126843214035  (Learning rate: [0.0015625], Time: 3.2052s\n",
            "Epoch: 1608, Loss: 0.04053406044840813  (Learning rate: [0.0015625], Time: 3.2067s\n",
            "Epoch: 1609, Loss: 0.04052909463644028  (Learning rate: [0.0015625], Time: 3.2337s\n",
            "Epoch: 1610, Loss: 0.04052416980266571  (Learning rate: [0.0015625], Time: 3.2027s\n",
            "Epoch: 1611, Loss: 0.040518999099731445  (Learning rate: [0.0015625], Time: 3.2104s\n",
            "Epoch: 1612, Loss: 0.04051382839679718  (Learning rate: [0.0015625], Time: 3.2102s\n",
            "Epoch: 1613, Loss: 0.04050884023308754  (Learning rate: [0.0015625], Time: 3.2033s\n",
            "Epoch: 1614, Loss: 0.04050347954034805  (Learning rate: [0.0015625], Time: 3.2054s\n",
            "Epoch: 1615, Loss: 0.040498144924640656  (Learning rate: [0.0015625], Time: 3.2042s\n",
            "Epoch: 1616, Loss: 0.04049302637577057  (Learning rate: [0.0015625], Time: 3.2147s\n",
            "Epoch: 1617, Loss: 0.04048758000135422  (Learning rate: [0.0015625], Time: 3.225s\n",
            "Epoch: 1618, Loss: 0.04048212617635727  (Learning rate: [0.0015625], Time: 3.2077s\n",
            "Epoch: 1619, Loss: 0.040476683527231216  (Learning rate: [0.0015625], Time: 3.2088s\n",
            "Epoch: 1620, Loss: 0.04047113656997681  (Learning rate: [0.0015625], Time: 3.2098s\n",
            "Epoch: 1621, Loss: 0.0404658168554306  (Learning rate: [0.0015625], Time: 3.2163s\n",
            "Epoch: 1622, Loss: 0.040460363030433655  (Learning rate: [0.0015625], Time: 3.2148s\n",
            "Epoch: 1623, Loss: 0.04045477509498596  (Learning rate: [0.0015625], Time: 3.1997s\n",
            "Epoch: 1624, Loss: 0.04044885188341141  (Learning rate: [0.0015625], Time: 3.221s\n",
            "Epoch: 1625, Loss: 0.04044308885931969  (Learning rate: [0.0015625], Time: 3.2072s\n",
            "Epoch: 1626, Loss: 0.04043728858232498  (Learning rate: [0.0015625], Time: 3.2086s\n",
            "Epoch: 1627, Loss: 0.04043193161487579  (Learning rate: [0.0015625], Time: 3.2122s\n",
            "Epoch: 1628, Loss: 0.04042632505297661  (Learning rate: [0.0015625], Time: 3.2064s\n",
            "Epoch: 1629, Loss: 0.04042045399546623  (Learning rate: [0.0015625], Time: 3.2102s\n",
            "Epoch: 1630, Loss: 0.040414370596408844  (Learning rate: [0.0015625], Time: 3.2075s\n",
            "Epoch: 1631, Loss: 0.040408503264188766  (Learning rate: [0.0015625], Time: 3.2219s\n",
            "Epoch: 1632, Loss: 0.04040252044796944  (Learning rate: [0.0015625], Time: 3.2209s\n",
            "Epoch: 1633, Loss: 0.040396593511104584  (Learning rate: [0.0015625], Time: 3.2029s\n",
            "Epoch: 1634, Loss: 0.04039064049720764  (Learning rate: [0.0015625], Time: 3.2048s\n",
            "Epoch: 1635, Loss: 0.04038436338305473  (Learning rate: [0.0015625], Time: 3.2007s\n",
            "Epoch: 1636, Loss: 0.04037865251302719  (Learning rate: [0.0015625], Time: 3.2083s\n",
            "Epoch: 1637, Loss: 0.04037253558635712  (Learning rate: [0.0015625], Time: 3.2178s\n",
            "Epoch: 1638, Loss: 0.040366753935813904  (Learning rate: [0.0015625], Time: 3.21s\n",
            "Epoch: 1639, Loss: 0.040360234677791595  (Learning rate: [0.0015625], Time: 3.2253s\n",
            "Epoch: 1640, Loss: 0.040353819727897644  (Learning rate: [0.0015625], Time: 3.2122s\n",
            "Epoch: 1641, Loss: 0.0403481163084507  (Learning rate: [0.0015625], Time: 3.2151s\n",
            "Epoch: 1642, Loss: 0.040341611951589584  (Learning rate: [0.0015625], Time: 3.2101s\n",
            "Epoch: 1643, Loss: 0.04033564776182175  (Learning rate: [0.0015625], Time: 3.1963s\n",
            "Epoch: 1644, Loss: 0.0403289794921875  (Learning rate: [0.0015625], Time: 3.2036s\n",
            "Epoch: 1645, Loss: 0.040322449058294296  (Learning rate: [0.0015625], Time: 3.2039s\n",
            "Epoch: 1646, Loss: 0.04031629115343094  (Learning rate: [0.0015625], Time: 3.2177s\n",
            "Epoch: 1647, Loss: 0.040309470146894455  (Learning rate: [0.0015625], Time: 3.2165s\n",
            "Epoch: 1648, Loss: 0.04030308127403259  (Learning rate: [0.0015625], Time: 3.2078s\n",
            "Epoch: 1649, Loss: 0.04029634967446327  (Learning rate: [0.0015625], Time: 3.2111s\n",
            "Epoch: 1650, Loss: 0.040290046483278275  (Learning rate: [0.0015625], Time: 3.2109s\n",
            "Epoch: 1651, Loss: 0.040282830595970154  (Learning rate: [0.0015625], Time: 3.2153s\n",
            "Epoch: 1652, Loss: 0.04027653485536575  (Learning rate: [0.0015625], Time: 3.249s\n",
            "Epoch: 1653, Loss: 0.040269654244184494  (Learning rate: [0.0015625], Time: 3.2081s\n",
            "Epoch: 1654, Loss: 0.040263064205646515  (Learning rate: [0.0015625], Time: 3.2286s\n",
            "Epoch: 1655, Loss: 0.040256306529045105  (Learning rate: [0.0015625], Time: 3.211s\n",
            "Epoch: 1656, Loss: 0.04024946317076683  (Learning rate: [0.0015625], Time: 3.2032s\n",
            "Epoch: 1657, Loss: 0.0402425117790699  (Learning rate: [0.0015625], Time: 3.1983s\n",
            "Epoch: 1658, Loss: 0.04023600369691849  (Learning rate: [0.0015625], Time: 3.2153s\n",
            "Epoch: 1659, Loss: 0.0402291901409626  (Learning rate: [0.0015625], Time: 3.2097s\n",
            "Epoch: 1660, Loss: 0.04022250324487686  (Learning rate: [0.0015625], Time: 3.2376s\n",
            "Epoch: 1661, Loss: 0.04021680727601051  (Learning rate: [0.0015625], Time: 3.2289s\n",
            "Epoch: 1662, Loss: 0.04021006077528  (Learning rate: [0.0015625], Time: 3.2268s\n",
            "Epoch: 1663, Loss: 0.0402027890086174  (Learning rate: [0.0015625], Time: 3.2049s\n",
            "Epoch: 1664, Loss: 0.04019535332918167  (Learning rate: [0.0015625], Time: 3.2047s\n",
            "Epoch: 1665, Loss: 0.04018865153193474  (Learning rate: [0.0015625], Time: 3.2073s\n",
            "Epoch: 1666, Loss: 0.040182746946811676  (Learning rate: [0.0015625], Time: 3.2163s\n",
            "Epoch: 1667, Loss: 0.040175631642341614  (Learning rate: [0.0015625], Time: 3.205s\n",
            "Epoch: 1668, Loss: 0.04016856849193573  (Learning rate: [0.0015625], Time: 3.227s\n",
            "Epoch: 1669, Loss: 0.04016200453042984  (Learning rate: [0.0015625], Time: 3.2184s\n",
            "Epoch: 1670, Loss: 0.040155526250600815  (Learning rate: [0.0015625], Time: 3.2091s\n",
            "Epoch: 1671, Loss: 0.04014883190393448  (Learning rate: [0.0015625], Time: 3.2014s\n",
            "Epoch: 1672, Loss: 0.040141552686691284  (Learning rate: [0.0015625], Time: 3.2169s\n",
            "Epoch: 1673, Loss: 0.04013502597808838  (Learning rate: [0.0015625], Time: 3.2082s\n",
            "Epoch: 1674, Loss: 0.04012826085090637  (Learning rate: [0.0015625], Time: 3.2036s\n",
            "Epoch: 1675, Loss: 0.04012170806527138  (Learning rate: [0.0015625], Time: 3.2115s\n",
            "Epoch: 1676, Loss: 0.04011492058634758  (Learning rate: [0.0015625], Time: 3.2158s\n",
            "Epoch: 1677, Loss: 0.040108196437358856  (Learning rate: [0.0015625], Time: 3.2152s\n",
            "Epoch: 1678, Loss: 0.04010147228837013  (Learning rate: [0.0015625], Time: 3.2047s\n",
            "Epoch: 1679, Loss: 0.04009505733847618  (Learning rate: [0.0015625], Time: 3.2119s\n",
            "Epoch: 1680, Loss: 0.040088068693876266  (Learning rate: [0.0015625], Time: 3.2094s\n",
            "Epoch: 1681, Loss: 0.04008135944604874  (Learning rate: [0.0015625], Time: 3.2069s\n",
            "Epoch: 1682, Loss: 0.04007432237267494  (Learning rate: [0.0015625], Time: 3.2053s\n",
            "Epoch: 1683, Loss: 0.04006791114807129  (Learning rate: [0.0015625], Time: 3.2128s\n",
            "Epoch: 1684, Loss: 0.04006108269095421  (Learning rate: [0.0015625], Time: 3.2244s\n",
            "Epoch: 1685, Loss: 0.04005405679345131  (Learning rate: [0.0015625], Time: 3.2126s\n",
            "Epoch: 1686, Loss: 0.040047720074653625  (Learning rate: [0.0015625], Time: 3.2058s\n",
            "Epoch: 1687, Loss: 0.04004104435443878  (Learning rate: [0.0015625], Time: 3.2036s\n",
            "Epoch: 1688, Loss: 0.04003367945551872  (Learning rate: [0.0015625], Time: 3.2087s\n",
            "Epoch: 1689, Loss: 0.04002688452601433  (Learning rate: [0.0015625], Time: 3.2031s\n",
            "Epoch: 1690, Loss: 0.040020789951086044  (Learning rate: [0.0015625], Time: 3.2091s\n",
            "Epoch: 1691, Loss: 0.04001361504197121  (Learning rate: [0.0015625], Time: 3.2087s\n",
            "Epoch: 1692, Loss: 0.040006961673498154  (Learning rate: [0.0015625], Time: 3.2482s\n",
            "Epoch: 1693, Loss: 0.040000129491090775  (Learning rate: [0.0015625], Time: 3.2032s\n",
            "Epoch: 1694, Loss: 0.03999270498752594  (Learning rate: [0.0015625], Time: 3.2112s\n",
            "Epoch: 1695, Loss: 0.039985764771699905  (Learning rate: [0.0015625], Time: 3.2059s\n",
            "Epoch: 1696, Loss: 0.03997982665896416  (Learning rate: [0.0015625], Time: 3.2092s\n",
            "Epoch: 1697, Loss: 0.039972610771656036  (Learning rate: [0.0015625], Time: 3.2077s\n",
            "Epoch: 1698, Loss: 0.03996530547738075  (Learning rate: [0.0015625], Time: 3.2149s\n",
            "Epoch: 1699, Loss: 0.039957109838724136  (Learning rate: [0.0015625], Time: 3.2172s\n",
            "Epoch: 1700, Loss: 0.03994956612586975  (Learning rate: [0.0015625], Time: 3.2063s\n",
            "Epoch: 1701, Loss: 0.03994261473417282  (Learning rate: [0.0015625], Time: 3.2079s\n",
            "Epoch: 1702, Loss: 0.03993608430027962  (Learning rate: [0.0015625], Time: 3.2072s\n",
            "Epoch: 1703, Loss: 0.039928585290908813  (Learning rate: [0.0015625], Time: 3.2027s\n",
            "Epoch: 1704, Loss: 0.03992225602269173  (Learning rate: [0.0015625], Time: 3.2106s\n",
            "Epoch: 1705, Loss: 0.03991411253809929  (Learning rate: [0.0015625], Time: 3.2057s\n",
            "Epoch: 1706, Loss: 0.039907149970531464  (Learning rate: [0.0015625], Time: 3.2316s\n",
            "Epoch: 1707, Loss: 0.03989988937973976  (Learning rate: [0.0015625], Time: 3.2182s\n",
            "Epoch: 1708, Loss: 0.039892666041851044  (Learning rate: [0.0015625], Time: 3.2034s\n",
            "Epoch: 1709, Loss: 0.039885975420475006  (Learning rate: [0.0015625], Time: 3.1981s\n",
            "Epoch: 1710, Loss: 0.03987833857536316  (Learning rate: [0.0015625], Time: 3.2048s\n",
            "Epoch: 1711, Loss: 0.03987099602818489  (Learning rate: [0.0015625], Time: 3.1993s\n",
            "Epoch: 1712, Loss: 0.03986310958862305  (Learning rate: [0.0015625], Time: 3.2045s\n",
            "Epoch: 1713, Loss: 0.0398559644818306  (Learning rate: [0.0015625], Time: 3.2025s\n",
            "Epoch: 1714, Loss: 0.03984825685620308  (Learning rate: [0.0015625], Time: 3.2058s\n",
            "Epoch: 1715, Loss: 0.039841774851083755  (Learning rate: [0.0015625], Time: 3.2191s\n",
            "Epoch: 1716, Loss: 0.039833489805459976  (Learning rate: [0.0015625], Time: 3.2094s\n",
            "Epoch: 1717, Loss: 0.03982659429311752  (Learning rate: [0.0015625], Time: 3.2068s\n",
            "Epoch: 1718, Loss: 0.039821553975343704  (Learning rate: [0.0015625], Time: 3.2029s\n",
            "Epoch: 1719, Loss: 0.03981555625796318  (Learning rate: [0.0015625], Time: 3.2043s\n",
            "Epoch: 1720, Loss: 0.039811234921216965  (Learning rate: [0.0015625], Time: 3.2045s\n",
            "Epoch: 1721, Loss: 0.03980747237801552  (Learning rate: [0.0015625], Time: 3.2142s\n",
            "Epoch: 1722, Loss: 0.03979654237627983  (Learning rate: [0.0015625], Time: 3.2138s\n",
            "Epoch: 1723, Loss: 0.03978516906499863  (Learning rate: [0.0015625], Time: 3.205s\n",
            "Epoch: 1724, Loss: 0.039780694991350174  (Learning rate: [0.0015625], Time: 3.211s\n",
            "Epoch: 1725, Loss: 0.03977533429861069  (Learning rate: [0.0015625], Time: 3.2053s\n",
            "Epoch: 1726, Loss: 0.039765533059835434  (Learning rate: [0.0015625], Time: 3.2087s\n",
            "Epoch: 1727, Loss: 0.03975629061460495  (Learning rate: [0.0015625], Time: 3.2022s\n",
            "Epoch: 1728, Loss: 0.039752401411533356  (Learning rate: [0.0015625], Time: 3.2068s\n",
            "Epoch: 1729, Loss: 0.039745450019836426  (Learning rate: [0.0015625], Time: 3.208s\n",
            "Epoch: 1730, Loss: 0.039736755192279816  (Learning rate: [0.0015625], Time: 3.2187s\n",
            "Epoch: 1731, Loss: 0.03973032534122467  (Learning rate: [0.0015625], Time: 3.2124s\n",
            "Epoch: 1732, Loss: 0.039725109934806824  (Learning rate: [0.0015625], Time: 3.2056s\n",
            "Epoch: 1733, Loss: 0.03971756622195244  (Learning rate: [0.0015625], Time: 3.2184s\n",
            "Epoch: 1734, Loss: 0.03971104323863983  (Learning rate: [0.0015625], Time: 3.2057s\n",
            "Epoch: 1735, Loss: 0.03970350697636604  (Learning rate: [0.0015625], Time: 3.209s\n",
            "Epoch: 1736, Loss: 0.03969743847846985  (Learning rate: [0.0015625], Time: 3.2075s\n",
            "Epoch: 1737, Loss: 0.03969009220600128  (Learning rate: [0.0015625], Time: 3.2132s\n",
            "Epoch: 1738, Loss: 0.03968190401792526  (Learning rate: [0.0015625], Time: 3.2127s\n",
            "Epoch: 1739, Loss: 0.039675500243902206  (Learning rate: [0.0015625], Time: 3.2021s\n",
            "Epoch: 1740, Loss: 0.03966868668794632  (Learning rate: [0.0015625], Time: 3.2063s\n",
            "Epoch: 1741, Loss: 0.03966154530644417  (Learning rate: [0.0015625], Time: 3.2142s\n",
            "Epoch: 1742, Loss: 0.03965512290596962  (Learning rate: [0.0015625], Time: 3.2069s\n",
            "Epoch: 1743, Loss: 0.039648350328207016  (Learning rate: [0.0015625], Time: 3.2099s\n",
            "Epoch: 1744, Loss: 0.039641719311475754  (Learning rate: [0.0015625], Time: 3.1988s\n",
            "Epoch: 1745, Loss: 0.03963536396622658  (Learning rate: [0.0015625], Time: 3.2219s\n",
            "Epoch: 1746, Loss: 0.03962802514433861  (Learning rate: [0.0015625], Time: 3.2032s\n",
            "Epoch: 1747, Loss: 0.03962181136012077  (Learning rate: [0.0015625], Time: 3.2039s\n",
            "Epoch: 1748, Loss: 0.03961491957306862  (Learning rate: [0.0015625], Time: 3.2123s\n",
            "Epoch: 1749, Loss: 0.039607178419828415  (Learning rate: [0.0015625], Time: 3.2099s\n",
            "Epoch: 1750, Loss: 0.039601027965545654  (Learning rate: [0.0015625], Time: 3.2074s\n",
            "Epoch: 1751, Loss: 0.03959400951862335  (Learning rate: [0.0015625], Time: 3.2011s\n",
            "Epoch: 1752, Loss: 0.03958719223737717  (Learning rate: [0.0015625], Time: 3.2034s\n",
            "Epoch: 1753, Loss: 0.03957992047071457  (Learning rate: [0.0015625], Time: 3.213s\n",
            "Epoch: 1754, Loss: 0.039572328329086304  (Learning rate: [0.0015625], Time: 3.2046s\n",
            "Epoch: 1755, Loss: 0.039565131068229675  (Learning rate: [0.0015625], Time: 3.2047s\n",
            "Epoch: 1756, Loss: 0.039558760821819305  (Learning rate: [0.0015625], Time: 3.2049s\n",
            "Epoch: 1757, Loss: 0.03955172747373581  (Learning rate: [0.0015625], Time: 3.2044s\n",
            "Epoch: 1758, Loss: 0.03954550251364708  (Learning rate: [0.0015625], Time: 3.2033s\n",
            "Epoch: 1759, Loss: 0.039539698511362076  (Learning rate: [0.0015625], Time: 3.211s\n",
            "Epoch: 1760, Loss: 0.03953281790018082  (Learning rate: [0.0015625], Time: 3.2163s\n",
            "Epoch: 1761, Loss: 0.03952789306640625  (Learning rate: [0.0015625], Time: 3.2198s\n",
            "Epoch: 1762, Loss: 0.03952160105109215  (Learning rate: [0.0015625], Time: 3.2063s\n",
            "Epoch: 1763, Loss: 0.03951578587293625  (Learning rate: [0.0015625], Time: 3.2052s\n",
            "Epoch: 1764, Loss: 0.039507586508989334  (Learning rate: [0.0015625], Time: 3.2049s\n",
            "Epoch: 1765, Loss: 0.03949807956814766  (Learning rate: [0.0015625], Time: 3.2042s\n",
            "Epoch: 1766, Loss: 0.03949034959077835  (Learning rate: [0.0015625], Time: 3.2065s\n",
            "Epoch: 1767, Loss: 0.03948532044887543  (Learning rate: [0.0015625], Time: 3.2105s\n",
            "Epoch: 1768, Loss: 0.03948097303509712  (Learning rate: [0.0015625], Time: 3.2548s\n",
            "Epoch: 1769, Loss: 0.03947531059384346  (Learning rate: [0.0015625], Time: 3.2251s\n",
            "Epoch: 1770, Loss: 0.03946658596396446  (Learning rate: [0.0015625], Time: 3.1979s\n",
            "Epoch: 1771, Loss: 0.0394587367773056  (Learning rate: [0.0015625], Time: 3.2038s\n",
            "Epoch: 1772, Loss: 0.03945156931877136  (Learning rate: [0.0015625], Time: 3.2291s\n",
            "Epoch: 1773, Loss: 0.039446499198675156  (Learning rate: [0.0015625], Time: 3.2054s\n",
            "Epoch: 1774, Loss: 0.039440516382455826  (Learning rate: [0.0015625], Time: 3.2056s\n",
            "Epoch: 1775, Loss: 0.03943260386586189  (Learning rate: [0.0015625], Time: 3.2141s\n",
            "Epoch: 1776, Loss: 0.03942525014281273  (Learning rate: [0.0015625], Time: 3.2124s\n",
            "Epoch: 1777, Loss: 0.039418481290340424  (Learning rate: [0.0015625], Time: 3.203s\n",
            "Epoch: 1778, Loss: 0.03941190987825394  (Learning rate: [0.0015625], Time: 3.2054s\n",
            "Epoch: 1779, Loss: 0.03940581902861595  (Learning rate: [0.0015625], Time: 3.2089s\n",
            "Epoch: 1780, Loss: 0.03939926624298096  (Learning rate: [0.0015625], Time: 3.2011s\n",
            "Epoch: 1781, Loss: 0.039392177015542984  (Learning rate: [0.0015625], Time: 3.2076s\n",
            "Epoch: 1782, Loss: 0.039384935051202774  (Learning rate: [0.0015625], Time: 3.2063s\n",
            "Epoch: 1783, Loss: 0.03937870264053345  (Learning rate: [0.0015625], Time: 3.2163s\n",
            "Epoch: 1784, Loss: 0.03937193378806114  (Learning rate: [0.0015625], Time: 3.2231s\n",
            "Epoch: 1785, Loss: 0.03936585411429405  (Learning rate: [0.0015625], Time: 3.2127s\n",
            "Epoch: 1786, Loss: 0.03935950621962547  (Learning rate: [0.0015625], Time: 3.2069s\n",
            "Epoch: 1787, Loss: 0.03935302048921585  (Learning rate: [0.0015625], Time: 3.2114s\n",
            "Epoch: 1788, Loss: 0.03934618458151817  (Learning rate: [0.0015625], Time: 3.2109s\n",
            "Epoch: 1789, Loss: 0.03933960944414139  (Learning rate: [0.0015625], Time: 3.2041s\n",
            "Epoch: 1790, Loss: 0.039332590997219086  (Learning rate: [0.0015625], Time: 3.2097s\n",
            "Epoch: 1791, Loss: 0.039326805621385574  (Learning rate: [0.0015625], Time: 3.2259s\n",
            "Epoch: 1792, Loss: 0.0393204502761364  (Learning rate: [0.0015625], Time: 3.2175s\n",
            "Epoch: 1793, Loss: 0.03931419923901558  (Learning rate: [0.0015625], Time: 3.2021s\n",
            "Epoch: 1794, Loss: 0.03930824622511864  (Learning rate: [0.0015625], Time: 3.2055s\n",
            "Epoch: 1795, Loss: 0.03930175304412842  (Learning rate: [0.0015625], Time: 3.2028s\n",
            "Epoch: 1796, Loss: 0.03929544985294342  (Learning rate: [0.0015625], Time: 3.213s\n",
            "Epoch: 1797, Loss: 0.03928801417350769  (Learning rate: [0.0015625], Time: 3.1985s\n",
            "Epoch: 1798, Loss: 0.039281461387872696  (Learning rate: [0.0015625], Time: 3.2018s\n",
            "Epoch: 1799, Loss: 0.03927522897720337  (Learning rate: [0.0015625], Time: 3.2125s\n",
            "Epoch: 1800, Loss: 0.03926844522356987  (Learning rate: [0.00078125], Time: 3.2126s\n",
            "Epoch: 1801, Loss: 0.03926263377070427  (Learning rate: [0.00078125], Time: 3.2134s\n",
            "Epoch: 1802, Loss: 0.03925780579447746  (Learning rate: [0.00078125], Time: 3.2031s\n",
            "Epoch: 1803, Loss: 0.03925503417849541  (Learning rate: [0.00078125], Time: 3.214s\n",
            "Epoch: 1804, Loss: 0.03925153240561485  (Learning rate: [0.00078125], Time: 3.1993s\n",
            "Epoch: 1805, Loss: 0.039248090237379074  (Learning rate: [0.00078125], Time: 3.2045s\n",
            "Epoch: 1806, Loss: 0.03924503177404404  (Learning rate: [0.00078125], Time: 3.2114s\n",
            "Epoch: 1807, Loss: 0.039241354912519455  (Learning rate: [0.00078125], Time: 3.2068s\n",
            "Epoch: 1808, Loss: 0.039238303899765015  (Learning rate: [0.00078125], Time: 3.1914s\n",
            "Epoch: 1809, Loss: 0.03923490270972252  (Learning rate: [0.00078125], Time: 3.204s\n",
            "Epoch: 1810, Loss: 0.039231691509485245  (Learning rate: [0.00078125], Time: 3.2071s\n",
            "Epoch: 1811, Loss: 0.039228226989507675  (Learning rate: [0.00078125], Time: 3.1972s\n",
            "Epoch: 1812, Loss: 0.03922513127326965  (Learning rate: [0.00078125], Time: 3.2092s\n",
            "Epoch: 1813, Loss: 0.03922191634774208  (Learning rate: [0.00078125], Time: 3.2087s\n",
            "Epoch: 1814, Loss: 0.039218444377183914  (Learning rate: [0.00078125], Time: 3.2224s\n",
            "Epoch: 1815, Loss: 0.03921541944146156  (Learning rate: [0.00078125], Time: 3.2197s\n",
            "Epoch: 1816, Loss: 0.03921202942728996  (Learning rate: [0.00078125], Time: 3.2012s\n",
            "Epoch: 1817, Loss: 0.03920890763401985  (Learning rate: [0.00078125], Time: 3.2115s\n",
            "Epoch: 1818, Loss: 0.03920561075210571  (Learning rate: [0.00078125], Time: 3.2154s\n",
            "Epoch: 1819, Loss: 0.03920239955186844  (Learning rate: [0.00078125], Time: 3.2175s\n",
            "Epoch: 1820, Loss: 0.03919919580221176  (Learning rate: [0.00078125], Time: 3.2279s\n",
            "Epoch: 1821, Loss: 0.03919592127203941  (Learning rate: [0.00078125], Time: 3.2046s\n",
            "Epoch: 1822, Loss: 0.03919275104999542  (Learning rate: [0.00078125], Time: 3.2107s\n",
            "Epoch: 1823, Loss: 0.03918949142098427  (Learning rate: [0.00078125], Time: 3.2288s\n",
            "Epoch: 1824, Loss: 0.03918631747364998  (Learning rate: [0.00078125], Time: 3.2132s\n",
            "Epoch: 1825, Loss: 0.039183080196380615  (Learning rate: [0.00078125], Time: 3.2053s\n",
            "Epoch: 1826, Loss: 0.03917988762259483  (Learning rate: [0.00078125], Time: 3.2052s\n",
            "Epoch: 1827, Loss: 0.039176661521196365  (Learning rate: [0.00078125], Time: 3.207s\n",
            "Epoch: 1828, Loss: 0.03917349502444267  (Learning rate: [0.00078125], Time: 3.2051s\n",
            "Epoch: 1829, Loss: 0.03917025774717331  (Learning rate: [0.00078125], Time: 3.2081s\n",
            "Epoch: 1830, Loss: 0.03916710242629051  (Learning rate: [0.00078125], Time: 3.2184s\n",
            "Epoch: 1831, Loss: 0.039163876324892044  (Learning rate: [0.00078125], Time: 3.2014s\n",
            "Epoch: 1832, Loss: 0.03916069120168686  (Learning rate: [0.00078125], Time: 3.2012s\n",
            "Epoch: 1833, Loss: 0.03915749490261078  (Learning rate: [0.00078125], Time: 3.2023s\n",
            "Epoch: 1834, Loss: 0.03915431350469589  (Learning rate: [0.00078125], Time: 3.2014s\n",
            "Epoch: 1835, Loss: 0.039151109755039215  (Learning rate: [0.00078125], Time: 3.204s\n",
            "Epoch: 1836, Loss: 0.03914795070886612  (Learning rate: [0.00078125], Time: 3.2053s\n",
            "Epoch: 1837, Loss: 0.03914473205804825  (Learning rate: [0.00078125], Time: 3.222s\n",
            "Epoch: 1838, Loss: 0.03914157301187515  (Learning rate: [0.00078125], Time: 3.2149s\n",
            "Epoch: 1839, Loss: 0.03913837671279907  (Learning rate: [0.00078125], Time: 3.2002s\n",
            "Epoch: 1840, Loss: 0.03913520649075508  (Learning rate: [0.00078125], Time: 3.2133s\n",
            "Epoch: 1841, Loss: 0.0391320176422596  (Learning rate: [0.00078125], Time: 3.2081s\n",
            "Epoch: 1842, Loss: 0.039128851145505905  (Learning rate: [0.00078125], Time: 3.2204s\n",
            "Epoch: 1843, Loss: 0.03912566974759102  (Learning rate: [0.00078125], Time: 3.2087s\n",
            "Epoch: 1844, Loss: 0.03912249580025673  (Learning rate: [0.00078125], Time: 3.2361s\n",
            "Epoch: 1845, Loss: 0.03911932557821274  (Learning rate: [0.00078125], Time: 3.2637s\n",
            "Epoch: 1846, Loss: 0.03911615163087845  (Learning rate: [0.00078125], Time: 3.2044s\n",
            "Epoch: 1847, Loss: 0.039112985134124756  (Learning rate: [0.00078125], Time: 3.2027s\n",
            "Epoch: 1848, Loss: 0.03910981863737106  (Learning rate: [0.00078125], Time: 3.195s\n",
            "Epoch: 1849, Loss: 0.03910664841532707  (Learning rate: [0.00078125], Time: 3.2128s\n",
            "Epoch: 1850, Loss: 0.03910348564386368  (Learning rate: [0.00078125], Time: 3.2106s\n",
            "Epoch: 1851, Loss: 0.039100319147109985  (Learning rate: [0.00078125], Time: 3.209s\n",
            "Epoch: 1852, Loss: 0.03909716382622719  (Learning rate: [0.00078125], Time: 3.2127s\n",
            "Epoch: 1853, Loss: 0.039093997329473495  (Learning rate: [0.00078125], Time: 3.2093s\n",
            "Epoch: 1854, Loss: 0.0390908420085907  (Learning rate: [0.00078125], Time: 3.2092s\n",
            "Epoch: 1855, Loss: 0.0390876829624176  (Learning rate: [0.00078125], Time: 3.2102s\n",
            "Epoch: 1856, Loss: 0.03908452391624451  (Learning rate: [0.00078125], Time: 3.2048s\n",
            "Epoch: 1857, Loss: 0.03908136859536171  (Learning rate: [0.00078125], Time: 3.2008s\n",
            "Epoch: 1858, Loss: 0.03907821327447891  (Learning rate: [0.00078125], Time: 3.2023s\n",
            "Epoch: 1859, Loss: 0.03907506540417671  (Learning rate: [0.00078125], Time: 3.2118s\n",
            "Epoch: 1860, Loss: 0.03907191380858421  (Learning rate: [0.00078125], Time: 3.2215s\n",
            "Epoch: 1861, Loss: 0.039068762212991714  (Learning rate: [0.00078125], Time: 3.2215s\n",
            "Epoch: 1862, Loss: 0.039065614342689514  (Learning rate: [0.00078125], Time: 3.2086s\n",
            "Epoch: 1863, Loss: 0.039062462747097015  (Learning rate: [0.00078125], Time: 3.2182s\n",
            "Epoch: 1864, Loss: 0.039059318602085114  (Learning rate: [0.00078125], Time: 3.213s\n",
            "Epoch: 1865, Loss: 0.03905617445707321  (Learning rate: [0.00078125], Time: 3.2095s\n",
            "Epoch: 1866, Loss: 0.03905303031206131  (Learning rate: [0.00078125], Time: 3.2099s\n",
            "Epoch: 1867, Loss: 0.039049889892339706  (Learning rate: [0.00078125], Time: 3.2195s\n",
            "Epoch: 1868, Loss: 0.0390467494726181  (Learning rate: [0.00078125], Time: 3.2228s\n",
            "Epoch: 1869, Loss: 0.0390436127781868  (Learning rate: [0.00078125], Time: 3.2091s\n",
            "Epoch: 1870, Loss: 0.039040472358465195  (Learning rate: [0.00078125], Time: 3.2133s\n",
            "Epoch: 1871, Loss: 0.03903733193874359  (Learning rate: [0.00078125], Time: 3.2045s\n",
            "Epoch: 1872, Loss: 0.039034198969602585  (Learning rate: [0.00078125], Time: 3.1993s\n",
            "Epoch: 1873, Loss: 0.03903106227517128  (Learning rate: [0.00078125], Time: 3.2072s\n",
            "Epoch: 1874, Loss: 0.03902792930603027  (Learning rate: [0.00078125], Time: 3.2104s\n",
            "Epoch: 1875, Loss: 0.03902479633688927  (Learning rate: [0.00078125], Time: 3.2237s\n",
            "Epoch: 1876, Loss: 0.03902166336774826  (Learning rate: [0.00078125], Time: 3.2246s\n",
            "Epoch: 1877, Loss: 0.03901853412389755  (Learning rate: [0.00078125], Time: 3.2041s\n",
            "Epoch: 1878, Loss: 0.039015401154756546  (Learning rate: [0.00078125], Time: 3.2091s\n",
            "Epoch: 1879, Loss: 0.03901227191090584  (Learning rate: [0.00078125], Time: 3.2069s\n",
            "Epoch: 1880, Loss: 0.03900914266705513  (Learning rate: [0.00078125], Time: 3.2109s\n",
            "Epoch: 1881, Loss: 0.03900601714849472  (Learning rate: [0.00078125], Time: 3.203s\n",
            "Epoch: 1882, Loss: 0.03900288790464401  (Learning rate: [0.00078125], Time: 3.2152s\n",
            "Epoch: 1883, Loss: 0.038999758660793304  (Learning rate: [0.00078125], Time: 3.2178s\n",
            "Epoch: 1884, Loss: 0.038996633142232895  (Learning rate: [0.00078125], Time: 3.2136s\n",
            "Epoch: 1885, Loss: 0.03899350389838219  (Learning rate: [0.00078125], Time: 3.1961s\n",
            "Epoch: 1886, Loss: 0.03899037465453148  (Learning rate: [0.00078125], Time: 3.2065s\n",
            "Epoch: 1887, Loss: 0.03898724541068077  (Learning rate: [0.00078125], Time: 3.2134s\n",
            "Epoch: 1888, Loss: 0.03898411616683006  (Learning rate: [0.00078125], Time: 3.2114s\n",
            "Epoch: 1889, Loss: 0.038980983197689056  (Learning rate: [0.00078125], Time: 3.2079s\n",
            "Epoch: 1890, Loss: 0.03897785022854805  (Learning rate: [0.00078125], Time: 3.2138s\n",
            "Epoch: 1891, Loss: 0.03897470980882645  (Learning rate: [0.00078125], Time: 3.2163s\n",
            "Epoch: 1892, Loss: 0.03897156938910484  (Learning rate: [0.00078125], Time: 3.2078s\n",
            "Epoch: 1893, Loss: 0.03896842151880264  (Learning rate: [0.00078125], Time: 3.2087s\n",
            "Epoch: 1894, Loss: 0.038965269923210144  (Learning rate: [0.00078125], Time: 3.2141s\n",
            "Epoch: 1895, Loss: 0.03896211087703705  (Learning rate: [0.00078125], Time: 3.2075s\n",
            "Epoch: 1896, Loss: 0.03895893692970276  (Learning rate: [0.00078125], Time: 3.2108s\n",
            "Epoch: 1897, Loss: 0.03895575553178787  (Learning rate: [0.00078125], Time: 3.2087s\n",
            "Epoch: 1898, Loss: 0.038952555507421494  (Learning rate: [0.00078125], Time: 3.2401s\n",
            "Epoch: 1899, Loss: 0.03894934058189392  (Learning rate: [0.00078125], Time: 3.203s\n",
            "Epoch: 1900, Loss: 0.038946107029914856  (Learning rate: [0.00078125], Time: 3.2022s\n",
            "Epoch: 1901, Loss: 0.038942851126194  (Learning rate: [0.00078125], Time: 3.2021s\n",
            "Epoch: 1902, Loss: 0.038939572870731354  (Learning rate: [0.00078125], Time: 3.2093s\n",
            "Epoch: 1903, Loss: 0.03893627971410751  (Learning rate: [0.00078125], Time: 3.2068s\n",
            "Epoch: 1904, Loss: 0.038932979106903076  (Learning rate: [0.00078125], Time: 3.2038s\n",
            "Epoch: 1905, Loss: 0.03892970085144043  (Learning rate: [0.00078125], Time: 3.2007s\n",
            "Epoch: 1906, Loss: 0.03892647475004196  (Learning rate: [0.00078125], Time: 3.2124s\n",
            "Epoch: 1907, Loss: 0.038923297077417374  (Learning rate: [0.00078125], Time: 3.2088s\n",
            "Epoch: 1908, Loss: 0.03892013803124428  (Learning rate: [0.00078125], Time: 3.189s\n",
            "Epoch: 1909, Loss: 0.0389169417321682  (Learning rate: [0.00078125], Time: 3.2059s\n",
            "Epoch: 1910, Loss: 0.038913678377866745  (Learning rate: [0.00078125], Time: 3.2212s\n",
            "Epoch: 1911, Loss: 0.03891037032008171  (Learning rate: [0.00078125], Time: 3.2086s\n",
            "Epoch: 1912, Loss: 0.03890705481171608  (Learning rate: [0.00078125], Time: 3.2088s\n",
            "Epoch: 1913, Loss: 0.03890375792980194  (Learning rate: [0.00078125], Time: 3.2051s\n",
            "Epoch: 1914, Loss: 0.03890048339962959  (Learning rate: [0.00078125], Time: 3.2142s\n",
            "Epoch: 1915, Loss: 0.03889722749590874  (Learning rate: [0.00078125], Time: 3.2073s\n",
            "Epoch: 1916, Loss: 0.03889396786689758  (Learning rate: [0.00078125], Time: 3.2007s\n",
            "Epoch: 1917, Loss: 0.03889070078730583  (Learning rate: [0.00078125], Time: 3.2015s\n",
            "Epoch: 1918, Loss: 0.03888741880655289  (Learning rate: [0.00078125], Time: 3.2028s\n",
            "Epoch: 1919, Loss: 0.03888411447405815  (Learning rate: [0.00078125], Time: 3.2096s\n",
            "Epoch: 1920, Loss: 0.03888080641627312  (Learning rate: [0.00078125], Time: 3.2128s\n",
            "Epoch: 1921, Loss: 0.03887750580906868  (Learning rate: [0.00078125], Time: 3.2166s\n",
            "Epoch: 1922, Loss: 0.03887420892715454  (Learning rate: [0.00078125], Time: 3.2176s\n",
            "Epoch: 1923, Loss: 0.0388709232211113  (Learning rate: [0.00078125], Time: 3.2047s\n",
            "Epoch: 1924, Loss: 0.03886763006448746  (Learning rate: [0.00078125], Time: 3.2045s\n",
            "Epoch: 1925, Loss: 0.03886432945728302  (Learning rate: [0.00078125], Time: 3.2175s\n",
            "Epoch: 1926, Loss: 0.038861025124788284  (Learning rate: [0.00078125], Time: 3.2133s\n",
            "Epoch: 1927, Loss: 0.03885771334171295  (Learning rate: [0.00078125], Time: 3.2141s\n",
            "Epoch: 1928, Loss: 0.03885440528392792  (Learning rate: [0.00078125], Time: 3.2131s\n",
            "Epoch: 1929, Loss: 0.03885109722614288  (Learning rate: [0.00078125], Time: 3.2295s\n",
            "Epoch: 1930, Loss: 0.03884779289364815  (Learning rate: [0.00078125], Time: 3.2315s\n",
            "Epoch: 1931, Loss: 0.03884449228644371  (Learning rate: [0.00078125], Time: 3.2172s\n",
            "Epoch: 1932, Loss: 0.038841187953948975  (Learning rate: [0.00078125], Time: 3.2122s\n",
            "Epoch: 1933, Loss: 0.03883788362145424  (Learning rate: [0.00078125], Time: 3.2096s\n",
            "Epoch: 1934, Loss: 0.038834571838378906  (Learning rate: [0.00078125], Time: 3.2051s\n",
            "Epoch: 1935, Loss: 0.03883126378059387  (Learning rate: [0.00078125], Time: 3.2101s\n",
            "Epoch: 1936, Loss: 0.03882795572280884  (Learning rate: [0.00078125], Time: 3.2193s\n",
            "Epoch: 1937, Loss: 0.0388246551156044  (Learning rate: [0.00078125], Time: 3.2156s\n",
            "Epoch: 1938, Loss: 0.03882135450839996  (Learning rate: [0.00078125], Time: 3.2167s\n",
            "Epoch: 1939, Loss: 0.038818053901195526  (Learning rate: [0.00078125], Time: 3.2031s\n",
            "Epoch: 1940, Loss: 0.03881475701928139  (Learning rate: [0.00078125], Time: 3.2088s\n",
            "Epoch: 1941, Loss: 0.03881145641207695  (Learning rate: [0.00078125], Time: 3.2078s\n",
            "Epoch: 1942, Loss: 0.03880815953016281  (Learning rate: [0.00078125], Time: 3.2033s\n",
            "Epoch: 1943, Loss: 0.03880486637353897  (Learning rate: [0.00078125], Time: 3.2093s\n",
            "Epoch: 1944, Loss: 0.03880157321691513  (Learning rate: [0.00078125], Time: 3.2135s\n",
            "Epoch: 1945, Loss: 0.03879828006029129  (Learning rate: [0.00078125], Time: 3.2239s\n",
            "Epoch: 1946, Loss: 0.03879499435424805  (Learning rate: [0.00078125], Time: 3.2066s\n",
            "Epoch: 1947, Loss: 0.0387917086482048  (Learning rate: [0.00078125], Time: 3.1999s\n",
            "Epoch: 1948, Loss: 0.03878842666745186  (Learning rate: [0.00078125], Time: 3.2066s\n",
            "Epoch: 1949, Loss: 0.038785140961408615  (Learning rate: [0.00078125], Time: 3.2136s\n",
            "Epoch: 1950, Loss: 0.03878186270594597  (Learning rate: [0.00078125], Time: 3.2013s\n",
            "Epoch: 1951, Loss: 0.03877858817577362  (Learning rate: [0.00078125], Time: 3.2156s\n",
            "Epoch: 1952, Loss: 0.03877531364560127  (Learning rate: [0.00078125], Time: 3.2172s\n",
            "Epoch: 1953, Loss: 0.03877204284071922  (Learning rate: [0.00078125], Time: 3.2111s\n",
            "Epoch: 1954, Loss: 0.03876877576112747  (Learning rate: [0.00078125], Time: 3.2043s\n",
            "Epoch: 1955, Loss: 0.03876550868153572  (Learning rate: [0.00078125], Time: 3.2162s\n",
            "Epoch: 1956, Loss: 0.03876224905252457  (Learning rate: [0.00078125], Time: 3.2001s\n",
            "Epoch: 1957, Loss: 0.03875898942351341  (Learning rate: [0.00078125], Time: 3.2087s\n",
            "Epoch: 1958, Loss: 0.03875573351979256  (Learning rate: [0.00078125], Time: 3.1985s\n",
            "Epoch: 1959, Loss: 0.038752481341362  (Learning rate: [0.00078125], Time: 3.2178s\n",
            "Epoch: 1960, Loss: 0.03874922916293144  (Learning rate: [0.00078125], Time: 3.2278s\n",
            "Epoch: 1961, Loss: 0.038745980709791183  (Learning rate: [0.00078125], Time: 3.2083s\n",
            "Epoch: 1962, Loss: 0.03874273970723152  (Learning rate: [0.00078125], Time: 3.2204s\n",
            "Epoch: 1963, Loss: 0.03873950242996216  (Learning rate: [0.00078125], Time: 3.2035s\n",
            "Epoch: 1964, Loss: 0.038736261427402496  (Learning rate: [0.00078125], Time: 3.2072s\n",
            "Epoch: 1965, Loss: 0.03873302787542343  (Learning rate: [0.00078125], Time: 3.2003s\n",
            "Epoch: 1966, Loss: 0.03872980177402496  (Learning rate: [0.00078125], Time: 3.2008s\n",
            "Epoch: 1967, Loss: 0.0387265719473362  (Learning rate: [0.00078125], Time: 3.2109s\n",
            "Epoch: 1968, Loss: 0.03872334957122803  (Learning rate: [0.00078125], Time: 3.2084s\n",
            "Epoch: 1969, Loss: 0.03872012719511986  (Learning rate: [0.00078125], Time: 3.2012s\n",
            "Epoch: 1970, Loss: 0.038716912269592285  (Learning rate: [0.00078125], Time: 3.1952s\n",
            "Epoch: 1971, Loss: 0.03871369734406471  (Learning rate: [0.00078125], Time: 3.2151s\n",
            "Epoch: 1972, Loss: 0.03871048614382744  (Learning rate: [0.00078125], Time: 3.2021s\n",
            "Epoch: 1973, Loss: 0.03870728239417076  (Learning rate: [0.00078125], Time: 3.199s\n",
            "Epoch: 1974, Loss: 0.038704074919223785  (Learning rate: [0.00078125], Time: 3.1945s\n",
            "Epoch: 1975, Loss: 0.03870087489485741  (Learning rate: [0.00078125], Time: 3.1936s\n",
            "Epoch: 1976, Loss: 0.03869767487049103  (Learning rate: [0.00078125], Time: 3.1996s\n",
            "Epoch: 1977, Loss: 0.038694482296705246  (Learning rate: [0.00078125], Time: 3.1932s\n",
            "Epoch: 1978, Loss: 0.038691285997629166  (Learning rate: [0.00078125], Time: 3.1927s\n",
            "Epoch: 1979, Loss: 0.03868810087442398  (Learning rate: [0.00078125], Time: 3.2015s\n",
            "Epoch: 1980, Loss: 0.038684915751218796  (Learning rate: [0.00078125], Time: 3.1868s\n",
            "Epoch: 1981, Loss: 0.03868173062801361  (Learning rate: [0.00078125], Time: 3.2016s\n",
            "Epoch: 1982, Loss: 0.038678549230098724  (Learning rate: [0.00078125], Time: 3.2088s\n",
            "Epoch: 1983, Loss: 0.038675371557474136  (Learning rate: [0.00078125], Time: 3.2191s\n",
            "Epoch: 1984, Loss: 0.038672201335430145  (Learning rate: [0.00078125], Time: 3.1967s\n",
            "Epoch: 1985, Loss: 0.038669027388095856  (Learning rate: [0.00078125], Time: 3.1985s\n",
            "Epoch: 1986, Loss: 0.038665857166051865  (Learning rate: [0.00078125], Time: 3.1879s\n",
            "Epoch: 1987, Loss: 0.03866269439458847  (Learning rate: [0.00078125], Time: 3.2004s\n",
            "Epoch: 1988, Loss: 0.038659531623125076  (Learning rate: [0.00078125], Time: 3.1939s\n",
            "Epoch: 1989, Loss: 0.03865636885166168  (Learning rate: [0.00078125], Time: 3.2146s\n",
            "Epoch: 1990, Loss: 0.038653213530778885  (Learning rate: [0.00078125], Time: 3.2097s\n",
            "Epoch: 1991, Loss: 0.03865005820989609  (Learning rate: [0.00078125], Time: 3.213s\n",
            "Epoch: 1992, Loss: 0.03864690288901329  (Learning rate: [0.00078125], Time: 3.2072s\n",
            "Epoch: 1993, Loss: 0.03864375874400139  (Learning rate: [0.00078125], Time: 3.2047s\n",
            "Epoch: 1994, Loss: 0.03864061087369919  (Learning rate: [0.00078125], Time: 3.2045s\n",
            "Epoch: 1995, Loss: 0.03863746300339699  (Learning rate: [0.00078125], Time: 3.1855s\n",
            "Epoch: 1996, Loss: 0.038634322583675385  (Learning rate: [0.00078125], Time: 3.18s\n",
            "Epoch: 1997, Loss: 0.03863118216395378  (Learning rate: [0.00078125], Time: 3.2099s\n",
            "Epoch: 1998, Loss: 0.038628045469522476  (Learning rate: [0.00078125], Time: 3.1875s\n",
            "Epoch: 1999, Loss: 0.03862491250038147  (Learning rate: [0.00078125], Time: 3.1956s\n",
            "Epoch: 2000, Loss: 0.038621775805950165  (Learning rate: [0.00078125], Time: 3.2122s\n",
            "Epoch: 2001, Loss: 0.03861864656209946  (Learning rate: [0.00078125], Time: 3.2111s\n",
            "Epoch: 2002, Loss: 0.03861552104353905  (Learning rate: [0.00078125], Time: 3.2119s\n",
            "Epoch: 2003, Loss: 0.03861239179968834  (Learning rate: [0.00078125], Time: 3.2113s\n",
            "Epoch: 2004, Loss: 0.03860927000641823  (Learning rate: [0.00078125], Time: 3.2006s\n",
            "Epoch: 2005, Loss: 0.038606151938438416  (Learning rate: [0.00078125], Time: 3.2014s\n",
            "Epoch: 2006, Loss: 0.0386030375957489  (Learning rate: [0.00078125], Time: 3.2022s\n",
            "Epoch: 2007, Loss: 0.038599926978349686  (Learning rate: [0.00078125], Time: 3.2034s\n",
            "Epoch: 2008, Loss: 0.038596831262111664  (Learning rate: [0.00078125], Time: 3.2185s\n",
            "Epoch: 2009, Loss: 0.03859373927116394  (Learning rate: [0.00078125], Time: 3.206s\n",
            "Epoch: 2010, Loss: 0.038590628653764725  (Learning rate: [0.00078125], Time: 3.2012s\n",
            "Epoch: 2011, Loss: 0.03858752176165581  (Learning rate: [0.00078125], Time: 3.2017s\n",
            "Epoch: 2012, Loss: 0.038584381341934204  (Learning rate: [0.00078125], Time: 3.2029s\n",
            "Epoch: 2013, Loss: 0.03858125954866409  (Learning rate: [0.00078125], Time: 3.2064s\n",
            "Epoch: 2014, Loss: 0.03857816010713577  (Learning rate: [0.00078125], Time: 3.1895s\n",
            "Epoch: 2015, Loss: 0.038575075566768646  (Learning rate: [0.00078125], Time: 3.2158s\n",
            "Epoch: 2016, Loss: 0.03857201337814331  (Learning rate: [0.00078125], Time: 3.2107s\n",
            "Epoch: 2017, Loss: 0.03856893256306648  (Learning rate: [0.00078125], Time: 3.206s\n",
            "Epoch: 2018, Loss: 0.03856586292386055  (Learning rate: [0.00078125], Time: 3.1978s\n",
            "Epoch: 2019, Loss: 0.038562703877687454  (Learning rate: [0.00078125], Time: 3.2092s\n",
            "Epoch: 2020, Loss: 0.03855959698557854  (Learning rate: [0.00078125], Time: 3.1976s\n",
            "Epoch: 2021, Loss: 0.0385565422475338  (Learning rate: [0.00078125], Time: 3.1882s\n",
            "Epoch: 2022, Loss: 0.03855348005890846  (Learning rate: [0.00078125], Time: 3.1823s\n",
            "Epoch: 2023, Loss: 0.03855043649673462  (Learning rate: [0.00078125], Time: 3.1907s\n",
            "Epoch: 2024, Loss: 0.038547269999980927  (Learning rate: [0.00078125], Time: 3.2066s\n",
            "Epoch: 2025, Loss: 0.038544174283742905  (Learning rate: [0.00078125], Time: 3.2055s\n",
            "Epoch: 2026, Loss: 0.03854113072156906  (Learning rate: [0.00078125], Time: 3.1953s\n",
            "Epoch: 2027, Loss: 0.038538068532943726  (Learning rate: [0.00078125], Time: 3.1967s\n",
            "Epoch: 2028, Loss: 0.038535021245479584  (Learning rate: [0.00078125], Time: 3.2086s\n",
            "Epoch: 2029, Loss: 0.03853188082575798  (Learning rate: [0.00078125], Time: 3.2237s\n",
            "Epoch: 2030, Loss: 0.03852878138422966  (Learning rate: [0.00078125], Time: 3.2004s\n",
            "Epoch: 2031, Loss: 0.03852573409676552  (Learning rate: [0.00078125], Time: 3.2235s\n",
            "Epoch: 2032, Loss: 0.03852269798517227  (Learning rate: [0.00078125], Time: 3.2063s\n",
            "Epoch: 2033, Loss: 0.03851968050003052  (Learning rate: [0.00078125], Time: 3.206s\n",
            "Epoch: 2034, Loss: 0.03851652890443802  (Learning rate: [0.00078125], Time: 3.1967s\n",
            "Epoch: 2035, Loss: 0.0385134331882  (Learning rate: [0.00078125], Time: 3.1754s\n",
            "Epoch: 2036, Loss: 0.03851039335131645  (Learning rate: [0.00078125], Time: 3.1843s\n",
            "Epoch: 2037, Loss: 0.038507360965013504  (Learning rate: [0.00078125], Time: 3.1827s\n",
            "Epoch: 2038, Loss: 0.03850435093045235  (Learning rate: [0.00078125], Time: 3.1862s\n",
            "Epoch: 2039, Loss: 0.03850121051073074  (Learning rate: [0.00078125], Time: 3.1906s\n",
            "Epoch: 2040, Loss: 0.03849812597036362  (Learning rate: [0.00078125], Time: 3.1925s\n",
            "Epoch: 2041, Loss: 0.03849509730935097  (Learning rate: [0.00078125], Time: 3.1771s\n",
            "Epoch: 2042, Loss: 0.038492072373628616  (Learning rate: [0.00078125], Time: 3.1873s\n",
            "Epoch: 2043, Loss: 0.03848906606435776  (Learning rate: [0.00078125], Time: 3.2063s\n",
            "Epoch: 2044, Loss: 0.03848592936992645  (Learning rate: [0.00078125], Time: 3.2045s\n",
            "Epoch: 2045, Loss: 0.03848285600543022  (Learning rate: [0.00078125], Time: 3.2082s\n",
            "Epoch: 2046, Loss: 0.038479842245578766  (Learning rate: [0.00078125], Time: 3.1933s\n",
            "Epoch: 2047, Loss: 0.038476817309856415  (Learning rate: [0.00078125], Time: 3.217s\n",
            "Epoch: 2048, Loss: 0.03847380727529526  (Learning rate: [0.00078125], Time: 3.2181s\n",
            "Epoch: 2049, Loss: 0.03847069665789604  (Learning rate: [0.00078125], Time: 3.1963s\n",
            "Epoch: 2050, Loss: 0.03846762329339981  (Learning rate: [0.00078125], Time: 3.2056s\n",
            "Epoch: 2051, Loss: 0.03846459463238716  (Learning rate: [0.00078125], Time: 3.2194s\n",
            "Epoch: 2052, Loss: 0.0384615957736969  (Learning rate: [0.00078125], Time: 3.1987s\n",
            "Epoch: 2053, Loss: 0.038458630442619324  (Learning rate: [0.00078125], Time: 3.2027s\n",
            "Epoch: 2054, Loss: 0.03845555707812309  (Learning rate: [0.00078125], Time: 3.2105s\n",
            "Epoch: 2055, Loss: 0.03845251351594925  (Learning rate: [0.00078125], Time: 3.2158s\n",
            "Epoch: 2056, Loss: 0.03844950720667839  (Learning rate: [0.00078125], Time: 3.2106s\n",
            "Epoch: 2057, Loss: 0.03844652697443962  (Learning rate: [0.00078125], Time: 3.1999s\n",
            "Epoch: 2058, Loss: 0.03844357281923294  (Learning rate: [0.00078125], Time: 3.2068s\n",
            "Epoch: 2059, Loss: 0.03844055160880089  (Learning rate: [0.00078125], Time: 3.1922s\n",
            "Epoch: 2060, Loss: 0.03843752294778824  (Learning rate: [0.00078125], Time: 3.1991s\n",
            "Epoch: 2061, Loss: 0.03843436390161514  (Learning rate: [0.00078125], Time: 3.1907s\n",
            "Epoch: 2062, Loss: 0.03843126446008682  (Learning rate: [0.00078125], Time: 3.2002s\n",
            "Epoch: 2063, Loss: 0.038428232073783875  (Learning rate: [0.00078125], Time: 3.2148s\n",
            "Epoch: 2064, Loss: 0.038425251841545105  (Learning rate: [0.00078125], Time: 3.2087s\n",
            "Epoch: 2065, Loss: 0.03842233121395111  (Learning rate: [0.00078125], Time: 3.1904s\n",
            "Epoch: 2066, Loss: 0.03841928765177727  (Learning rate: [0.00078125], Time: 3.2047s\n",
            "Epoch: 2067, Loss: 0.03841627389192581  (Learning rate: [0.00078125], Time: 3.1967s\n",
            "Epoch: 2068, Loss: 0.03841325268149376  (Learning rate: [0.00078125], Time: 3.2025s\n",
            "Epoch: 2069, Loss: 0.03841022402048111  (Learning rate: [0.00078125], Time: 3.2456s\n",
            "Epoch: 2070, Loss: 0.03840722143650055  (Learning rate: [0.00078125], Time: 3.1902s\n",
            "Epoch: 2071, Loss: 0.0384042002260685  (Learning rate: [0.00078125], Time: 3.1943s\n",
            "Epoch: 2072, Loss: 0.03840121999382973  (Learning rate: [0.00078125], Time: 3.1834s\n",
            "Epoch: 2073, Loss: 0.038398198783397675  (Learning rate: [0.00078125], Time: 3.1894s\n",
            "Epoch: 2074, Loss: 0.03839519992470741  (Learning rate: [0.00078125], Time: 3.1783s\n",
            "Epoch: 2075, Loss: 0.03839220106601715  (Learning rate: [0.00078125], Time: 3.1907s\n",
            "Epoch: 2076, Loss: 0.03838920593261719  (Learning rate: [0.00078125], Time: 3.1852s\n",
            "Epoch: 2077, Loss: 0.038386207073926926  (Learning rate: [0.00078125], Time: 3.1996s\n",
            "Epoch: 2078, Loss: 0.03838319703936577  (Learning rate: [0.00078125], Time: 3.1845s\n",
            "Epoch: 2079, Loss: 0.03838019445538521  (Learning rate: [0.00078125], Time: 3.1878s\n",
            "Epoch: 2080, Loss: 0.038377195596694946  (Learning rate: [0.00078125], Time: 3.207s\n",
            "Epoch: 2081, Loss: 0.03837423399090767  (Learning rate: [0.00078125], Time: 3.2075s\n",
            "Epoch: 2082, Loss: 0.038371264934539795  (Learning rate: [0.00078125], Time: 3.1868s\n",
            "Epoch: 2083, Loss: 0.03836831822991371  (Learning rate: [0.00078125], Time: 3.205s\n",
            "Epoch: 2084, Loss: 0.038365304470062256  (Learning rate: [0.00078125], Time: 3.1856s\n",
            "Epoch: 2085, Loss: 0.03836231306195259  (Learning rate: [0.00078125], Time: 3.1953s\n",
            "Epoch: 2086, Loss: 0.038359325379133224  (Learning rate: [0.00078125], Time: 3.1832s\n",
            "Epoch: 2087, Loss: 0.038356345146894455  (Learning rate: [0.00078125], Time: 3.1916s\n",
            "Epoch: 2088, Loss: 0.03835335746407509  (Learning rate: [0.00078125], Time: 3.1839s\n",
            "Epoch: 2089, Loss: 0.03835036978125572  (Learning rate: [0.00078125], Time: 3.212s\n",
            "Epoch: 2090, Loss: 0.03834739327430725  (Learning rate: [0.00078125], Time: 3.2054s\n",
            "Epoch: 2091, Loss: 0.038344427943229675  (Learning rate: [0.00078125], Time: 3.2081s\n",
            "Epoch: 2092, Loss: 0.03834148123860359  (Learning rate: [0.00078125], Time: 3.1907s\n",
            "Epoch: 2093, Loss: 0.03833853825926781  (Learning rate: [0.00078125], Time: 3.2098s\n",
            "Epoch: 2094, Loss: 0.0383356511592865  (Learning rate: [0.00078125], Time: 3.1905s\n",
            "Epoch: 2095, Loss: 0.03833265230059624  (Learning rate: [0.00078125], Time: 3.1819s\n",
            "Epoch: 2096, Loss: 0.03832969069480896  (Learning rate: [0.00078125], Time: 3.1793s\n",
            "Epoch: 2097, Loss: 0.038326676934957504  (Learning rate: [0.00078125], Time: 3.1949s\n",
            "Epoch: 2098, Loss: 0.038323692977428436  (Learning rate: [0.00078125], Time: 3.1969s\n",
            "Epoch: 2099, Loss: 0.038320716470479965  (Learning rate: [0.00078125], Time: 3.1903s\n",
            "Epoch: 2100, Loss: 0.03831774741411209  (Learning rate: [0.000390625], Time: 3.1887s\n",
            "Epoch: 2101, Loss: 0.038314785808324814  (Learning rate: [0.000390625], Time: 3.1919s\n",
            "Epoch: 2102, Loss: 0.03831328824162483  (Learning rate: [0.000390625], Time: 3.1839s\n",
            "Epoch: 2103, Loss: 0.03831182420253754  (Learning rate: [0.000390625], Time: 3.1866s\n",
            "Epoch: 2104, Loss: 0.03831033408641815  (Learning rate: [0.000390625], Time: 3.1869s\n",
            "Epoch: 2105, Loss: 0.03830886632204056  (Learning rate: [0.000390625], Time: 3.19s\n",
            "Epoch: 2106, Loss: 0.03830737993121147  (Learning rate: [0.000390625], Time: 3.1966s\n",
            "Epoch: 2107, Loss: 0.03830591216683388  (Learning rate: [0.000390625], Time: 3.2087s\n",
            "Epoch: 2108, Loss: 0.03830442577600479  (Learning rate: [0.000390625], Time: 3.1908s\n",
            "Epoch: 2109, Loss: 0.0383029580116272  (Learning rate: [0.000390625], Time: 3.182s\n",
            "Epoch: 2110, Loss: 0.03830147534608841  (Learning rate: [0.000390625], Time: 3.1888s\n",
            "Epoch: 2111, Loss: 0.038300007581710815  (Learning rate: [0.000390625], Time: 3.1793s\n",
            "Epoch: 2112, Loss: 0.03829852491617203  (Learning rate: [0.000390625], Time: 3.189s\n",
            "Epoch: 2113, Loss: 0.038297057151794434  (Learning rate: [0.000390625], Time: 3.1819s\n",
            "Epoch: 2114, Loss: 0.038295578211545944  (Learning rate: [0.000390625], Time: 3.1825s\n",
            "Epoch: 2115, Loss: 0.03829410672187805  (Learning rate: [0.000390625], Time: 3.19s\n",
            "Epoch: 2116, Loss: 0.03829263150691986  (Learning rate: [0.000390625], Time: 3.1992s\n",
            "Epoch: 2117, Loss: 0.03829116001725197  (Learning rate: [0.000390625], Time: 3.1934s\n",
            "Epoch: 2118, Loss: 0.03828968480229378  (Learning rate: [0.000390625], Time: 3.1986s\n",
            "Epoch: 2119, Loss: 0.038288217037916183  (Learning rate: [0.000390625], Time: 3.2061s\n",
            "Epoch: 2120, Loss: 0.038286738097667694  (Learning rate: [0.000390625], Time: 3.2039s\n",
            "Epoch: 2121, Loss: 0.0382852703332901  (Learning rate: [0.000390625], Time: 3.1893s\n",
            "Epoch: 2122, Loss: 0.03828379884362221  (Learning rate: [0.000390625], Time: 3.1961s\n",
            "Epoch: 2123, Loss: 0.038282327353954315  (Learning rate: [0.000390625], Time: 3.2106s\n",
            "Epoch: 2124, Loss: 0.03828085586428642  (Learning rate: [0.000390625], Time: 3.2138s\n",
            "Epoch: 2125, Loss: 0.03827938809990883  (Learning rate: [0.000390625], Time: 3.202s\n",
            "Epoch: 2126, Loss: 0.038277916610240936  (Learning rate: [0.000390625], Time: 3.196s\n",
            "Epoch: 2127, Loss: 0.03827644884586334  (Learning rate: [0.000390625], Time: 3.1997s\n",
            "Epoch: 2128, Loss: 0.03827497363090515  (Learning rate: [0.000390625], Time: 3.2033s\n",
            "Epoch: 2129, Loss: 0.03827350586652756  (Learning rate: [0.000390625], Time: 3.1936s\n",
            "Epoch: 2130, Loss: 0.038272034376859665  (Learning rate: [0.000390625], Time: 3.1837s\n",
            "Epoch: 2131, Loss: 0.03827056661248207  (Learning rate: [0.000390625], Time: 3.2009s\n",
            "Epoch: 2132, Loss: 0.03826909884810448  (Learning rate: [0.000390625], Time: 3.2237s\n",
            "Epoch: 2133, Loss: 0.03826763108372688  (Learning rate: [0.000390625], Time: 3.1954s\n",
            "Epoch: 2134, Loss: 0.03826616331934929  (Learning rate: [0.000390625], Time: 3.1893s\n",
            "Epoch: 2135, Loss: 0.03826469928026199  (Learning rate: [0.000390625], Time: 3.1987s\n",
            "Epoch: 2136, Loss: 0.0382632315158844  (Learning rate: [0.000390625], Time: 3.2081s\n",
            "Epoch: 2137, Loss: 0.038261763751506805  (Learning rate: [0.000390625], Time: 3.2132s\n",
            "Epoch: 2138, Loss: 0.03826029598712921  (Learning rate: [0.000390625], Time: 3.207s\n",
            "Epoch: 2139, Loss: 0.03825882822275162  (Learning rate: [0.000390625], Time: 3.2066s\n",
            "Epoch: 2140, Loss: 0.03825736045837402  (Learning rate: [0.000390625], Time: 3.1987s\n",
            "Epoch: 2141, Loss: 0.03825589269399643  (Learning rate: [0.000390625], Time: 3.2065s\n",
            "Epoch: 2142, Loss: 0.038254428654909134  (Learning rate: [0.000390625], Time: 3.203s\n",
            "Epoch: 2143, Loss: 0.03825296461582184  (Learning rate: [0.000390625], Time: 3.2018s\n",
            "Epoch: 2144, Loss: 0.038251496851444244  (Learning rate: [0.000390625], Time: 3.2076s\n",
            "Epoch: 2145, Loss: 0.03825002908706665  (Learning rate: [0.000390625], Time: 3.2005s\n",
            "Epoch: 2146, Loss: 0.038248565047979355  (Learning rate: [0.000390625], Time: 3.2081s\n",
            "Epoch: 2147, Loss: 0.03824710100889206  (Learning rate: [0.000390625], Time: 3.2133s\n",
            "Epoch: 2148, Loss: 0.038245636969804764  (Learning rate: [0.000390625], Time: 3.2101s\n",
            "Epoch: 2149, Loss: 0.03824417293071747  (Learning rate: [0.000390625], Time: 3.2029s\n",
            "Epoch: 2150, Loss: 0.038242705166339874  (Learning rate: [0.000390625], Time: 3.2099s\n",
            "Epoch: 2151, Loss: 0.03824124485254288  (Learning rate: [0.000390625], Time: 3.2064s\n",
            "Epoch: 2152, Loss: 0.03823978081345558  (Learning rate: [0.000390625], Time: 3.211s\n",
            "Epoch: 2153, Loss: 0.038238316774368286  (Learning rate: [0.000390625], Time: 3.2069s\n",
            "Epoch: 2154, Loss: 0.03823685646057129  (Learning rate: [0.000390625], Time: 3.2065s\n",
            "Epoch: 2155, Loss: 0.038235392421483994  (Learning rate: [0.000390625], Time: 3.2099s\n",
            "Epoch: 2156, Loss: 0.0382339283823967  (Learning rate: [0.000390625], Time: 3.2171s\n",
            "Epoch: 2157, Loss: 0.0382324680685997  (Learning rate: [0.000390625], Time: 3.2147s\n",
            "Epoch: 2158, Loss: 0.038231004029512405  (Learning rate: [0.000390625], Time: 3.1986s\n",
            "Epoch: 2159, Loss: 0.03822953999042511  (Learning rate: [0.000390625], Time: 3.2046s\n",
            "Epoch: 2160, Loss: 0.03822807967662811  (Learning rate: [0.000390625], Time: 3.2061s\n",
            "Epoch: 2161, Loss: 0.03822661563754082  (Learning rate: [0.000390625], Time: 3.2089s\n",
            "Epoch: 2162, Loss: 0.03822515532374382  (Learning rate: [0.000390625], Time: 3.2066s\n",
            "Epoch: 2163, Loss: 0.03822369500994682  (Learning rate: [0.000390625], Time: 3.215s\n",
            "Epoch: 2164, Loss: 0.038222234696149826  (Learning rate: [0.000390625], Time: 3.2061s\n",
            "Epoch: 2165, Loss: 0.03822077438235283  (Learning rate: [0.000390625], Time: 3.1829s\n",
            "Epoch: 2166, Loss: 0.03821931406855583  (Learning rate: [0.000390625], Time: 3.1987s\n",
            "Epoch: 2167, Loss: 0.038217853754758835  (Learning rate: [0.000390625], Time: 3.2034s\n",
            "Epoch: 2168, Loss: 0.03821639344096184  (Learning rate: [0.000390625], Time: 3.2053s\n",
            "Epoch: 2169, Loss: 0.03821492940187454  (Learning rate: [0.000390625], Time: 3.2023s\n",
            "Epoch: 2170, Loss: 0.038213472813367844  (Learning rate: [0.000390625], Time: 3.2054s\n",
            "Epoch: 2171, Loss: 0.03821201249957085  (Learning rate: [0.000390625], Time: 3.2269s\n",
            "Epoch: 2172, Loss: 0.03821055218577385  (Learning rate: [0.000390625], Time: 3.2079s\n",
            "Epoch: 2173, Loss: 0.03820909559726715  (Learning rate: [0.000390625], Time: 3.2271s\n",
            "Epoch: 2174, Loss: 0.038207635283470154  (Learning rate: [0.000390625], Time: 3.2038s\n",
            "Epoch: 2175, Loss: 0.038206178694963455  (Learning rate: [0.000390625], Time: 3.1996s\n",
            "Epoch: 2176, Loss: 0.03820471838116646  (Learning rate: [0.000390625], Time: 3.1998s\n",
            "Epoch: 2177, Loss: 0.03820326179265976  (Learning rate: [0.000390625], Time: 3.1809s\n",
            "Epoch: 2178, Loss: 0.03820180147886276  (Learning rate: [0.000390625], Time: 3.1946s\n",
            "Epoch: 2179, Loss: 0.038200341165065765  (Learning rate: [0.000390625], Time: 3.2082s\n",
            "Epoch: 2180, Loss: 0.03819888457655907  (Learning rate: [0.000390625], Time: 3.2093s\n",
            "Epoch: 2181, Loss: 0.03819742798805237  (Learning rate: [0.000390625], Time: 3.2025s\n",
            "Epoch: 2182, Loss: 0.03819597139954567  (Learning rate: [0.000390625], Time: 3.2076s\n",
            "Epoch: 2183, Loss: 0.03819451481103897  (Learning rate: [0.000390625], Time: 3.2188s\n",
            "Epoch: 2184, Loss: 0.03819305822253227  (Learning rate: [0.000390625], Time: 3.2059s\n",
            "Epoch: 2185, Loss: 0.038191601634025574  (Learning rate: [0.000390625], Time: 3.2505s\n",
            "Epoch: 2186, Loss: 0.03819014132022858  (Learning rate: [0.000390625], Time: 3.2002s\n",
            "Epoch: 2187, Loss: 0.03818868473172188  (Learning rate: [0.000390625], Time: 3.2171s\n",
            "Epoch: 2188, Loss: 0.03818722814321518  (Learning rate: [0.000390625], Time: 3.2041s\n",
            "Epoch: 2189, Loss: 0.03818577155470848  (Learning rate: [0.000390625], Time: 3.219s\n",
            "Epoch: 2190, Loss: 0.03818431496620178  (Learning rate: [0.000390625], Time: 3.1938s\n",
            "Epoch: 2191, Loss: 0.03818286210298538  (Learning rate: [0.000390625], Time: 3.204s\n",
            "Epoch: 2192, Loss: 0.038181405514478683  (Learning rate: [0.000390625], Time: 3.2007s\n",
            "Epoch: 2193, Loss: 0.038179948925971985  (Learning rate: [0.000390625], Time: 3.2086s\n",
            "Epoch: 2194, Loss: 0.038178492337465286  (Learning rate: [0.000390625], Time: 3.2053s\n",
            "Epoch: 2195, Loss: 0.038177039474248886  (Learning rate: [0.000390625], Time: 3.2119s\n",
            "Epoch: 2196, Loss: 0.03817557916045189  (Learning rate: [0.000390625], Time: 3.2s\n",
            "Epoch: 2197, Loss: 0.03817412629723549  (Learning rate: [0.000390625], Time: 3.2028s\n",
            "Epoch: 2198, Loss: 0.03817266970872879  (Learning rate: [0.000390625], Time: 3.2163s\n",
            "Epoch: 2199, Loss: 0.03817121312022209  (Learning rate: [0.000390625], Time: 3.2083s\n",
            "Epoch: 2200, Loss: 0.03816976025700569  (Learning rate: [0.000390625], Time: 3.2099s\n",
            "Epoch: 2201, Loss: 0.03816830366849899  (Learning rate: [0.000390625], Time: 3.2092s\n",
            "Epoch: 2202, Loss: 0.03816685080528259  (Learning rate: [0.000390625], Time: 3.2149s\n",
            "Epoch: 2203, Loss: 0.038165394216775894  (Learning rate: [0.000390625], Time: 3.221s\n",
            "Epoch: 2204, Loss: 0.038163941353559494  (Learning rate: [0.000390625], Time: 3.2052s\n",
            "Epoch: 2205, Loss: 0.038162484765052795  (Learning rate: [0.000390625], Time: 3.2145s\n",
            "Epoch: 2206, Loss: 0.038161031901836395  (Learning rate: [0.000390625], Time: 3.2042s\n",
            "Epoch: 2207, Loss: 0.038159579038619995  (Learning rate: [0.000390625], Time: 3.199s\n",
            "Epoch: 2208, Loss: 0.038158122450113297  (Learning rate: [0.000390625], Time: 3.1991s\n",
            "Epoch: 2209, Loss: 0.038156669586896896  (Learning rate: [0.000390625], Time: 3.217s\n",
            "Epoch: 2210, Loss: 0.038155216723680496  (Learning rate: [0.000390625], Time: 3.216s\n",
            "Epoch: 2211, Loss: 0.038153763860464096  (Learning rate: [0.000390625], Time: 3.2223s\n",
            "Epoch: 2212, Loss: 0.0381523072719574  (Learning rate: [0.000390625], Time: 3.2107s\n",
            "Epoch: 2213, Loss: 0.038150854408741  (Learning rate: [0.000390625], Time: 3.1954s\n",
            "Epoch: 2214, Loss: 0.0381494015455246  (Learning rate: [0.000390625], Time: 3.184s\n",
            "Epoch: 2215, Loss: 0.0381479486823082  (Learning rate: [0.000390625], Time: 3.1819s\n",
            "Epoch: 2216, Loss: 0.038146499544382095  (Learning rate: [0.000390625], Time: 3.1857s\n",
            "Epoch: 2217, Loss: 0.0381450429558754  (Learning rate: [0.000390625], Time: 3.181s\n",
            "Epoch: 2218, Loss: 0.038143593817949295  (Learning rate: [0.000390625], Time: 3.1849s\n",
            "Epoch: 2219, Loss: 0.038142140954732895  (Learning rate: [0.000390625], Time: 3.1874s\n",
            "Epoch: 2220, Loss: 0.038140688091516495  (Learning rate: [0.000390625], Time: 3.189s\n",
            "Epoch: 2221, Loss: 0.038139235228300095  (Learning rate: [0.000390625], Time: 3.1838s\n",
            "Epoch: 2222, Loss: 0.03813778609037399  (Learning rate: [0.000390625], Time: 3.1824s\n",
            "Epoch: 2223, Loss: 0.03813633322715759  (Learning rate: [0.000390625], Time: 3.1794s\n",
            "Epoch: 2224, Loss: 0.03813488408923149  (Learning rate: [0.000390625], Time: 3.1724s\n",
            "Epoch: 2225, Loss: 0.03813343122601509  (Learning rate: [0.000390625], Time: 3.1815s\n",
            "Epoch: 2226, Loss: 0.03813198208808899  (Learning rate: [0.000390625], Time: 3.1866s\n",
            "Epoch: 2227, Loss: 0.03813053295016289  (Learning rate: [0.000390625], Time: 3.1828s\n",
            "Epoch: 2228, Loss: 0.03812908008694649  (Learning rate: [0.000390625], Time: 3.1924s\n",
            "Epoch: 2229, Loss: 0.038127630949020386  (Learning rate: [0.000390625], Time: 3.1882s\n",
            "Epoch: 2230, Loss: 0.038126181811094284  (Learning rate: [0.000390625], Time: 3.1841s\n",
            "Epoch: 2231, Loss: 0.03812473267316818  (Learning rate: [0.000390625], Time: 3.1856s\n",
            "Epoch: 2232, Loss: 0.03812327980995178  (Learning rate: [0.000390625], Time: 3.1848s\n",
            "Epoch: 2233, Loss: 0.03812183439731598  (Learning rate: [0.000390625], Time: 3.1858s\n",
            "Epoch: 2234, Loss: 0.03812038525938988  (Learning rate: [0.000390625], Time: 3.1778s\n",
            "Epoch: 2235, Loss: 0.038118936121463776  (Learning rate: [0.000390625], Time: 3.1847s\n",
            "Epoch: 2236, Loss: 0.038117486983537674  (Learning rate: [0.000390625], Time: 3.1752s\n",
            "Epoch: 2237, Loss: 0.03811604157090187  (Learning rate: [0.000390625], Time: 3.187s\n",
            "Epoch: 2238, Loss: 0.03811459243297577  (Learning rate: [0.000390625], Time: 3.2046s\n",
            "Epoch: 2239, Loss: 0.03811314329504967  (Learning rate: [0.000390625], Time: 3.203s\n",
            "Epoch: 2240, Loss: 0.038111694157123566  (Learning rate: [0.000390625], Time: 3.2042s\n",
            "Epoch: 2241, Loss: 0.038110245019197464  (Learning rate: [0.000390625], Time: 3.1944s\n",
            "Epoch: 2242, Loss: 0.03810879960656166  (Learning rate: [0.000390625], Time: 3.1863s\n",
            "Epoch: 2243, Loss: 0.03810735046863556  (Learning rate: [0.000390625], Time: 3.1946s\n",
            "Epoch: 2244, Loss: 0.038105905055999756  (Learning rate: [0.000390625], Time: 3.1797s\n",
            "Epoch: 2245, Loss: 0.038104455918073654  (Learning rate: [0.000390625], Time: 3.1798s\n",
            "Epoch: 2246, Loss: 0.03810301050543785  (Learning rate: [0.000390625], Time: 3.195s\n",
            "Epoch: 2247, Loss: 0.03810156509280205  (Learning rate: [0.000390625], Time: 3.2074s\n",
            "Epoch: 2248, Loss: 0.038100119680166245  (Learning rate: [0.000390625], Time: 3.2035s\n",
            "Epoch: 2249, Loss: 0.03809867054224014  (Learning rate: [0.000390625], Time: 3.2028s\n",
            "Epoch: 2250, Loss: 0.03809722140431404  (Learning rate: [0.000390625], Time: 3.1928s\n",
            "Epoch: 2251, Loss: 0.038095779716968536  (Learning rate: [0.000390625], Time: 3.2029s\n",
            "Epoch: 2252, Loss: 0.038094330579042435  (Learning rate: [0.000390625], Time: 3.195s\n",
            "Epoch: 2253, Loss: 0.03809288889169693  (Learning rate: [0.000390625], Time: 3.2013s\n",
            "Epoch: 2254, Loss: 0.03809143975377083  (Learning rate: [0.000390625], Time: 3.1949s\n",
            "Epoch: 2255, Loss: 0.038089998066425323  (Learning rate: [0.000390625], Time: 3.2276s\n",
            "Epoch: 2256, Loss: 0.03808855265378952  (Learning rate: [0.000390625], Time: 3.1977s\n",
            "Epoch: 2257, Loss: 0.03808710351586342  (Learning rate: [0.000390625], Time: 3.2052s\n",
            "Epoch: 2258, Loss: 0.038085661828517914  (Learning rate: [0.000390625], Time: 3.2057s\n",
            "Epoch: 2259, Loss: 0.03808421641588211  (Learning rate: [0.000390625], Time: 3.1973s\n",
            "Epoch: 2260, Loss: 0.03808277100324631  (Learning rate: [0.000390625], Time: 3.1995s\n",
            "Epoch: 2261, Loss: 0.0380813293159008  (Learning rate: [0.000390625], Time: 3.2065s\n",
            "Epoch: 2262, Loss: 0.0380798801779747  (Learning rate: [0.000390625], Time: 3.2715s\n",
            "Epoch: 2263, Loss: 0.038078438490629196  (Learning rate: [0.000390625], Time: 3.2156s\n",
            "Epoch: 2264, Loss: 0.03807699680328369  (Learning rate: [0.000390625], Time: 3.2145s\n",
            "Epoch: 2265, Loss: 0.03807555139064789  (Learning rate: [0.000390625], Time: 3.2128s\n",
            "Epoch: 2266, Loss: 0.038074105978012085  (Learning rate: [0.000390625], Time: 3.1936s\n",
            "Epoch: 2267, Loss: 0.03807266056537628  (Learning rate: [0.000390625], Time: 3.1965s\n",
            "Epoch: 2268, Loss: 0.038071222603321075  (Learning rate: [0.000390625], Time: 3.2163s\n",
            "Epoch: 2269, Loss: 0.03806977719068527  (Learning rate: [0.000390625], Time: 3.1969s\n",
            "Epoch: 2270, Loss: 0.03806833550333977  (Learning rate: [0.000390625], Time: 3.2127s\n",
            "Epoch: 2271, Loss: 0.03806689381599426  (Learning rate: [0.000390625], Time: 3.2096s\n",
            "Epoch: 2272, Loss: 0.03806544840335846  (Learning rate: [0.000390625], Time: 3.2032s\n",
            "Epoch: 2273, Loss: 0.038064002990722656  (Learning rate: [0.000390625], Time: 3.203s\n",
            "Epoch: 2274, Loss: 0.03806256502866745  (Learning rate: [0.000390625], Time: 3.2046s\n",
            "Epoch: 2275, Loss: 0.03806111961603165  (Learning rate: [0.000390625], Time: 3.197s\n",
            "Epoch: 2276, Loss: 0.03805967792868614  (Learning rate: [0.000390625], Time: 3.2s\n",
            "Epoch: 2277, Loss: 0.03805823251605034  (Learning rate: [0.000390625], Time: 3.2109s\n",
            "Epoch: 2278, Loss: 0.038056790828704834  (Learning rate: [0.000390625], Time: 3.2123s\n",
            "Epoch: 2279, Loss: 0.03805534914135933  (Learning rate: [0.000390625], Time: 3.2178s\n",
            "Epoch: 2280, Loss: 0.038053907454013824  (Learning rate: [0.000390625], Time: 3.2061s\n",
            "Epoch: 2281, Loss: 0.03805246576666832  (Learning rate: [0.000390625], Time: 3.2041s\n",
            "Epoch: 2282, Loss: 0.03805102780461311  (Learning rate: [0.000390625], Time: 3.2085s\n",
            "Epoch: 2283, Loss: 0.03804958239197731  (Learning rate: [0.000390625], Time: 3.1994s\n",
            "Epoch: 2284, Loss: 0.038048140704631805  (Learning rate: [0.000390625], Time: 3.1978s\n",
            "Epoch: 2285, Loss: 0.0380466990172863  (Learning rate: [0.000390625], Time: 3.2296s\n",
            "Epoch: 2286, Loss: 0.038045261055231094  (Learning rate: [0.000390625], Time: 3.2126s\n",
            "Epoch: 2287, Loss: 0.03804381564259529  (Learning rate: [0.000390625], Time: 3.2157s\n",
            "Epoch: 2288, Loss: 0.038042373955249786  (Learning rate: [0.000390625], Time: 3.203s\n",
            "Epoch: 2289, Loss: 0.03804093226790428  (Learning rate: [0.000390625], Time: 3.2065s\n",
            "Epoch: 2290, Loss: 0.038039494305849075  (Learning rate: [0.000390625], Time: 3.2069s\n",
            "Epoch: 2291, Loss: 0.03803805261850357  (Learning rate: [0.000390625], Time: 3.2023s\n",
            "Epoch: 2292, Loss: 0.038036610931158066  (Learning rate: [0.000390625], Time: 3.198s\n",
            "Epoch: 2293, Loss: 0.03803516924381256  (Learning rate: [0.000390625], Time: 3.2059s\n",
            "Epoch: 2294, Loss: 0.038033727556467056  (Learning rate: [0.000390625], Time: 3.2168s\n",
            "Epoch: 2295, Loss: 0.03803228959441185  (Learning rate: [0.000390625], Time: 3.2122s\n",
            "Epoch: 2296, Loss: 0.038030847907066345  (Learning rate: [0.000390625], Time: 3.2011s\n",
            "Epoch: 2297, Loss: 0.03802940621972084  (Learning rate: [0.000390625], Time: 3.2106s\n",
            "Epoch: 2298, Loss: 0.038027964532375336  (Learning rate: [0.000390625], Time: 3.1996s\n",
            "Epoch: 2299, Loss: 0.03802652284502983  (Learning rate: [0.000390625], Time: 3.2031s\n",
            "Epoch: 2300, Loss: 0.038025081157684326  (Learning rate: [0.000390625], Time: 3.2008s\n",
            "Epoch: 2301, Loss: 0.03802364319562912  (Learning rate: [0.000390625], Time: 3.2094s\n",
            "Epoch: 2302, Loss: 0.038022201508283615  (Learning rate: [0.000390625], Time: 3.2119s\n",
            "Epoch: 2303, Loss: 0.03802075982093811  (Learning rate: [0.000390625], Time: 3.2164s\n",
            "Epoch: 2304, Loss: 0.038019318133592606  (Learning rate: [0.000390625], Time: 3.2113s\n",
            "Epoch: 2305, Loss: 0.0380178801715374  (Learning rate: [0.000390625], Time: 3.2084s\n",
            "Epoch: 2306, Loss: 0.038016434758901596  (Learning rate: [0.000390625], Time: 3.2022s\n",
            "Epoch: 2307, Loss: 0.03801499679684639  (Learning rate: [0.000390625], Time: 3.2045s\n",
            "Epoch: 2308, Loss: 0.038013555109500885  (Learning rate: [0.000390625], Time: 3.2124s\n",
            "Epoch: 2309, Loss: 0.03801211342215538  (Learning rate: [0.000390625], Time: 3.2069s\n",
            "Epoch: 2310, Loss: 0.038010671734809875  (Learning rate: [0.000390625], Time: 3.2146s\n",
            "Epoch: 2311, Loss: 0.03800923377275467  (Learning rate: [0.000390625], Time: 3.2239s\n",
            "Epoch: 2312, Loss: 0.038007788360118866  (Learning rate: [0.000390625], Time: 3.2069s\n",
            "Epoch: 2313, Loss: 0.03800635039806366  (Learning rate: [0.000390625], Time: 3.2029s\n",
            "Epoch: 2314, Loss: 0.038004904985427856  (Learning rate: [0.000390625], Time: 3.2107s\n",
            "Epoch: 2315, Loss: 0.03800346329808235  (Learning rate: [0.000390625], Time: 3.2051s\n",
            "Epoch: 2316, Loss: 0.03800202161073685  (Learning rate: [0.000390625], Time: 3.2051s\n",
            "Epoch: 2317, Loss: 0.038000576198101044  (Learning rate: [0.000390625], Time: 3.2206s\n",
            "Epoch: 2318, Loss: 0.03799913823604584  (Learning rate: [0.000390625], Time: 3.215s\n",
            "Epoch: 2319, Loss: 0.037997692823410034  (Learning rate: [0.000390625], Time: 3.198s\n",
            "Epoch: 2320, Loss: 0.03799625113606453  (Learning rate: [0.000390625], Time: 3.2098s\n",
            "Epoch: 2321, Loss: 0.037994805723428726  (Learning rate: [0.000390625], Time: 3.211s\n",
            "Epoch: 2322, Loss: 0.03799336031079292  (Learning rate: [0.000390625], Time: 3.2046s\n",
            "Epoch: 2323, Loss: 0.03799191862344742  (Learning rate: [0.000390625], Time: 3.2065s\n",
            "Epoch: 2324, Loss: 0.037990473210811615  (Learning rate: [0.000390625], Time: 3.1985s\n",
            "Epoch: 2325, Loss: 0.03798902779817581  (Learning rate: [0.000390625], Time: 3.2077s\n",
            "Epoch: 2326, Loss: 0.03798758611083031  (Learning rate: [0.000390625], Time: 3.2208s\n",
            "Epoch: 2327, Loss: 0.037986136972904205  (Learning rate: [0.000390625], Time: 3.193s\n",
            "Epoch: 2328, Loss: 0.0379846915602684  (Learning rate: [0.000390625], Time: 3.196s\n",
            "Epoch: 2329, Loss: 0.0379832461476326  (Learning rate: [0.000390625], Time: 3.2066s\n",
            "Epoch: 2330, Loss: 0.0379817970097065  (Learning rate: [0.000390625], Time: 3.2054s\n",
            "Epoch: 2331, Loss: 0.037980351597070694  (Learning rate: [0.000390625], Time: 3.2023s\n",
            "Epoch: 2332, Loss: 0.037978898733854294  (Learning rate: [0.000390625], Time: 3.2118s\n",
            "Epoch: 2333, Loss: 0.03797744959592819  (Learning rate: [0.000390625], Time: 3.2156s\n",
            "Epoch: 2334, Loss: 0.03797600045800209  (Learning rate: [0.000390625], Time: 3.2118s\n",
            "Epoch: 2335, Loss: 0.03797454759478569  (Learning rate: [0.000390625], Time: 3.2078s\n",
            "Epoch: 2336, Loss: 0.03797309845685959  (Learning rate: [0.000390625], Time: 3.214s\n",
            "Epoch: 2337, Loss: 0.03797164559364319  (Learning rate: [0.000390625], Time: 3.1956s\n",
            "Epoch: 2338, Loss: 0.03797019273042679  (Learning rate: [0.000390625], Time: 3.2111s\n",
            "Epoch: 2339, Loss: 0.03796873986721039  (Learning rate: [0.000390625], Time: 3.2096s\n",
            "Epoch: 2340, Loss: 0.03796728327870369  (Learning rate: [0.000390625], Time: 3.2013s\n",
            "Epoch: 2341, Loss: 0.03796582669019699  (Learning rate: [0.000390625], Time: 3.2088s\n",
            "Epoch: 2342, Loss: 0.03796437382698059  (Learning rate: [0.000390625], Time: 3.2186s\n",
            "Epoch: 2343, Loss: 0.037962913513183594  (Learning rate: [0.000390625], Time: 3.2044s\n",
            "Epoch: 2344, Loss: 0.0379614531993866  (Learning rate: [0.000390625], Time: 3.2039s\n",
            "Epoch: 2345, Loss: 0.0379599966108799  (Learning rate: [0.000390625], Time: 3.212s\n",
            "Epoch: 2346, Loss: 0.0379585325717926  (Learning rate: [0.000390625], Time: 3.227s\n",
            "Epoch: 2347, Loss: 0.037957072257995605  (Learning rate: [0.000390625], Time: 3.2033s\n",
            "Epoch: 2348, Loss: 0.03795560449361801  (Learning rate: [0.000390625], Time: 3.207s\n",
            "Epoch: 2349, Loss: 0.037954144179821014  (Learning rate: [0.000390625], Time: 3.2158s\n",
            "Epoch: 2350, Loss: 0.03795267641544342  (Learning rate: [0.000390625], Time: 3.2131s\n",
            "Epoch: 2351, Loss: 0.03795120492577553  (Learning rate: [0.000390625], Time: 3.2046s\n",
            "Epoch: 2352, Loss: 0.037949737161397934  (Learning rate: [0.000390625], Time: 3.2044s\n",
            "Epoch: 2353, Loss: 0.03794826939702034  (Learning rate: [0.000390625], Time: 3.203s\n",
            "Epoch: 2354, Loss: 0.03794679790735245  (Learning rate: [0.000390625], Time: 3.204s\n",
            "Epoch: 2355, Loss: 0.03794531896710396  (Learning rate: [0.000390625], Time: 3.2133s\n",
            "Epoch: 2356, Loss: 0.037943847477436066  (Learning rate: [0.000390625], Time: 3.211s\n",
            "Epoch: 2357, Loss: 0.03794236481189728  (Learning rate: [0.000390625], Time: 3.2077s\n",
            "Epoch: 2358, Loss: 0.037940893322229385  (Learning rate: [0.000390625], Time: 3.2168s\n",
            "Epoch: 2359, Loss: 0.037939414381980896  (Learning rate: [0.000390625], Time: 3.2095s\n",
            "Epoch: 2360, Loss: 0.03793792799115181  (Learning rate: [0.000390625], Time: 3.2024s\n",
            "Epoch: 2361, Loss: 0.03793644532561302  (Learning rate: [0.000390625], Time: 3.2018s\n",
            "Epoch: 2362, Loss: 0.037934962660074234  (Learning rate: [0.000390625], Time: 3.2253s\n",
            "Epoch: 2363, Loss: 0.03793347626924515  (Learning rate: [0.000390625], Time: 3.2076s\n",
            "Epoch: 2364, Loss: 0.03793198615312576  (Learning rate: [0.000390625], Time: 3.2078s\n",
            "Epoch: 2365, Loss: 0.03793049603700638  (Learning rate: [0.000390625], Time: 3.222s\n",
            "Epoch: 2366, Loss: 0.03792900964617729  (Learning rate: [0.000390625], Time: 3.2054s\n",
            "Epoch: 2367, Loss: 0.03792751207947731  (Learning rate: [0.000390625], Time: 3.1995s\n",
            "Epoch: 2368, Loss: 0.03792601451277733  (Learning rate: [0.000390625], Time: 3.2018s\n",
            "Epoch: 2369, Loss: 0.03792451694607735  (Learning rate: [0.000390625], Time: 3.2054s\n",
            "Epoch: 2370, Loss: 0.037923023104667664  (Learning rate: [0.000390625], Time: 3.2004s\n",
            "Epoch: 2371, Loss: 0.03792152553796768  (Learning rate: [0.000390625], Time: 3.2176s\n",
            "Epoch: 2372, Loss: 0.0379200205206871  (Learning rate: [0.000390625], Time: 3.2052s\n",
            "Epoch: 2373, Loss: 0.03791851922869682  (Learning rate: [0.000390625], Time: 3.212s\n",
            "Epoch: 2374, Loss: 0.037917010486125946  (Learning rate: [0.000390625], Time: 3.2032s\n",
            "Epoch: 2375, Loss: 0.03791550546884537  (Learning rate: [0.000390625], Time: 3.1938s\n",
            "Epoch: 2376, Loss: 0.03791399672627449  (Learning rate: [0.000390625], Time: 3.2112s\n",
            "Epoch: 2377, Loss: 0.03791248798370361  (Learning rate: [0.000390625], Time: 3.2098s\n",
            "Epoch: 2378, Loss: 0.03791097551584244  (Learning rate: [0.000390625], Time: 3.2076s\n",
            "Epoch: 2379, Loss: 0.03790946677327156  (Learning rate: [0.000390625], Time: 3.1953s\n",
            "Epoch: 2380, Loss: 0.03790795058012009  (Learning rate: [0.000390625], Time: 3.1882s\n",
            "Epoch: 2381, Loss: 0.037906426936388016  (Learning rate: [0.000390625], Time: 3.1992s\n",
            "Epoch: 2382, Loss: 0.03790490701794624  (Learning rate: [0.000390625], Time: 3.194s\n",
            "Epoch: 2383, Loss: 0.03790338709950447  (Learning rate: [0.000390625], Time: 3.1845s\n",
            "Epoch: 2384, Loss: 0.0379018634557724  (Learning rate: [0.000390625], Time: 3.1797s\n",
            "Epoch: 2385, Loss: 0.03790033608675003  (Learning rate: [0.000390625], Time: 3.1911s\n",
            "Epoch: 2386, Loss: 0.03789881244301796  (Learning rate: [0.000390625], Time: 3.1866s\n",
            "Epoch: 2387, Loss: 0.03789728879928589  (Learning rate: [0.000390625], Time: 3.192s\n",
            "Epoch: 2388, Loss: 0.037895768880844116  (Learning rate: [0.000390625], Time: 3.1859s\n",
            "Epoch: 2389, Loss: 0.03789424151182175  (Learning rate: [0.000390625], Time: 3.1877s\n",
            "Epoch: 2390, Loss: 0.037892717868089676  (Learning rate: [0.000390625], Time: 3.1904s\n",
            "Epoch: 2391, Loss: 0.037891190499067307  (Learning rate: [0.000390625], Time: 3.1947s\n",
            "Epoch: 2392, Loss: 0.03788966313004494  (Learning rate: [0.000390625], Time: 3.1785s\n",
            "Epoch: 2393, Loss: 0.03788813576102257  (Learning rate: [0.000390625], Time: 3.183s\n",
            "Epoch: 2394, Loss: 0.0378866046667099  (Learning rate: [0.000390625], Time: 3.2159s\n",
            "Epoch: 2395, Loss: 0.03788507729768753  (Learning rate: [0.000390625], Time: 3.1833s\n",
            "Epoch: 2396, Loss: 0.03788354992866516  (Learning rate: [0.000390625], Time: 3.1856s\n",
            "Epoch: 2397, Loss: 0.037882015109062195  (Learning rate: [0.000390625], Time: 3.1796s\n",
            "Epoch: 2398, Loss: 0.03788048401474953  (Learning rate: [0.000390625], Time: 3.1843s\n",
            "Epoch: 2399, Loss: 0.03787895292043686  (Learning rate: [0.000390625], Time: 3.1953s\n",
            "Epoch: 2400, Loss: 0.03787742182612419  (Learning rate: [0.0001953125], Time: 3.1955s\n",
            "Epoch: 2401, Loss: 0.03787589073181152  (Learning rate: [0.0001953125], Time: 3.1817s\n",
            "Epoch: 2402, Loss: 0.03787512332201004  (Learning rate: [0.0001953125], Time: 3.1793s\n",
            "Epoch: 2403, Loss: 0.037874359637498856  (Learning rate: [0.0001953125], Time: 3.1829s\n",
            "Epoch: 2404, Loss: 0.03787359222769737  (Learning rate: [0.0001953125], Time: 3.1808s\n",
            "Epoch: 2405, Loss: 0.03787282481789589  (Learning rate: [0.0001953125], Time: 3.1911s\n",
            "Epoch: 2406, Loss: 0.037872061133384705  (Learning rate: [0.0001953125], Time: 3.1767s\n",
            "Epoch: 2407, Loss: 0.03787128999829292  (Learning rate: [0.0001953125], Time: 3.1792s\n",
            "Epoch: 2408, Loss: 0.03787052631378174  (Learning rate: [0.0001953125], Time: 3.202s\n",
            "Epoch: 2409, Loss: 0.037869758903980255  (Learning rate: [0.0001953125], Time: 3.1897s\n",
            "Epoch: 2410, Loss: 0.03786899149417877  (Learning rate: [0.0001953125], Time: 3.1842s\n",
            "Epoch: 2411, Loss: 0.03786822780966759  (Learning rate: [0.0001953125], Time: 3.1817s\n",
            "Epoch: 2412, Loss: 0.037867460399866104  (Learning rate: [0.0001953125], Time: 3.1792s\n",
            "Epoch: 2413, Loss: 0.03786669299006462  (Learning rate: [0.0001953125], Time: 3.1876s\n",
            "Epoch: 2414, Loss: 0.037865929305553436  (Learning rate: [0.0001953125], Time: 3.1905s\n",
            "Epoch: 2415, Loss: 0.03786516189575195  (Learning rate: [0.0001953125], Time: 3.1832s\n",
            "Epoch: 2416, Loss: 0.03786439821124077  (Learning rate: [0.0001953125], Time: 3.1806s\n",
            "Epoch: 2417, Loss: 0.037863630801439285  (Learning rate: [0.0001953125], Time: 3.1852s\n",
            "Epoch: 2418, Loss: 0.0378628633916378  (Learning rate: [0.0001953125], Time: 3.1991s\n",
            "Epoch: 2419, Loss: 0.03786209970712662  (Learning rate: [0.0001953125], Time: 3.1929s\n",
            "Epoch: 2420, Loss: 0.037861332297325134  (Learning rate: [0.0001953125], Time: 3.1841s\n",
            "Epoch: 2421, Loss: 0.03786056861281395  (Learning rate: [0.0001953125], Time: 3.1862s\n",
            "Epoch: 2422, Loss: 0.03785979747772217  (Learning rate: [0.0001953125], Time: 3.1849s\n",
            "Epoch: 2423, Loss: 0.03785903379321098  (Learning rate: [0.0001953125], Time: 3.188s\n",
            "Epoch: 2424, Loss: 0.0378582663834095  (Learning rate: [0.0001953125], Time: 3.183s\n",
            "Epoch: 2425, Loss: 0.037857502698898315  (Learning rate: [0.0001953125], Time: 3.1803s\n",
            "Epoch: 2426, Loss: 0.03785673901438713  (Learning rate: [0.0001953125], Time: 3.186s\n",
            "Epoch: 2427, Loss: 0.03785597160458565  (Learning rate: [0.0001953125], Time: 3.1898s\n",
            "Epoch: 2428, Loss: 0.03785520792007446  (Learning rate: [0.0001953125], Time: 3.1932s\n",
            "Epoch: 2429, Loss: 0.03785444423556328  (Learning rate: [0.0001953125], Time: 3.1977s\n",
            "Epoch: 2430, Loss: 0.037853680551052094  (Learning rate: [0.0001953125], Time: 3.196s\n",
            "Epoch: 2431, Loss: 0.03785291686654091  (Learning rate: [0.0001953125], Time: 3.2024s\n",
            "Epoch: 2432, Loss: 0.037852149456739426  (Learning rate: [0.0001953125], Time: 3.216s\n",
            "Epoch: 2433, Loss: 0.03785138577222824  (Learning rate: [0.0001953125], Time: 3.2147s\n",
            "Epoch: 2434, Loss: 0.037850622087717056  (Learning rate: [0.0001953125], Time: 3.1976s\n",
            "Epoch: 2435, Loss: 0.03784985840320587  (Learning rate: [0.0001953125], Time: 3.207s\n",
            "Epoch: 2436, Loss: 0.03784909471869469  (Learning rate: [0.0001953125], Time: 3.2406s\n",
            "Epoch: 2437, Loss: 0.0378483310341835  (Learning rate: [0.0001953125], Time: 3.2021s\n",
            "Epoch: 2438, Loss: 0.03784756734967232  (Learning rate: [0.0001953125], Time: 3.2019s\n",
            "Epoch: 2439, Loss: 0.03784680366516113  (Learning rate: [0.0001953125], Time: 3.2002s\n",
            "Epoch: 2440, Loss: 0.03784603998064995  (Learning rate: [0.0001953125], Time: 3.2101s\n",
            "Epoch: 2441, Loss: 0.03784528002142906  (Learning rate: [0.0001953125], Time: 3.2011s\n",
            "Epoch: 2442, Loss: 0.03784451261162758  (Learning rate: [0.0001953125], Time: 3.1958s\n",
            "Epoch: 2443, Loss: 0.03784375265240669  (Learning rate: [0.0001953125], Time: 3.2224s\n",
            "Epoch: 2444, Loss: 0.03784298896789551  (Learning rate: [0.0001953125], Time: 3.2056s\n",
            "Epoch: 2445, Loss: 0.03784222900867462  (Learning rate: [0.0001953125], Time: 3.2035s\n",
            "Epoch: 2446, Loss: 0.03784146159887314  (Learning rate: [0.0001953125], Time: 3.1965s\n",
            "Epoch: 2447, Loss: 0.03784070163965225  (Learning rate: [0.0001953125], Time: 3.2s\n",
            "Epoch: 2448, Loss: 0.037839941680431366  (Learning rate: [0.0001953125], Time: 3.202s\n",
            "Epoch: 2449, Loss: 0.03783917799592018  (Learning rate: [0.0001953125], Time: 3.199s\n",
            "Epoch: 2450, Loss: 0.037838414311409  (Learning rate: [0.0001953125], Time: 3.2119s\n",
            "Epoch: 2451, Loss: 0.03783765435218811  (Learning rate: [0.0001953125], Time: 3.2276s\n",
            "Epoch: 2452, Loss: 0.037836890667676926  (Learning rate: [0.0001953125], Time: 3.218s\n",
            "Epoch: 2453, Loss: 0.03783613443374634  (Learning rate: [0.0001953125], Time: 3.2048s\n",
            "Epoch: 2454, Loss: 0.037835367023944855  (Learning rate: [0.0001953125], Time: 3.2083s\n",
            "Epoch: 2455, Loss: 0.03783460706472397  (Learning rate: [0.0001953125], Time: 3.2072s\n",
            "Epoch: 2456, Loss: 0.03783384710550308  (Learning rate: [0.0001953125], Time: 3.2073s\n",
            "Epoch: 2457, Loss: 0.037833090871572495  (Learning rate: [0.0001953125], Time: 3.2047s\n",
            "Epoch: 2458, Loss: 0.03783233091235161  (Learning rate: [0.0001953125], Time: 3.2001s\n",
            "Epoch: 2459, Loss: 0.03783157095313072  (Learning rate: [0.0001953125], Time: 3.2142s\n",
            "Epoch: 2460, Loss: 0.03783080726861954  (Learning rate: [0.0001953125], Time: 3.2063s\n",
            "Epoch: 2461, Loss: 0.03783004730939865  (Learning rate: [0.0001953125], Time: 3.2007s\n",
            "Epoch: 2462, Loss: 0.037829287350177765  (Learning rate: [0.0001953125], Time: 3.2005s\n",
            "Epoch: 2463, Loss: 0.03782852739095688  (Learning rate: [0.0001953125], Time: 3.2006s\n",
            "Epoch: 2464, Loss: 0.03782776743173599  (Learning rate: [0.0001953125], Time: 3.2023s\n",
            "Epoch: 2465, Loss: 0.03782700374722481  (Learning rate: [0.0001953125], Time: 3.2082s\n",
            "Epoch: 2466, Loss: 0.03782624751329422  (Learning rate: [0.0001953125], Time: 3.1975s\n",
            "Epoch: 2467, Loss: 0.037825487554073334  (Learning rate: [0.0001953125], Time: 3.2127s\n",
            "Epoch: 2468, Loss: 0.037824731320142746  (Learning rate: [0.0001953125], Time: 3.212s\n",
            "Epoch: 2469, Loss: 0.03782397136092186  (Learning rate: [0.0001953125], Time: 3.2047s\n",
            "Epoch: 2470, Loss: 0.03782321512699127  (Learning rate: [0.0001953125], Time: 3.2081s\n",
            "Epoch: 2471, Loss: 0.03782245144248009  (Learning rate: [0.0001953125], Time: 3.2225s\n",
            "Epoch: 2472, Loss: 0.0378216989338398  (Learning rate: [0.0001953125], Time: 3.2057s\n",
            "Epoch: 2473, Loss: 0.03782093897461891  (Learning rate: [0.0001953125], Time: 3.2151s\n",
            "Epoch: 2474, Loss: 0.037820179015398026  (Learning rate: [0.0001953125], Time: 3.2152s\n",
            "Epoch: 2475, Loss: 0.03781942278146744  (Learning rate: [0.0001953125], Time: 3.2098s\n",
            "Epoch: 2476, Loss: 0.03781866654753685  (Learning rate: [0.0001953125], Time: 3.2026s\n",
            "Epoch: 2477, Loss: 0.037817906588315964  (Learning rate: [0.0001953125], Time: 3.2s\n",
            "Epoch: 2478, Loss: 0.037817150354385376  (Learning rate: [0.0001953125], Time: 3.2002s\n",
            "Epoch: 2479, Loss: 0.03781639039516449  (Learning rate: [0.0001953125], Time: 3.2015s\n",
            "Epoch: 2480, Loss: 0.0378156341612339  (Learning rate: [0.0001953125], Time: 3.216s\n",
            "Epoch: 2481, Loss: 0.037814877927303314  (Learning rate: [0.0001953125], Time: 3.2132s\n",
            "Epoch: 2482, Loss: 0.037814121693372726  (Learning rate: [0.0001953125], Time: 3.2301s\n",
            "Epoch: 2483, Loss: 0.03781336545944214  (Learning rate: [0.0001953125], Time: 3.2112s\n",
            "Epoch: 2484, Loss: 0.03781260550022125  (Learning rate: [0.0001953125], Time: 3.2036s\n",
            "Epoch: 2485, Loss: 0.037811849266290665  (Learning rate: [0.0001953125], Time: 3.2087s\n",
            "Epoch: 2486, Loss: 0.03781109303236008  (Learning rate: [0.0001953125], Time: 3.2528s\n",
            "Epoch: 2487, Loss: 0.03781033679842949  (Learning rate: [0.0001953125], Time: 3.2116s\n",
            "Epoch: 2488, Loss: 0.0378095842897892  (Learning rate: [0.0001953125], Time: 3.2089s\n",
            "Epoch: 2489, Loss: 0.03780882805585861  (Learning rate: [0.0001953125], Time: 3.2116s\n",
            "Epoch: 2490, Loss: 0.037808071821928024  (Learning rate: [0.0001953125], Time: 3.2073s\n",
            "Epoch: 2491, Loss: 0.037807319313287735  (Learning rate: [0.0001953125], Time: 3.2057s\n",
            "Epoch: 2492, Loss: 0.03780655935406685  (Learning rate: [0.0001953125], Time: 3.2104s\n",
            "Epoch: 2493, Loss: 0.03780580312013626  (Learning rate: [0.0001953125], Time: 3.2122s\n",
            "Epoch: 2494, Loss: 0.03780505061149597  (Learning rate: [0.0001953125], Time: 3.2118s\n",
            "Epoch: 2495, Loss: 0.037804294377565384  (Learning rate: [0.0001953125], Time: 3.2124s\n",
            "Epoch: 2496, Loss: 0.037803538143634796  (Learning rate: [0.0001953125], Time: 3.2066s\n",
            "Epoch: 2497, Loss: 0.03780278563499451  (Learning rate: [0.0001953125], Time: 3.218s\n",
            "Epoch: 2498, Loss: 0.03780202940106392  (Learning rate: [0.0001953125], Time: 3.2226s\n",
            "Epoch: 2499, Loss: 0.03780127689242363  (Learning rate: [0.0001953125], Time: 3.2096s\n",
            "Epoch: 2500, Loss: 0.03780052065849304  (Learning rate: [0.0001953125], Time: 3.2167s\n",
            "Epoch: 2501, Loss: 0.03779976814985275  (Learning rate: [0.0001953125], Time: 3.2123s\n",
            "Epoch: 2502, Loss: 0.037799011915922165  (Learning rate: [0.0001953125], Time: 3.2039s\n",
            "Epoch: 2503, Loss: 0.037798259407281876  (Learning rate: [0.0001953125], Time: 3.2025s\n",
            "Epoch: 2504, Loss: 0.037797506898641586  (Learning rate: [0.0001953125], Time: 3.2034s\n",
            "Epoch: 2505, Loss: 0.037796750664711  (Learning rate: [0.0001953125], Time: 3.2125s\n",
            "Epoch: 2506, Loss: 0.03779599815607071  (Learning rate: [0.0001953125], Time: 3.2021s\n",
            "Epoch: 2507, Loss: 0.03779524564743042  (Learning rate: [0.0001953125], Time: 3.2045s\n",
            "Epoch: 2508, Loss: 0.03779449313879013  (Learning rate: [0.0001953125], Time: 3.2075s\n",
            "Epoch: 2509, Loss: 0.03779373690485954  (Learning rate: [0.0001953125], Time: 3.1995s\n",
            "Epoch: 2510, Loss: 0.037792984396219254  (Learning rate: [0.0001953125], Time: 3.2082s\n",
            "Epoch: 2511, Loss: 0.037792231887578964  (Learning rate: [0.0001953125], Time: 3.2092s\n",
            "Epoch: 2512, Loss: 0.037791479378938675  (Learning rate: [0.0001953125], Time: 3.2131s\n",
            "Epoch: 2513, Loss: 0.037790726870298386  (Learning rate: [0.0001953125], Time: 3.2152s\n",
            "Epoch: 2514, Loss: 0.037789978086948395  (Learning rate: [0.0001953125], Time: 3.206s\n",
            "Epoch: 2515, Loss: 0.03778922185301781  (Learning rate: [0.0001953125], Time: 3.1999s\n",
            "Epoch: 2516, Loss: 0.03778846934437752  (Learning rate: [0.0001953125], Time: 3.2047s\n",
            "Epoch: 2517, Loss: 0.03778771683573723  (Learning rate: [0.0001953125], Time: 3.2071s\n",
            "Epoch: 2518, Loss: 0.03778696432709694  (Learning rate: [0.0001953125], Time: 3.2022s\n",
            "Epoch: 2519, Loss: 0.03778621181845665  (Learning rate: [0.0001953125], Time: 3.2157s\n",
            "Epoch: 2520, Loss: 0.03778545930981636  (Learning rate: [0.0001953125], Time: 3.2113s\n",
            "Epoch: 2521, Loss: 0.03778471052646637  (Learning rate: [0.0001953125], Time: 3.2183s\n",
            "Epoch: 2522, Loss: 0.03778395801782608  (Learning rate: [0.0001953125], Time: 3.2012s\n",
            "Epoch: 2523, Loss: 0.03778320550918579  (Learning rate: [0.0001953125], Time: 3.2119s\n",
            "Epoch: 2524, Loss: 0.0377824567258358  (Learning rate: [0.0001953125], Time: 3.2021s\n",
            "Epoch: 2525, Loss: 0.03778170421719551  (Learning rate: [0.0001953125], Time: 3.2074s\n",
            "Epoch: 2526, Loss: 0.03778095170855522  (Learning rate: [0.0001953125], Time: 3.2072s\n",
            "Epoch: 2527, Loss: 0.03778019919991493  (Learning rate: [0.0001953125], Time: 3.2071s\n",
            "Epoch: 2528, Loss: 0.03777944669127464  (Learning rate: [0.0001953125], Time: 3.2164s\n",
            "Epoch: 2529, Loss: 0.03777870163321495  (Learning rate: [0.0001953125], Time: 3.2195s\n",
            "Epoch: 2530, Loss: 0.03777794912457466  (Learning rate: [0.0001953125], Time: 3.2145s\n",
            "Epoch: 2531, Loss: 0.03777719661593437  (Learning rate: [0.0001953125], Time: 3.207s\n",
            "Epoch: 2532, Loss: 0.03777644783258438  (Learning rate: [0.0001953125], Time: 3.2026s\n",
            "Epoch: 2533, Loss: 0.03777569532394409  (Learning rate: [0.0001953125], Time: 3.199s\n",
            "Epoch: 2534, Loss: 0.0377749465405941  (Learning rate: [0.0001953125], Time: 3.2041s\n",
            "Epoch: 2535, Loss: 0.03777419403195381  (Learning rate: [0.0001953125], Time: 3.1977s\n",
            "Epoch: 2536, Loss: 0.03777344524860382  (Learning rate: [0.0001953125], Time: 3.2145s\n",
            "Epoch: 2537, Loss: 0.03777269646525383  (Learning rate: [0.0001953125], Time: 3.2126s\n",
            "Epoch: 2538, Loss: 0.03777194023132324  (Learning rate: [0.0001953125], Time: 3.2051s\n",
            "Epoch: 2539, Loss: 0.03777119144797325  (Learning rate: [0.0001953125], Time: 3.2055s\n",
            "Epoch: 2540, Loss: 0.03777044638991356  (Learning rate: [0.0001953125], Time: 3.2083s\n",
            "Epoch: 2541, Loss: 0.03776969760656357  (Learning rate: [0.0001953125], Time: 3.2096s\n",
            "Epoch: 2542, Loss: 0.03776894137263298  (Learning rate: [0.0001953125], Time: 3.2021s\n",
            "Epoch: 2543, Loss: 0.03776819258928299  (Learning rate: [0.0001953125], Time: 3.2055s\n",
            "Epoch: 2544, Loss: 0.037767443805933  (Learning rate: [0.0001953125], Time: 3.2267s\n",
            "Epoch: 2545, Loss: 0.037766698747873306  (Learning rate: [0.0001953125], Time: 3.2135s\n",
            "Epoch: 2546, Loss: 0.03776594623923302  (Learning rate: [0.0001953125], Time: 3.21s\n",
            "Epoch: 2547, Loss: 0.037765197455883026  (Learning rate: [0.0001953125], Time: 3.208s\n",
            "Epoch: 2548, Loss: 0.03776444494724274  (Learning rate: [0.0001953125], Time: 3.2347s\n",
            "Epoch: 2549, Loss: 0.037763696163892746  (Learning rate: [0.0001953125], Time: 3.1991s\n",
            "Epoch: 2550, Loss: 0.037762951105833054  (Learning rate: [0.0001953125], Time: 3.2045s\n",
            "Epoch: 2551, Loss: 0.03776220232248306  (Learning rate: [0.0001953125], Time: 3.2052s\n",
            "Epoch: 2552, Loss: 0.03776145353913307  (Learning rate: [0.0001953125], Time: 3.2153s\n",
            "Epoch: 2553, Loss: 0.03776070475578308  (Learning rate: [0.0001953125], Time: 3.2081s\n",
            "Epoch: 2554, Loss: 0.03775995597243309  (Learning rate: [0.0001953125], Time: 3.2027s\n",
            "Epoch: 2555, Loss: 0.0377592034637928  (Learning rate: [0.0001953125], Time: 3.2062s\n",
            "Epoch: 2556, Loss: 0.03775845468044281  (Learning rate: [0.0001953125], Time: 3.2061s\n",
            "Epoch: 2557, Loss: 0.03775770962238312  (Learning rate: [0.0001953125], Time: 3.2036s\n",
            "Epoch: 2558, Loss: 0.03775696083903313  (Learning rate: [0.0001953125], Time: 3.1986s\n",
            "Epoch: 2559, Loss: 0.03775620833039284  (Learning rate: [0.0001953125], Time: 3.2187s\n",
            "Epoch: 2560, Loss: 0.037755463272333145  (Learning rate: [0.0001953125], Time: 3.217s\n",
            "Epoch: 2561, Loss: 0.037754710763692856  (Learning rate: [0.0001953125], Time: 3.2117s\n",
            "Epoch: 2562, Loss: 0.03775396570563316  (Learning rate: [0.0001953125], Time: 3.2008s\n",
            "Epoch: 2563, Loss: 0.037753213196992874  (Learning rate: [0.0001953125], Time: 3.2094s\n",
            "Epoch: 2564, Loss: 0.03775246813893318  (Learning rate: [0.0001953125], Time: 3.2005s\n",
            "Epoch: 2565, Loss: 0.03775171935558319  (Learning rate: [0.0001953125], Time: 3.2085s\n",
            "Epoch: 2566, Loss: 0.0377509705722332  (Learning rate: [0.0001953125], Time: 3.2047s\n",
            "Epoch: 2567, Loss: 0.03775022551417351  (Learning rate: [0.0001953125], Time: 3.2175s\n",
            "Epoch: 2568, Loss: 0.03774947673082352  (Learning rate: [0.0001953125], Time: 3.2163s\n",
            "Epoch: 2569, Loss: 0.037748731672763824  (Learning rate: [0.0001953125], Time: 3.2046s\n",
            "Epoch: 2570, Loss: 0.037747982889413834  (Learning rate: [0.0001953125], Time: 3.2036s\n",
            "Epoch: 2571, Loss: 0.03774723410606384  (Learning rate: [0.0001953125], Time: 3.1993s\n",
            "Epoch: 2572, Loss: 0.03774648532271385  (Learning rate: [0.0001953125], Time: 3.2051s\n",
            "Epoch: 2573, Loss: 0.03774573653936386  (Learning rate: [0.0001953125], Time: 3.202s\n",
            "Epoch: 2574, Loss: 0.03774498775601387  (Learning rate: [0.0001953125], Time: 3.2018s\n",
            "Epoch: 2575, Loss: 0.03774424269795418  (Learning rate: [0.0001953125], Time: 3.2258s\n",
            "Epoch: 2576, Loss: 0.03774349391460419  (Learning rate: [0.0001953125], Time: 3.2173s\n",
            "Epoch: 2577, Loss: 0.037742748856544495  (Learning rate: [0.0001953125], Time: 3.194s\n",
            "Epoch: 2578, Loss: 0.037742000073194504  (Learning rate: [0.0001953125], Time: 3.2061s\n",
            "Epoch: 2579, Loss: 0.03774125128984451  (Learning rate: [0.0001953125], Time: 3.2085s\n",
            "Epoch: 2580, Loss: 0.03774050250649452  (Learning rate: [0.0001953125], Time: 3.2019s\n",
            "Epoch: 2581, Loss: 0.03773975744843483  (Learning rate: [0.0001953125], Time: 3.1921s\n",
            "Epoch: 2582, Loss: 0.03773900866508484  (Learning rate: [0.0001953125], Time: 3.1843s\n",
            "Epoch: 2583, Loss: 0.037738263607025146  (Learning rate: [0.0001953125], Time: 3.1938s\n",
            "Epoch: 2584, Loss: 0.037737514823675156  (Learning rate: [0.0001953125], Time: 3.1949s\n",
            "Epoch: 2585, Loss: 0.037736766040325165  (Learning rate: [0.0001953125], Time: 3.1794s\n",
            "Epoch: 2586, Loss: 0.037736017256975174  (Learning rate: [0.0001953125], Time: 3.1809s\n",
            "Epoch: 2587, Loss: 0.03773527219891548  (Learning rate: [0.0001953125], Time: 3.185s\n",
            "Epoch: 2588, Loss: 0.03773452714085579  (Learning rate: [0.0001953125], Time: 3.1896s\n",
            "Epoch: 2589, Loss: 0.0377337783575058  (Learning rate: [0.0001953125], Time: 3.1899s\n",
            "Epoch: 2590, Loss: 0.03773302957415581  (Learning rate: [0.0001953125], Time: 3.187s\n",
            "Epoch: 2591, Loss: 0.03773228079080582  (Learning rate: [0.0001953125], Time: 3.1896s\n",
            "Epoch: 2592, Loss: 0.037731535732746124  (Learning rate: [0.0001953125], Time: 3.1847s\n",
            "Epoch: 2593, Loss: 0.03773078694939613  (Learning rate: [0.0001953125], Time: 3.2058s\n",
            "Epoch: 2594, Loss: 0.03773004189133644  (Learning rate: [0.0001953125], Time: 3.1932s\n",
            "Epoch: 2595, Loss: 0.03772929310798645  (Learning rate: [0.0001953125], Time: 3.1821s\n",
            "Epoch: 2596, Loss: 0.03772854432463646  (Learning rate: [0.0001953125], Time: 3.1851s\n",
            "Epoch: 2597, Loss: 0.03772779926657677  (Learning rate: [0.0001953125], Time: 3.1801s\n",
            "Epoch: 2598, Loss: 0.037727050483226776  (Learning rate: [0.0001953125], Time: 3.1793s\n",
            "Epoch: 2599, Loss: 0.037726305425167084  (Learning rate: [0.0001953125], Time: 3.1807s\n",
            "Epoch: 2600, Loss: 0.03772555664181709  (Learning rate: [0.0001953125], Time: 3.1759s\n",
            "Epoch: 2601, Loss: 0.0377248078584671  (Learning rate: [0.0001953125], Time: 3.1807s\n",
            "Epoch: 2602, Loss: 0.03772406280040741  (Learning rate: [0.0001953125], Time: 3.2554s\n",
            "Epoch: 2603, Loss: 0.03772331401705742  (Learning rate: [0.0001953125], Time: 3.1921s\n",
            "Epoch: 2604, Loss: 0.037722568958997726  (Learning rate: [0.0001953125], Time: 3.1827s\n",
            "Epoch: 2605, Loss: 0.037721820175647736  (Learning rate: [0.0001953125], Time: 3.1896s\n",
            "Epoch: 2606, Loss: 0.037721071392297745  (Learning rate: [0.0001953125], Time: 3.189s\n",
            "Epoch: 2607, Loss: 0.03772032633423805  (Learning rate: [0.0001953125], Time: 3.1772s\n",
            "Epoch: 2608, Loss: 0.03771957755088806  (Learning rate: [0.0001953125], Time: 3.185s\n",
            "Epoch: 2609, Loss: 0.03771883249282837  (Learning rate: [0.0001953125], Time: 3.1748s\n",
            "Epoch: 2610, Loss: 0.03771808370947838  (Learning rate: [0.0001953125], Time: 3.1787s\n",
            "Epoch: 2611, Loss: 0.03771733492612839  (Learning rate: [0.0001953125], Time: 3.1916s\n",
            "Epoch: 2612, Loss: 0.037716589868068695  (Learning rate: [0.0001953125], Time: 3.1929s\n",
            "Epoch: 2613, Loss: 0.037715841084718704  (Learning rate: [0.0001953125], Time: 3.1956s\n",
            "Epoch: 2614, Loss: 0.03771509230136871  (Learning rate: [0.0001953125], Time: 3.1829s\n",
            "Epoch: 2615, Loss: 0.037714339792728424  (Learning rate: [0.0001953125], Time: 3.1766s\n",
            "Epoch: 2616, Loss: 0.03771359473466873  (Learning rate: [0.0001953125], Time: 3.1862s\n",
            "Epoch: 2617, Loss: 0.03771284222602844  (Learning rate: [0.0001953125], Time: 3.1792s\n",
            "Epoch: 2618, Loss: 0.03771209344267845  (Learning rate: [0.0001953125], Time: 3.1881s\n",
            "Epoch: 2619, Loss: 0.03771134838461876  (Learning rate: [0.0001953125], Time: 3.1805s\n",
            "Epoch: 2620, Loss: 0.03771059960126877  (Learning rate: [0.0001953125], Time: 3.196s\n",
            "Epoch: 2621, Loss: 0.03770985081791878  (Learning rate: [0.0001953125], Time: 3.2154s\n",
            "Epoch: 2622, Loss: 0.03770909830927849  (Learning rate: [0.0001953125], Time: 3.2184s\n",
            "Epoch: 2623, Loss: 0.0377083495259285  (Learning rate: [0.0001953125], Time: 3.1962s\n",
            "Epoch: 2624, Loss: 0.037707600742578506  (Learning rate: [0.0001953125], Time: 3.1996s\n",
            "Epoch: 2625, Loss: 0.037706851959228516  (Learning rate: [0.0001953125], Time: 3.201s\n",
            "Epoch: 2626, Loss: 0.037706099450588226  (Learning rate: [0.0001953125], Time: 3.2066s\n",
            "Epoch: 2627, Loss: 0.037705350667238235  (Learning rate: [0.0001953125], Time: 3.1987s\n",
            "Epoch: 2628, Loss: 0.037704601883888245  (Learning rate: [0.0001953125], Time: 3.1946s\n",
            "Epoch: 2629, Loss: 0.037703853100538254  (Learning rate: [0.0001953125], Time: 3.1914s\n",
            "Epoch: 2630, Loss: 0.037703100591897964  (Learning rate: [0.0001953125], Time: 3.2066s\n",
            "Epoch: 2631, Loss: 0.037702348083257675  (Learning rate: [0.0001953125], Time: 3.1946s\n",
            "Epoch: 2632, Loss: 0.037701599299907684  (Learning rate: [0.0001953125], Time: 3.1885s\n",
            "Epoch: 2633, Loss: 0.037700850516557693  (Learning rate: [0.0001953125], Time: 3.1946s\n",
            "Epoch: 2634, Loss: 0.037700094282627106  (Learning rate: [0.0001953125], Time: 3.2144s\n",
            "Epoch: 2635, Loss: 0.037699345499277115  (Learning rate: [0.0001953125], Time: 3.2032s\n",
            "Epoch: 2636, Loss: 0.037698592990636826  (Learning rate: [0.0001953125], Time: 3.2145s\n",
            "Epoch: 2637, Loss: 0.037697844207286835  (Learning rate: [0.0001953125], Time: 3.215s\n",
            "Epoch: 2638, Loss: 0.03769708797335625  (Learning rate: [0.0001953125], Time: 3.2163s\n",
            "Epoch: 2639, Loss: 0.03769633546471596  (Learning rate: [0.0001953125], Time: 3.2038s\n",
            "Epoch: 2640, Loss: 0.03769558295607567  (Learning rate: [0.0001953125], Time: 3.1998s\n",
            "Epoch: 2641, Loss: 0.03769483044743538  (Learning rate: [0.0001953125], Time: 3.2155s\n",
            "Epoch: 2642, Loss: 0.03769407793879509  (Learning rate: [0.0001953125], Time: 3.2048s\n",
            "Epoch: 2643, Loss: 0.0376933217048645  (Learning rate: [0.0001953125], Time: 3.2124s\n",
            "Epoch: 2644, Loss: 0.03769256919622421  (Learning rate: [0.0001953125], Time: 3.2053s\n",
            "Epoch: 2645, Loss: 0.037691812962293625  (Learning rate: [0.0001953125], Time: 3.2152s\n",
            "Epoch: 2646, Loss: 0.03769105672836304  (Learning rate: [0.0001953125], Time: 3.2148s\n",
            "Epoch: 2647, Loss: 0.03769030421972275  (Learning rate: [0.0001953125], Time: 3.2121s\n",
            "Epoch: 2648, Loss: 0.03768954798579216  (Learning rate: [0.0001953125], Time: 3.202s\n",
            "Epoch: 2649, Loss: 0.03768879175186157  (Learning rate: [0.0001953125], Time: 3.1991s\n",
            "Epoch: 2650, Loss: 0.037688035517930984  (Learning rate: [0.0001953125], Time: 3.2003s\n",
            "Epoch: 2651, Loss: 0.037687283009290695  (Learning rate: [0.0001953125], Time: 3.2037s\n",
            "Epoch: 2652, Loss: 0.03768652305006981  (Learning rate: [0.0001953125], Time: 3.1984s\n",
            "Epoch: 2653, Loss: 0.03768576681613922  (Learning rate: [0.0001953125], Time: 3.2072s\n",
            "Epoch: 2654, Loss: 0.037685006856918335  (Learning rate: [0.0001953125], Time: 3.2131s\n",
            "Epoch: 2655, Loss: 0.03768424689769745  (Learning rate: [0.0001953125], Time: 3.2117s\n",
            "Epoch: 2656, Loss: 0.03768349438905716  (Learning rate: [0.0001953125], Time: 3.2218s\n",
            "Epoch: 2657, Loss: 0.03768273442983627  (Learning rate: [0.0001953125], Time: 3.2027s\n",
            "Epoch: 2658, Loss: 0.03768197447061539  (Learning rate: [0.0001953125], Time: 3.2108s\n",
            "Epoch: 2659, Loss: 0.0376812145113945  (Learning rate: [0.0001953125], Time: 3.2057s\n",
            "Epoch: 2660, Loss: 0.037680454552173615  (Learning rate: [0.0001953125], Time: 3.2318s\n",
            "Epoch: 2661, Loss: 0.03767969459295273  (Learning rate: [0.0001953125], Time: 3.2146s\n",
            "Epoch: 2662, Loss: 0.03767893463373184  (Learning rate: [0.0001953125], Time: 3.222s\n",
            "Epoch: 2663, Loss: 0.037678174674510956  (Learning rate: [0.0001953125], Time: 3.2047s\n",
            "Epoch: 2664, Loss: 0.03767741471529007  (Learning rate: [0.0001953125], Time: 3.2053s\n",
            "Epoch: 2665, Loss: 0.037676651030778885  (Learning rate: [0.0001953125], Time: 3.2109s\n",
            "Epoch: 2666, Loss: 0.037675891071558  (Learning rate: [0.0001953125], Time: 3.2065s\n",
            "Epoch: 2667, Loss: 0.037675127387046814  (Learning rate: [0.0001953125], Time: 3.2035s\n",
            "Epoch: 2668, Loss: 0.03767436742782593  (Learning rate: [0.0001953125], Time: 3.1945s\n",
            "Epoch: 2669, Loss: 0.03767360374331474  (Learning rate: [0.0001953125], Time: 3.2132s\n",
            "Epoch: 2670, Loss: 0.03767284005880356  (Learning rate: [0.0001953125], Time: 3.2078s\n",
            "Epoch: 2671, Loss: 0.03767208009958267  (Learning rate: [0.0001953125], Time: 3.2089s\n",
            "Epoch: 2672, Loss: 0.03767131641507149  (Learning rate: [0.0001953125], Time: 3.2003s\n",
            "Epoch: 2673, Loss: 0.037670549005270004  (Learning rate: [0.0001953125], Time: 3.2095s\n",
            "Epoch: 2674, Loss: 0.03766978904604912  (Learning rate: [0.0001953125], Time: 3.2003s\n",
            "Epoch: 2675, Loss: 0.03766902536153793  (Learning rate: [0.0001953125], Time: 3.2029s\n",
            "Epoch: 2676, Loss: 0.03766826167702675  (Learning rate: [0.0001953125], Time: 3.211s\n",
            "Epoch: 2677, Loss: 0.037667494267225266  (Learning rate: [0.0001953125], Time: 3.2094s\n",
            "Epoch: 2678, Loss: 0.03766673058271408  (Learning rate: [0.0001953125], Time: 3.2118s\n",
            "Epoch: 2679, Loss: 0.037665970623493195  (Learning rate: [0.0001953125], Time: 3.2401s\n",
            "Epoch: 2680, Loss: 0.03766519948840141  (Learning rate: [0.0001953125], Time: 3.2099s\n",
            "Epoch: 2681, Loss: 0.03766443952918053  (Learning rate: [0.0001953125], Time: 3.1948s\n",
            "Epoch: 2682, Loss: 0.037663672119379044  (Learning rate: [0.0001953125], Time: 3.1883s\n",
            "Epoch: 2683, Loss: 0.03766290843486786  (Learning rate: [0.0001953125], Time: 3.1971s\n",
            "Epoch: 2684, Loss: 0.037662141025066376  (Learning rate: [0.0001953125], Time: 3.2044s\n",
            "Epoch: 2685, Loss: 0.03766138106584549  (Learning rate: [0.0001953125], Time: 3.2143s\n",
            "Epoch: 2686, Loss: 0.037660613656044006  (Learning rate: [0.0001953125], Time: 3.2152s\n",
            "Epoch: 2687, Loss: 0.03765984997153282  (Learning rate: [0.0001953125], Time: 3.2033s\n",
            "Epoch: 2688, Loss: 0.03765908256173134  (Learning rate: [0.0001953125], Time: 3.2154s\n",
            "Epoch: 2689, Loss: 0.03765832260251045  (Learning rate: [0.0001953125], Time: 3.2067s\n",
            "Epoch: 2690, Loss: 0.03765755519270897  (Learning rate: [0.0001953125], Time: 3.2098s\n",
            "Epoch: 2691, Loss: 0.037656791508197784  (Learning rate: [0.0001953125], Time: 3.2035s\n",
            "Epoch: 2692, Loss: 0.0376560240983963  (Learning rate: [0.0001953125], Time: 3.2081s\n",
            "Epoch: 2693, Loss: 0.03765526041388512  (Learning rate: [0.0001953125], Time: 3.2156s\n",
            "Epoch: 2694, Loss: 0.03765449672937393  (Learning rate: [0.0001953125], Time: 3.2243s\n",
            "Epoch: 2695, Loss: 0.03765373304486275  (Learning rate: [0.0001953125], Time: 3.1937s\n",
            "Epoch: 2696, Loss: 0.03765296936035156  (Learning rate: [0.0001953125], Time: 3.2061s\n",
            "Epoch: 2697, Loss: 0.03765220195055008  (Learning rate: [0.0001953125], Time: 3.203s\n",
            "Epoch: 2698, Loss: 0.037651438266038895  (Learning rate: [0.0001953125], Time: 3.1885s\n",
            "Epoch: 2699, Loss: 0.03765067085623741  (Learning rate: [0.0001953125], Time: 3.2107s\n",
            "Epoch: 2700, Loss: 0.03764990717172623  (Learning rate: [9.765625e-05], Time: 3.211s\n",
            "Epoch: 2701, Loss: 0.03764914721250534  (Learning rate: [9.765625e-05], Time: 3.2139s\n",
            "Epoch: 2702, Loss: 0.0376487635076046  (Learning rate: [9.765625e-05], Time: 3.2142s\n",
            "Epoch: 2703, Loss: 0.037648383527994156  (Learning rate: [9.765625e-05], Time: 3.2147s\n",
            "Epoch: 2704, Loss: 0.037647999823093414  (Learning rate: [9.765625e-05], Time: 3.2039s\n",
            "Epoch: 2705, Loss: 0.03764761611819267  (Learning rate: [9.765625e-05], Time: 3.2122s\n",
            "Epoch: 2706, Loss: 0.03764723613858223  (Learning rate: [9.765625e-05], Time: 3.2017s\n",
            "Epoch: 2707, Loss: 0.037646856158971786  (Learning rate: [9.765625e-05], Time: 3.2026s\n",
            "Epoch: 2708, Loss: 0.037646472454071045  (Learning rate: [9.765625e-05], Time: 3.2023s\n",
            "Epoch: 2709, Loss: 0.0376460924744606  (Learning rate: [9.765625e-05], Time: 3.2107s\n",
            "Epoch: 2710, Loss: 0.03764570876955986  (Learning rate: [9.765625e-05], Time: 3.215s\n",
            "Epoch: 2711, Loss: 0.03764532506465912  (Learning rate: [9.765625e-05], Time: 3.2418s\n",
            "Epoch: 2712, Loss: 0.037644945085048676  (Learning rate: [9.765625e-05], Time: 3.2021s\n",
            "Epoch: 2713, Loss: 0.037644561380147934  (Learning rate: [9.765625e-05], Time: 3.2125s\n",
            "Epoch: 2714, Loss: 0.03764418140053749  (Learning rate: [9.765625e-05], Time: 3.2171s\n",
            "Epoch: 2715, Loss: 0.03764380142092705  (Learning rate: [9.765625e-05], Time: 3.2047s\n",
            "Epoch: 2716, Loss: 0.03764341399073601  (Learning rate: [9.765625e-05], Time: 3.2145s\n",
            "Epoch: 2717, Loss: 0.037643034011125565  (Learning rate: [9.765625e-05], Time: 3.2169s\n",
            "Epoch: 2718, Loss: 0.03764265403151512  (Learning rate: [9.765625e-05], Time: 3.2109s\n",
            "Epoch: 2719, Loss: 0.03764227032661438  (Learning rate: [9.765625e-05], Time: 3.2039s\n",
            "Epoch: 2720, Loss: 0.03764188662171364  (Learning rate: [9.765625e-05], Time: 3.202s\n",
            "Epoch: 2721, Loss: 0.037641506642103195  (Learning rate: [9.765625e-05], Time: 3.2043s\n",
            "Epoch: 2722, Loss: 0.03764112666249275  (Learning rate: [9.765625e-05], Time: 3.2097s\n",
            "Epoch: 2723, Loss: 0.03764074668288231  (Learning rate: [9.765625e-05], Time: 3.2111s\n",
            "Epoch: 2724, Loss: 0.03764035925269127  (Learning rate: [9.765625e-05], Time: 3.2059s\n",
            "Epoch: 2725, Loss: 0.037639979273080826  (Learning rate: [9.765625e-05], Time: 3.2158s\n",
            "Epoch: 2726, Loss: 0.037639595568180084  (Learning rate: [9.765625e-05], Time: 3.2008s\n",
            "Epoch: 2727, Loss: 0.03763921558856964  (Learning rate: [9.765625e-05], Time: 3.2034s\n",
            "Epoch: 2728, Loss: 0.0376388356089592  (Learning rate: [9.765625e-05], Time: 3.202s\n",
            "Epoch: 2729, Loss: 0.037638455629348755  (Learning rate: [9.765625e-05], Time: 3.2087s\n",
            "Epoch: 2730, Loss: 0.037638068199157715  (Learning rate: [9.765625e-05], Time: 3.2196s\n",
            "Epoch: 2731, Loss: 0.03763768821954727  (Learning rate: [9.765625e-05], Time: 3.2044s\n",
            "Epoch: 2732, Loss: 0.03763730823993683  (Learning rate: [9.765625e-05], Time: 3.2011s\n",
            "Epoch: 2733, Loss: 0.037636928260326385  (Learning rate: [9.765625e-05], Time: 3.2124s\n",
            "Epoch: 2734, Loss: 0.037636544555425644  (Learning rate: [9.765625e-05], Time: 3.2153s\n",
            "Epoch: 2735, Loss: 0.0376361645758152  (Learning rate: [9.765625e-05], Time: 3.1912s\n",
            "Epoch: 2736, Loss: 0.03763578087091446  (Learning rate: [9.765625e-05], Time: 3.1931s\n",
            "Epoch: 2737, Loss: 0.03763539716601372  (Learning rate: [9.765625e-05], Time: 3.2068s\n",
            "Epoch: 2738, Loss: 0.037635017186403275  (Learning rate: [9.765625e-05], Time: 3.201s\n",
            "Epoch: 2739, Loss: 0.03763463348150253  (Learning rate: [9.765625e-05], Time: 3.204s\n",
            "Epoch: 2740, Loss: 0.03763424977660179  (Learning rate: [9.765625e-05], Time: 3.2057s\n",
            "Epoch: 2741, Loss: 0.03763387352228165  (Learning rate: [9.765625e-05], Time: 3.221s\n",
            "Epoch: 2742, Loss: 0.03763348609209061  (Learning rate: [9.765625e-05], Time: 3.2129s\n",
            "Epoch: 2743, Loss: 0.037633106112480164  (Learning rate: [9.765625e-05], Time: 3.2298s\n",
            "Epoch: 2744, Loss: 0.03763272613286972  (Learning rate: [9.765625e-05], Time: 3.2053s\n",
            "Epoch: 2745, Loss: 0.03763234242796898  (Learning rate: [9.765625e-05], Time: 3.2048s\n",
            "Epoch: 2746, Loss: 0.03763195872306824  (Learning rate: [9.765625e-05], Time: 3.2077s\n",
            "Epoch: 2747, Loss: 0.037631578743457794  (Learning rate: [9.765625e-05], Time: 3.2032s\n",
            "Epoch: 2748, Loss: 0.03763119876384735  (Learning rate: [9.765625e-05], Time: 3.2096s\n",
            "Epoch: 2749, Loss: 0.03763081878423691  (Learning rate: [9.765625e-05], Time: 3.2088s\n",
            "Epoch: 2750, Loss: 0.037630435079336166  (Learning rate: [9.765625e-05], Time: 3.2062s\n",
            "Epoch: 2751, Loss: 0.037630051374435425  (Learning rate: [9.765625e-05], Time: 3.2097s\n",
            "Epoch: 2752, Loss: 0.03762966766953468  (Learning rate: [9.765625e-05], Time: 3.2038s\n",
            "Epoch: 2753, Loss: 0.03762928768992424  (Learning rate: [9.765625e-05], Time: 3.195s\n",
            "Epoch: 2754, Loss: 0.0376289077103138  (Learning rate: [9.765625e-05], Time: 3.1905s\n",
            "Epoch: 2755, Loss: 0.03762852028012276  (Learning rate: [9.765625e-05], Time: 3.2132s\n",
            "Epoch: 2756, Loss: 0.037628140300512314  (Learning rate: [9.765625e-05], Time: 3.2088s\n",
            "Epoch: 2757, Loss: 0.03762776032090187  (Learning rate: [9.765625e-05], Time: 3.2221s\n",
            "Epoch: 2758, Loss: 0.03762737661600113  (Learning rate: [9.765625e-05], Time: 3.2169s\n",
            "Epoch: 2759, Loss: 0.037626996636390686  (Learning rate: [9.765625e-05], Time: 3.2038s\n",
            "Epoch: 2760, Loss: 0.037626612931489944  (Learning rate: [9.765625e-05], Time: 3.2046s\n",
            "Epoch: 2761, Loss: 0.0376262292265892  (Learning rate: [9.765625e-05], Time: 3.2081s\n",
            "Epoch: 2762, Loss: 0.03762584924697876  (Learning rate: [9.765625e-05], Time: 3.2127s\n",
            "Epoch: 2763, Loss: 0.03762546554207802  (Learning rate: [9.765625e-05], Time: 3.1975s\n",
            "Epoch: 2764, Loss: 0.037625085562467575  (Learning rate: [9.765625e-05], Time: 3.2103s\n",
            "Epoch: 2765, Loss: 0.037624701857566833  (Learning rate: [9.765625e-05], Time: 3.2128s\n",
            "Epoch: 2766, Loss: 0.03762431815266609  (Learning rate: [9.765625e-05], Time: 3.2092s\n",
            "Epoch: 2767, Loss: 0.03762394189834595  (Learning rate: [9.765625e-05], Time: 3.2005s\n",
            "Epoch: 2768, Loss: 0.037623558193445206  (Learning rate: [9.765625e-05], Time: 3.2057s\n",
            "Epoch: 2769, Loss: 0.037623174488544464  (Learning rate: [9.765625e-05], Time: 3.2174s\n",
            "Epoch: 2770, Loss: 0.03762279078364372  (Learning rate: [9.765625e-05], Time: 3.2005s\n",
            "Epoch: 2771, Loss: 0.03762241080403328  (Learning rate: [9.765625e-05], Time: 3.2066s\n",
            "Epoch: 2772, Loss: 0.03762202709913254  (Learning rate: [9.765625e-05], Time: 3.2194s\n",
            "Epoch: 2773, Loss: 0.037621643394231796  (Learning rate: [9.765625e-05], Time: 3.2168s\n",
            "Epoch: 2774, Loss: 0.03762126341462135  (Learning rate: [9.765625e-05], Time: 3.2017s\n",
            "Epoch: 2775, Loss: 0.03762087970972061  (Learning rate: [9.765625e-05], Time: 3.1956s\n",
            "Epoch: 2776, Loss: 0.03762049600481987  (Learning rate: [9.765625e-05], Time: 3.2076s\n",
            "Epoch: 2777, Loss: 0.03762011229991913  (Learning rate: [9.765625e-05], Time: 3.2029s\n",
            "Epoch: 2778, Loss: 0.037619732320308685  (Learning rate: [9.765625e-05], Time: 3.2025s\n",
            "Epoch: 2779, Loss: 0.037619348615407944  (Learning rate: [9.765625e-05], Time: 3.205s\n",
            "Epoch: 2780, Loss: 0.0376189686357975  (Learning rate: [9.765625e-05], Time: 3.2206s\n",
            "Epoch: 2781, Loss: 0.03761858493089676  (Learning rate: [9.765625e-05], Time: 3.2185s\n",
            "Epoch: 2782, Loss: 0.03761820122599602  (Learning rate: [9.765625e-05], Time: 3.2017s\n",
            "Epoch: 2783, Loss: 0.037617821246385574  (Learning rate: [9.765625e-05], Time: 3.2064s\n",
            "Epoch: 2784, Loss: 0.03761743754148483  (Learning rate: [9.765625e-05], Time: 3.2085s\n",
            "Epoch: 2785, Loss: 0.03761705756187439  (Learning rate: [9.765625e-05], Time: 3.2066s\n",
            "Epoch: 2786, Loss: 0.03761667013168335  (Learning rate: [9.765625e-05], Time: 3.2168s\n",
            "Epoch: 2787, Loss: 0.037616290152072906  (Learning rate: [9.765625e-05], Time: 3.2054s\n",
            "Epoch: 2788, Loss: 0.037615906447172165  (Learning rate: [9.765625e-05], Time: 3.2096s\n",
            "Epoch: 2789, Loss: 0.03761552646756172  (Learning rate: [9.765625e-05], Time: 3.2144s\n",
            "Epoch: 2790, Loss: 0.03761513903737068  (Learning rate: [9.765625e-05], Time: 3.2061s\n",
            "Epoch: 2791, Loss: 0.03761475905776024  (Learning rate: [9.765625e-05], Time: 3.2055s\n",
            "Epoch: 2792, Loss: 0.0376143753528595  (Learning rate: [9.765625e-05], Time: 3.2039s\n",
            "Epoch: 2793, Loss: 0.037613991647958755  (Learning rate: [9.765625e-05], Time: 3.2004s\n",
            "Epoch: 2794, Loss: 0.03761361166834831  (Learning rate: [9.765625e-05], Time: 3.2036s\n",
            "Epoch: 2795, Loss: 0.03761322796344757  (Learning rate: [9.765625e-05], Time: 3.2021s\n",
            "Epoch: 2796, Loss: 0.03761284425854683  (Learning rate: [9.765625e-05], Time: 3.2136s\n",
            "Epoch: 2797, Loss: 0.03761246055364609  (Learning rate: [9.765625e-05], Time: 3.2169s\n",
            "Epoch: 2798, Loss: 0.037612080574035645  (Learning rate: [9.765625e-05], Time: 3.1976s\n",
            "Epoch: 2799, Loss: 0.0376116968691349  (Learning rate: [9.765625e-05], Time: 3.2015s\n",
            "Epoch: 2800, Loss: 0.03761131316423416  (Learning rate: [9.765625e-05], Time: 3.2047s\n",
            "Epoch: 2801, Loss: 0.03761092945933342  (Learning rate: [9.765625e-05], Time: 3.2013s\n",
            "Epoch: 2802, Loss: 0.03761054947972298  (Learning rate: [9.765625e-05], Time: 3.1986s\n",
            "Epoch: 2803, Loss: 0.037610165774822235  (Learning rate: [9.765625e-05], Time: 3.2068s\n",
            "Epoch: 2804, Loss: 0.037609778344631195  (Learning rate: [9.765625e-05], Time: 3.2022s\n",
            "Epoch: 2805, Loss: 0.03760939836502075  (Learning rate: [9.765625e-05], Time: 3.2209s\n",
            "Epoch: 2806, Loss: 0.03760901093482971  (Learning rate: [9.765625e-05], Time: 3.2106s\n",
            "Epoch: 2807, Loss: 0.03760863095521927  (Learning rate: [9.765625e-05], Time: 3.2095s\n",
            "Epoch: 2808, Loss: 0.03760824725031853  (Learning rate: [9.765625e-05], Time: 3.2105s\n",
            "Epoch: 2809, Loss: 0.037607867270708084  (Learning rate: [9.765625e-05], Time: 3.2028s\n",
            "Epoch: 2810, Loss: 0.037607479840517044  (Learning rate: [9.765625e-05], Time: 3.2008s\n",
            "Epoch: 2811, Loss: 0.0376070961356163  (Learning rate: [9.765625e-05], Time: 3.1895s\n",
            "Epoch: 2812, Loss: 0.03760671615600586  (Learning rate: [9.765625e-05], Time: 3.1841s\n",
            "Epoch: 2813, Loss: 0.03760632872581482  (Learning rate: [9.765625e-05], Time: 3.2024s\n",
            "Epoch: 2814, Loss: 0.037605948746204376  (Learning rate: [9.765625e-05], Time: 3.1974s\n",
            "Epoch: 2815, Loss: 0.037605565041303635  (Learning rate: [9.765625e-05], Time: 3.1909s\n",
            "Epoch: 2816, Loss: 0.03760518133640289  (Learning rate: [9.765625e-05], Time: 3.1812s\n",
            "Epoch: 2817, Loss: 0.03760479763150215  (Learning rate: [9.765625e-05], Time: 3.1818s\n",
            "Epoch: 2818, Loss: 0.03760441392660141  (Learning rate: [9.765625e-05], Time: 3.19s\n",
            "Epoch: 2819, Loss: 0.03760403022170067  (Learning rate: [9.765625e-05], Time: 3.1883s\n",
            "Epoch: 2820, Loss: 0.03760364651679993  (Learning rate: [9.765625e-05], Time: 3.1854s\n",
            "Epoch: 2821, Loss: 0.037603262811899185  (Learning rate: [9.765625e-05], Time: 3.1793s\n",
            "Epoch: 2822, Loss: 0.037602879106998444  (Learning rate: [9.765625e-05], Time: 3.1956s\n",
            "Epoch: 2823, Loss: 0.037602499127388  (Learning rate: [9.765625e-05], Time: 3.1836s\n",
            "Epoch: 2824, Loss: 0.03760211169719696  (Learning rate: [9.765625e-05], Time: 3.2059s\n",
            "Epoch: 2825, Loss: 0.03760172799229622  (Learning rate: [9.765625e-05], Time: 3.2104s\n",
            "Epoch: 2826, Loss: 0.03760134056210518  (Learning rate: [9.765625e-05], Time: 3.2164s\n",
            "Epoch: 2827, Loss: 0.037600960582494736  (Learning rate: [9.765625e-05], Time: 3.2023s\n",
            "Epoch: 2828, Loss: 0.037600576877593994  (Learning rate: [9.765625e-05], Time: 3.2045s\n",
            "Epoch: 2829, Loss: 0.03760019689798355  (Learning rate: [9.765625e-05], Time: 3.2104s\n",
            "Epoch: 2830, Loss: 0.03759980574250221  (Learning rate: [9.765625e-05], Time: 3.198s\n",
            "Epoch: 2831, Loss: 0.03759942576289177  (Learning rate: [9.765625e-05], Time: 3.2176s\n",
            "Epoch: 2832, Loss: 0.03759904205799103  (Learning rate: [9.765625e-05], Time: 3.2018s\n",
            "Epoch: 2833, Loss: 0.037598658353090286  (Learning rate: [9.765625e-05], Time: 3.2023s\n",
            "Epoch: 2834, Loss: 0.037598274648189545  (Learning rate: [9.765625e-05], Time: 3.2127s\n",
            "Epoch: 2835, Loss: 0.037597887217998505  (Learning rate: [9.765625e-05], Time: 3.2055s\n",
            "Epoch: 2836, Loss: 0.03759750351309776  (Learning rate: [9.765625e-05], Time: 3.2204s\n",
            "Epoch: 2837, Loss: 0.03759711980819702  (Learning rate: [9.765625e-05], Time: 3.1987s\n",
            "Epoch: 2838, Loss: 0.03759673610329628  (Learning rate: [9.765625e-05], Time: 3.2041s\n",
            "Epoch: 2839, Loss: 0.03759635239839554  (Learning rate: [9.765625e-05], Time: 3.2159s\n",
            "Epoch: 2840, Loss: 0.0375959649682045  (Learning rate: [9.765625e-05], Time: 3.2008s\n",
            "Epoch: 2841, Loss: 0.03759558126330376  (Learning rate: [9.765625e-05], Time: 3.2032s\n",
            "Epoch: 2842, Loss: 0.037595197558403015  (Learning rate: [9.765625e-05], Time: 3.2071s\n",
            "Epoch: 2843, Loss: 0.037594813853502274  (Learning rate: [9.765625e-05], Time: 3.208s\n",
            "Epoch: 2844, Loss: 0.037594426423311234  (Learning rate: [9.765625e-05], Time: 3.2055s\n",
            "Epoch: 2845, Loss: 0.03759404271841049  (Learning rate: [9.765625e-05], Time: 3.209s\n",
            "Epoch: 2846, Loss: 0.03759365901350975  (Learning rate: [9.765625e-05], Time: 3.2152s\n",
            "Epoch: 2847, Loss: 0.03759327530860901  (Learning rate: [9.765625e-05], Time: 3.2115s\n",
            "Epoch: 2848, Loss: 0.03759289160370827  (Learning rate: [9.765625e-05], Time: 3.2084s\n",
            "Epoch: 2849, Loss: 0.03759250417351723  (Learning rate: [9.765625e-05], Time: 3.2039s\n",
            "Epoch: 2850, Loss: 0.037592120468616486  (Learning rate: [9.765625e-05], Time: 3.2047s\n",
            "Epoch: 2851, Loss: 0.037591736763715744  (Learning rate: [9.765625e-05], Time: 3.2058s\n",
            "Epoch: 2852, Loss: 0.037591349333524704  (Learning rate: [9.765625e-05], Time: 3.2205s\n",
            "Epoch: 2853, Loss: 0.03759096562862396  (Learning rate: [9.765625e-05], Time: 3.2027s\n",
            "Epoch: 2854, Loss: 0.03759058192372322  (Learning rate: [9.765625e-05], Time: 3.2129s\n",
            "Epoch: 2855, Loss: 0.03759019449353218  (Learning rate: [9.765625e-05], Time: 3.2165s\n",
            "Epoch: 2856, Loss: 0.03758981451392174  (Learning rate: [9.765625e-05], Time: 3.2069s\n",
            "Epoch: 2857, Loss: 0.0375894270837307  (Learning rate: [9.765625e-05], Time: 3.2084s\n",
            "Epoch: 2858, Loss: 0.03758903965353966  (Learning rate: [9.765625e-05], Time: 3.2006s\n",
            "Epoch: 2859, Loss: 0.037588655948638916  (Learning rate: [9.765625e-05], Time: 3.2037s\n",
            "Epoch: 2860, Loss: 0.037588272243738174  (Learning rate: [9.765625e-05], Time: 3.2056s\n",
            "Epoch: 2861, Loss: 0.037587884813547134  (Learning rate: [9.765625e-05], Time: 3.2025s\n",
            "Epoch: 2862, Loss: 0.03758750110864639  (Learning rate: [9.765625e-05], Time: 3.215s\n",
            "Epoch: 2863, Loss: 0.03758711367845535  (Learning rate: [9.765625e-05], Time: 3.2157s\n",
            "Epoch: 2864, Loss: 0.03758672997355461  (Learning rate: [9.765625e-05], Time: 3.2051s\n",
            "Epoch: 2865, Loss: 0.03758634254336357  (Learning rate: [9.765625e-05], Time: 3.2091s\n",
            "Epoch: 2866, Loss: 0.03758595883846283  (Learning rate: [9.765625e-05], Time: 3.2139s\n",
            "Epoch: 2867, Loss: 0.03758557513356209  (Learning rate: [9.765625e-05], Time: 3.2136s\n",
            "Epoch: 2868, Loss: 0.03758518770337105  (Learning rate: [9.765625e-05], Time: 3.2022s\n",
            "Epoch: 2869, Loss: 0.037584803998470306  (Learning rate: [9.765625e-05], Time: 3.2013s\n",
            "Epoch: 2870, Loss: 0.037584416568279266  (Learning rate: [9.765625e-05], Time: 3.2217s\n",
            "Epoch: 2871, Loss: 0.037584032863378525  (Learning rate: [9.765625e-05], Time: 3.2132s\n",
            "Epoch: 2872, Loss: 0.037583641707897186  (Learning rate: [9.765625e-05], Time: 3.2032s\n",
            "Epoch: 2873, Loss: 0.03758326172828674  (Learning rate: [9.765625e-05], Time: 3.2142s\n",
            "Epoch: 2874, Loss: 0.0375828742980957  (Learning rate: [9.765625e-05], Time: 3.2042s\n",
            "Epoch: 2875, Loss: 0.03758248686790466  (Learning rate: [9.765625e-05], Time: 3.2108s\n",
            "Epoch: 2876, Loss: 0.03758210316300392  (Learning rate: [9.765625e-05], Time: 3.2164s\n",
            "Epoch: 2877, Loss: 0.03758171573281288  (Learning rate: [9.765625e-05], Time: 3.2134s\n",
            "Epoch: 2878, Loss: 0.03758132830262184  (Learning rate: [9.765625e-05], Time: 3.216s\n",
            "Epoch: 2879, Loss: 0.0375809408724308  (Learning rate: [9.765625e-05], Time: 3.202s\n",
            "Epoch: 2880, Loss: 0.03758055716753006  (Learning rate: [9.765625e-05], Time: 3.2048s\n",
            "Epoch: 2881, Loss: 0.03758016973733902  (Learning rate: [9.765625e-05], Time: 3.2048s\n",
            "Epoch: 2882, Loss: 0.03757978603243828  (Learning rate: [9.765625e-05], Time: 3.2049s\n",
            "Epoch: 2883, Loss: 0.03757939860224724  (Learning rate: [9.765625e-05], Time: 3.2053s\n",
            "Epoch: 2884, Loss: 0.0375790111720562  (Learning rate: [9.765625e-05], Time: 3.2268s\n",
            "Epoch: 2885, Loss: 0.03757862374186516  (Learning rate: [9.765625e-05], Time: 3.2144s\n",
            "Epoch: 2886, Loss: 0.03757823631167412  (Learning rate: [9.765625e-05], Time: 3.2151s\n",
            "Epoch: 2887, Loss: 0.037577852606773376  (Learning rate: [9.765625e-05], Time: 3.2063s\n",
            "Epoch: 2888, Loss: 0.037577465176582336  (Learning rate: [9.765625e-05], Time: 3.2161s\n",
            "Epoch: 2889, Loss: 0.037577081471681595  (Learning rate: [9.765625e-05], Time: 3.205s\n",
            "Epoch: 2890, Loss: 0.037576690316200256  (Learning rate: [9.765625e-05], Time: 3.2054s\n",
            "Epoch: 2891, Loss: 0.037576302886009216  (Learning rate: [9.765625e-05], Time: 3.2051s\n",
            "Epoch: 2892, Loss: 0.037575919181108475  (Learning rate: [9.765625e-05], Time: 3.2069s\n",
            "Epoch: 2893, Loss: 0.037575531750917435  (Learning rate: [9.765625e-05], Time: 3.2111s\n",
            "Epoch: 2894, Loss: 0.037575144320726395  (Learning rate: [9.765625e-05], Time: 3.2104s\n",
            "Epoch: 2895, Loss: 0.037574756890535355  (Learning rate: [9.765625e-05], Time: 3.2184s\n",
            "Epoch: 2896, Loss: 0.037574369460344315  (Learning rate: [9.765625e-05], Time: 3.2067s\n",
            "Epoch: 2897, Loss: 0.03757398575544357  (Learning rate: [9.765625e-05], Time: 3.2041s\n",
            "Epoch: 2898, Loss: 0.037573594599962234  (Learning rate: [9.765625e-05], Time: 3.2093s\n",
            "Epoch: 2899, Loss: 0.037573207169771194  (Learning rate: [9.765625e-05], Time: 3.2083s\n",
            "Epoch: 2900, Loss: 0.03757282346487045  (Learning rate: [9.765625e-05], Time: 3.2168s\n",
            "Epoch: 2901, Loss: 0.037572432309389114  (Learning rate: [9.765625e-05], Time: 3.218s\n",
            "Epoch: 2902, Loss: 0.03757204860448837  (Learning rate: [9.765625e-05], Time: 3.2164s\n",
            "Epoch: 2903, Loss: 0.03757166117429733  (Learning rate: [9.765625e-05], Time: 3.2622s\n",
            "Epoch: 2904, Loss: 0.03757127374410629  (Learning rate: [9.765625e-05], Time: 3.2046s\n",
            "Epoch: 2905, Loss: 0.03757088631391525  (Learning rate: [9.765625e-05], Time: 3.2075s\n",
            "Epoch: 2906, Loss: 0.03757049888372421  (Learning rate: [9.765625e-05], Time: 3.2107s\n",
            "Epoch: 2907, Loss: 0.03757011145353317  (Learning rate: [9.765625e-05], Time: 3.2154s\n",
            "Epoch: 2908, Loss: 0.03756972402334213  (Learning rate: [9.765625e-05], Time: 3.2119s\n",
            "Epoch: 2909, Loss: 0.03756933659315109  (Learning rate: [9.765625e-05], Time: 3.2216s\n",
            "Epoch: 2910, Loss: 0.03756894916296005  (Learning rate: [9.765625e-05], Time: 3.2017s\n",
            "Epoch: 2911, Loss: 0.03756856173276901  (Learning rate: [9.765625e-05], Time: 3.2088s\n",
            "Epoch: 2912, Loss: 0.03756817430257797  (Learning rate: [9.765625e-05], Time: 3.2026s\n",
            "Epoch: 2913, Loss: 0.03756778687238693  (Learning rate: [9.765625e-05], Time: 3.2013s\n",
            "Epoch: 2914, Loss: 0.03756739944219589  (Learning rate: [9.765625e-05], Time: 3.2027s\n",
            "Epoch: 2915, Loss: 0.03756701201200485  (Learning rate: [9.765625e-05], Time: 3.2048s\n",
            "Epoch: 2916, Loss: 0.03756662458181381  (Learning rate: [9.765625e-05], Time: 3.2179s\n",
            "Epoch: 2917, Loss: 0.037566233426332474  (Learning rate: [9.765625e-05], Time: 3.2251s\n",
            "Epoch: 2918, Loss: 0.037565845996141434  (Learning rate: [9.765625e-05], Time: 3.2043s\n",
            "Epoch: 2919, Loss: 0.037565458565950394  (Learning rate: [9.765625e-05], Time: 3.2161s\n",
            "Epoch: 2920, Loss: 0.037565071135759354  (Learning rate: [9.765625e-05], Time: 3.2027s\n",
            "Epoch: 2921, Loss: 0.03756468743085861  (Learning rate: [9.765625e-05], Time: 3.2078s\n",
            "Epoch: 2922, Loss: 0.037564296275377274  (Learning rate: [9.765625e-05], Time: 3.2006s\n",
            "Epoch: 2923, Loss: 0.037563908845186234  (Learning rate: [9.765625e-05], Time: 3.2002s\n",
            "Epoch: 2924, Loss: 0.037563521414995193  (Learning rate: [9.765625e-05], Time: 3.2161s\n",
            "Epoch: 2925, Loss: 0.03756313398480415  (Learning rate: [9.765625e-05], Time: 3.2185s\n",
            "Epoch: 2926, Loss: 0.037562742829322815  (Learning rate: [9.765625e-05], Time: 3.2041s\n",
            "Epoch: 2927, Loss: 0.037562355399131775  (Learning rate: [9.765625e-05], Time: 3.2098s\n",
            "Epoch: 2928, Loss: 0.037561967968940735  (Learning rate: [9.765625e-05], Time: 3.2011s\n",
            "Epoch: 2929, Loss: 0.037561580538749695  (Learning rate: [9.765625e-05], Time: 3.2022s\n",
            "Epoch: 2930, Loss: 0.037561189383268356  (Learning rate: [9.765625e-05], Time: 3.2116s\n",
            "Epoch: 2931, Loss: 0.037560801953077316  (Learning rate: [9.765625e-05], Time: 3.2076s\n",
            "Epoch: 2932, Loss: 0.037560418248176575  (Learning rate: [9.765625e-05], Time: 3.2069s\n",
            "Epoch: 2933, Loss: 0.037560027092695236  (Learning rate: [9.765625e-05], Time: 3.2118s\n",
            "Epoch: 2934, Loss: 0.0375596359372139  (Learning rate: [9.765625e-05], Time: 3.2068s\n",
            "Epoch: 2935, Loss: 0.03755924850702286  (Learning rate: [9.765625e-05], Time: 3.2094s\n",
            "Epoch: 2936, Loss: 0.037558864802122116  (Learning rate: [9.765625e-05], Time: 3.2081s\n",
            "Epoch: 2937, Loss: 0.03755847364664078  (Learning rate: [9.765625e-05], Time: 3.2082s\n",
            "Epoch: 2938, Loss: 0.03755808249115944  (Learning rate: [9.765625e-05], Time: 3.2052s\n",
            "Epoch: 2939, Loss: 0.0375576950609684  (Learning rate: [9.765625e-05], Time: 3.2162s\n",
            "Epoch: 2940, Loss: 0.03755731135606766  (Learning rate: [9.765625e-05], Time: 3.2079s\n",
            "Epoch: 2941, Loss: 0.03755692020058632  (Learning rate: [9.765625e-05], Time: 3.2027s\n",
            "Epoch: 2942, Loss: 0.03755652904510498  (Learning rate: [9.765625e-05], Time: 3.2277s\n",
            "Epoch: 2943, Loss: 0.03755614161491394  (Learning rate: [9.765625e-05], Time: 3.21s\n",
            "Epoch: 2944, Loss: 0.0375557579100132  (Learning rate: [9.765625e-05], Time: 3.205s\n",
            "Epoch: 2945, Loss: 0.03755536675453186  (Learning rate: [9.765625e-05], Time: 3.214s\n",
            "Epoch: 2946, Loss: 0.03755497559905052  (Learning rate: [9.765625e-05], Time: 3.2024s\n",
            "Epoch: 2947, Loss: 0.03755458816885948  (Learning rate: [9.765625e-05], Time: 3.2181s\n",
            "Epoch: 2948, Loss: 0.03755419701337814  (Learning rate: [9.765625e-05], Time: 3.2127s\n",
            "Epoch: 2949, Loss: 0.0375538095831871  (Learning rate: [9.765625e-05], Time: 3.2104s\n",
            "Epoch: 2950, Loss: 0.03755342215299606  (Learning rate: [9.765625e-05], Time: 3.2035s\n",
            "Epoch: 2951, Loss: 0.037553030997514725  (Learning rate: [9.765625e-05], Time: 3.2276s\n",
            "Epoch: 2952, Loss: 0.037552639842033386  (Learning rate: [9.765625e-05], Time: 3.198s\n",
            "Epoch: 2953, Loss: 0.037552252411842346  (Learning rate: [9.765625e-05], Time: 3.2062s\n",
            "Epoch: 2954, Loss: 0.037551864981651306  (Learning rate: [9.765625e-05], Time: 3.2164s\n",
            "Epoch: 2955, Loss: 0.037551477551460266  (Learning rate: [9.765625e-05], Time: 3.2164s\n",
            "Epoch: 2956, Loss: 0.03755108639597893  (Learning rate: [9.765625e-05], Time: 3.2186s\n",
            "Epoch: 2957, Loss: 0.03755069524049759  (Learning rate: [9.765625e-05], Time: 3.2132s\n",
            "Epoch: 2958, Loss: 0.03755030408501625  (Learning rate: [9.765625e-05], Time: 3.2062s\n",
            "Epoch: 2959, Loss: 0.03754991665482521  (Learning rate: [9.765625e-05], Time: 3.2129s\n",
            "Epoch: 2960, Loss: 0.03754952549934387  (Learning rate: [9.765625e-05], Time: 3.2094s\n",
            "Epoch: 2961, Loss: 0.03754913806915283  (Learning rate: [9.765625e-05], Time: 3.2079s\n",
            "Epoch: 2962, Loss: 0.037548746913671494  (Learning rate: [9.765625e-05], Time: 3.2185s\n",
            "Epoch: 2963, Loss: 0.037548359483480453  (Learning rate: [9.765625e-05], Time: 3.2296s\n",
            "Epoch: 2964, Loss: 0.03754797205328941  (Learning rate: [9.765625e-05], Time: 3.2127s\n",
            "Epoch: 2965, Loss: 0.037547580897808075  (Learning rate: [9.765625e-05], Time: 3.206s\n",
            "Epoch: 2966, Loss: 0.037547189742326736  (Learning rate: [9.765625e-05], Time: 3.2045s\n",
            "Epoch: 2967, Loss: 0.037546802312135696  (Learning rate: [9.765625e-05], Time: 3.2003s\n",
            "Epoch: 2968, Loss: 0.03754641115665436  (Learning rate: [9.765625e-05], Time: 3.2076s\n",
            "Epoch: 2969, Loss: 0.03754602000117302  (Learning rate: [9.765625e-05], Time: 3.1979s\n",
            "Epoch: 2970, Loss: 0.03754563257098198  (Learning rate: [9.765625e-05], Time: 3.2139s\n",
            "Epoch: 2971, Loss: 0.03754524141550064  (Learning rate: [9.765625e-05], Time: 3.213s\n",
            "Epoch: 2972, Loss: 0.0375448539853096  (Learning rate: [9.765625e-05], Time: 3.2193s\n",
            "Epoch: 2973, Loss: 0.03754446282982826  (Learning rate: [9.765625e-05], Time: 3.2069s\n",
            "Epoch: 2974, Loss: 0.03754407539963722  (Learning rate: [9.765625e-05], Time: 3.2025s\n",
            "Epoch: 2975, Loss: 0.037543684244155884  (Learning rate: [9.765625e-05], Time: 3.2052s\n",
            "Epoch: 2976, Loss: 0.037543293088674545  (Learning rate: [9.765625e-05], Time: 3.211s\n",
            "Epoch: 2977, Loss: 0.03754290193319321  (Learning rate: [9.765625e-05], Time: 3.2044s\n",
            "Epoch: 2978, Loss: 0.03754251077771187  (Learning rate: [9.765625e-05], Time: 3.2228s\n",
            "Epoch: 2979, Loss: 0.03754211962223053  (Learning rate: [9.765625e-05], Time: 3.2173s\n",
            "Epoch: 2980, Loss: 0.03754172846674919  (Learning rate: [9.765625e-05], Time: 3.2062s\n",
            "Epoch: 2981, Loss: 0.03754134103655815  (Learning rate: [9.765625e-05], Time: 3.2134s\n",
            "Epoch: 2982, Loss: 0.03754094988107681  (Learning rate: [9.765625e-05], Time: 3.208s\n",
            "Epoch: 2983, Loss: 0.03754056245088577  (Learning rate: [9.765625e-05], Time: 3.2165s\n",
            "Epoch: 2984, Loss: 0.037540171295404434  (Learning rate: [9.765625e-05], Time: 3.1992s\n",
            "Epoch: 2985, Loss: 0.037539780139923096  (Learning rate: [9.765625e-05], Time: 3.2046s\n",
            "Epoch: 2986, Loss: 0.03753938898444176  (Learning rate: [9.765625e-05], Time: 3.2221s\n",
            "Epoch: 2987, Loss: 0.03753899782896042  (Learning rate: [9.765625e-05], Time: 3.2146s\n",
            "Epoch: 2988, Loss: 0.03753860667347908  (Learning rate: [9.765625e-05], Time: 3.2007s\n",
            "Epoch: 2989, Loss: 0.03753821551799774  (Learning rate: [9.765625e-05], Time: 3.2031s\n",
            "Epoch: 2990, Loss: 0.0375378243625164  (Learning rate: [9.765625e-05], Time: 3.2067s\n",
            "Epoch: 2991, Loss: 0.037537433207035065  (Learning rate: [9.765625e-05], Time: 3.2058s\n",
            "Epoch: 2992, Loss: 0.037537042051553726  (Learning rate: [9.765625e-05], Time: 3.2159s\n",
            "Epoch: 2993, Loss: 0.03753665089607239  (Learning rate: [9.765625e-05], Time: 3.2133s\n",
            "Epoch: 2994, Loss: 0.03753625974059105  (Learning rate: [9.765625e-05], Time: 3.2185s\n",
            "Epoch: 2995, Loss: 0.03753586858510971  (Learning rate: [9.765625e-05], Time: 3.2048s\n",
            "Epoch: 2996, Loss: 0.03753547742962837  (Learning rate: [9.765625e-05], Time: 3.1957s\n",
            "Epoch: 2997, Loss: 0.037535086274147034  (Learning rate: [9.765625e-05], Time: 3.2067s\n",
            "Epoch: 2998, Loss: 0.037534698843955994  (Learning rate: [9.765625e-05], Time: 3.2002s\n",
            "Epoch: 2999, Loss: 0.03753430396318436  (Learning rate: [9.765625e-05], Time: 3.2084s\n",
            "Epoch: 3000, Loss: 0.03753391280770302  (Learning rate: [4.8828125e-05], Time: 3.1937s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMDAzMxwGZmaGw8DMzID/D0hYgeI0BnpIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNCtOASxL2Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def net_generate(e, sample=False):\n",
        "  event_steps = e.shape[0]\n",
        "  encoded_conditioning = event_forward_pass(e.view(1, event_steps, -1))\n",
        "  hidden = (signal_h_ini[0][0,0,:].view(num_signal_layers, 1, signal_hidden_size), \\\n",
        "           signal_h_ini[1][0,0,:].view(num_signal_layers, 1, signal_hidden_size))\n",
        "  signal_prev = torch.zeros(1, signal_emb_size).to(device=dflt_device)\n",
        "  prediction_list     = []\n",
        "  raw_prediction_list = []\n",
        "  cumulative_duration = 0\n",
        "  while cumulative_duration <= float(event_steps-1):\n",
        "    dynamic_idx = int(cumulative_duration)\n",
        "    conditioning = encoded_conditioning[0, dynamic_idx, :].view(1,-1)\n",
        "    signal_input = torch.cat((signal_prev, conditioning), dim=1)\n",
        "    signal_input = signal_input.view(1,1,-1)\n",
        "    s_hat_pre, hidden = signal_forward_pass(signal_input, hidden )\n",
        "    #s_hat = torch.sigmoid(s_hat)  #smoothens the future prob dist\n",
        "    s_hat_pitch  = F.softmax( s_hat_pre[0, 0, 0:rhythm_idx_ini], dim = 0 )\n",
        "    s_hat_rhythm = F.softmax( s_hat_pre[0, 0, rhythm_idx_ini:], dim = 0 )\n",
        "    \n",
        "    raw_s_hat = torch.cat ((s_hat_pitch,s_hat_rhythm) , dim = 0).view(1,-1)\n",
        "    raw_prediction_list.append(raw_s_hat)        \n",
        "    \n",
        "    if sample == False:\n",
        "        note_max , note_argmax = s_hat_pitch.max(0)\n",
        "        rhythm_max , rhythm_argmax = s_hat_rhythm.max(0)\n",
        "        \n",
        "    if sample == True:\n",
        "        note_prob_dist = torch.distributions.Categorical(s_hat_pitch)\n",
        "        note_argmax = int(note_prob_dist.sample())\n",
        "        rhythm_prob_dist = torch.distributions.Categorical(s_hat_rhythm)\n",
        "        rhythm_argmax = int(rhythm_prob_dist.sample())\n",
        "    \n",
        "    s_hat = torch.zeros(1, signal_emb_size)\n",
        "    s_hat[0, int(note_argmax)] = 1  \n",
        "    s_hat[0, int(rhythm_idx_ini + int(rhythm_argmax))] = 1                    \n",
        "    prediction_list.append(s_hat)\n",
        "\n",
        "    #pitch_idx, rhythm_idx = list((s_hat != 0).nonzero())\n",
        "    #pitch_idx, rhythm_idx = int(pitch_idx), int(rhythm_idx)\n",
        "    #duration_type_idx = rhythm_argmax - rhythm_idx_ini\n",
        "    duration_type = durations_list[rhythm_argmax]\n",
        "    cumulative_duration += duration_type\n",
        "\n",
        "    signal_prev  = s_hat.to(device=dflt_device)\n",
        "\n",
        "  prediction = torch.cat(prediction_list)\n",
        "  raw_prediction = torch.cat(raw_prediction_list)\n",
        "\n",
        "  return prediction , raw_prediction\n",
        "\n",
        "e = E[1,:,:]\n",
        "prediction , raw_prediction = net_generate(e, sample=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAFJZ-mw8vH7",
        "colab_type": "code",
        "outputId": "07e6a005-6782-45c4-c4f1-ae9fc29958f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(prediction.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([61, 89])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrld_D1PrpFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conditioning_prueba = event_forward_pass(E[0,:,:].view(1,16,-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT26iejytLhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conditioning_prueba[0,0,:].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O0LbIBJtYCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_prueba = torch.cat( (S_input.data[0,0:89], conditioning_prueba[0,0,:]), dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNqYgQ12uxMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_prueba = input_prueba.view(1,1,105)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxPXX2MYu8D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prueba_h_ini = (signal_h_ini[0][0,0,:].view(1,1,128), signal_h_ini[1][0,0,:].view(1,1,128))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIv1eTkgvFDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_hat, hidden = signal_forward_pass(input_prueba, prueba_h_ini )\n",
        "s_hat = torch.sigmoid(s_hat)\n",
        "s_hat.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vkNtYLjvN0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_hat = 1*(s_hat>=0.5)\n",
        "s_hat = s_hat.type(torch.FloatTensor)\n",
        "s_hat = s_hat.to(device=dflt_device)\n",
        "print(s_hat.shape)\n",
        "conditioning_prueba[0,0,:].view(1,1,16).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBa_giDcwILr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_next = torch.cat((s_hat, conditioning_prueba[0,0,:].view(1,1,16)), dim=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm7dH_LdwWCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_hat2, hidden = signal_forward_pass(s_next, hidden )\n",
        "s_hat2 = torch.sigmoid(s_hat2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1If9e36wsqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_hat1, hidden = signal_forward_pass(input_prueba, prueba_h_ini )\n",
        "s_hat1 = torch.sigmoid(s_hat1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A58GjRJCwuK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s_hat1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}